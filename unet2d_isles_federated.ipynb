{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "433c64ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "import monai\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import copy\n",
    "\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AsChannelFirstD,\n",
    "    AddChannel,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandRotate90,\n",
    "    RandSpatialCrop,\n",
    "    ScaleIntensity,\n",
    "    EnsureType,\n",
    "    Resized\n",
    ")\n",
    "\n",
    "from monai.data import (\n",
    "    ArrayDataset, GridPatchDataset, create_test_image_3d, PatchIter) #Aparently this allow to read direcly a set of niftis\n",
    "from monai.utils import first\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import DataLoader, decollate_batch\n",
    "\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "597d9a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_weights(local_trained_weights):\n",
    "    \"\"\"Returns the average of the weights.\n",
    "       local_trained_weights: The list of tensors (of the same shape) that will be averaged\n",
    "    \"\"\"\n",
    "    # Initialize copy model weights with the untrained model weights.\n",
    "    avg_weights = copy.deepcopy(local_trained_weights[0])\n",
    "    for key in avg_weights.keys():\n",
    "        for i in range(1, len(local_trained_weights)):\n",
    "            avg_weights[key] += local_trained_weights[i][key]\n",
    "        avg_weights[key] = torch.div(avg_weights[key], len(local_trained_weights))\n",
    "    return avg_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c28369c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============CENTER1====================\n",
      "15 15\n",
      "3 3\n",
      "4 4\n",
      "===============CENTER2====================\n",
      "41 41\n",
      "8 8\n",
      "8 8\n",
      "===============CENTER3====================\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "===============CENTER4====================\n",
      "9 9\n",
      "2 2\n",
      "2 2\n"
     ]
    }
   ],
   "source": [
    "#loading volume paths\n",
    "LOCATION = 'scan' #laptop\n",
    "if LOCATION == 'scan':\n",
    "    isles_data_root = '/str/data/ASAP/miccai22_data/isles/federated/'\n",
    "    exp_root = '/home/otarola/miccai22/fedem/'\n",
    "\n",
    "if LOCATION == 'laptop':\n",
    "    isles_data_root = '/data/ASAP/miccai22_data/isles/federated/'\n",
    "\n",
    "center1_cbf_paths_train  = sorted(glob(isles_data_root+'center1/train/'+'/**/*CBF*/*.nii'))\n",
    "center1_cbf_paths_valid  = sorted(glob(isles_data_root+'center1/valid/'+'/**/*CBF*/*.nii'))\n",
    "center1_cbf_paths_test   = sorted(glob(isles_data_root+'center1/test/'+'/**/*CBF*/*.nii'))\n",
    "center1_lbl_paths_train  = sorted(glob(isles_data_root+'center1/train/'+'/**/*OT*/*nii'))\n",
    "center1_lbl_paths_valid  = sorted(glob(isles_data_root+'center1/valid/'+'/**/*OT*/*nii'))\n",
    "center1_lbl_paths_test  = sorted(glob(isles_data_root+'center1/test/'+'/**/*OT*/*nii'))\n",
    "\n",
    "center2_cbf_paths_train  = sorted(glob(isles_data_root+'center2/train/'+'/**/*CBF*/*.nii'))\n",
    "center2_cbf_paths_valid  = sorted(glob(isles_data_root+'center2/valid/'+'/**/*CBF*/*.nii'))\n",
    "center2_cbf_paths_test   = sorted(glob(isles_data_root+'center2/test/'+'/**/*CBF*/*.nii'))\n",
    "center2_lbl_paths_train  = sorted(glob(isles_data_root+'center2/train/'+'/**/*OT*/*nii'))\n",
    "center2_lbl_paths_valid  = sorted(glob(isles_data_root+'center2/valid/'+'/**/*OT*/*nii'))\n",
    "center2_lbl_paths_test   = sorted(glob(isles_data_root+'center2/test/'+'/**/*OT*/*nii'))\n",
    "\n",
    "center3_cbf_paths_train  = sorted(glob(isles_data_root+'center3/train/'+'/**/*CBF*/*.nii'))\n",
    "center3_cbf_paths_valid  = sorted(glob(isles_data_root+'center3/valid/'+'/**/*CBF*/*.nii'))\n",
    "center3_cbf_paths_test   = sorted(glob(isles_data_root+'center3/test/'+'/**/*CBF*/*.nii'))\n",
    "center3_lbl_paths_train  = sorted(glob(isles_data_root+'center3/train/'+'/**/*OT*/*nii'))\n",
    "center3_lbl_paths_valid  = sorted(glob(isles_data_root+'center3/valid/'+'/**/*OT*/*nii'))\n",
    "center3_lbl_paths_test   = sorted(glob(isles_data_root+'center3/test/'+'/**/*OT*/*nii'))\n",
    "\n",
    "center4_cbf_paths_train  = sorted(glob(isles_data_root+'center4/train/'+'/**/*CBF*/*.nii'))\n",
    "center4_cbf_paths_valid  = sorted(glob(isles_data_root+'center4/valid/'+'/**/*CBF*/*.nii'))\n",
    "center4_cbf_paths_test   = sorted(glob(isles_data_root+'center4/test/'+'/**/*CBF*/*.nii'))\n",
    "center4_lbl_paths_train  = sorted(glob(isles_data_root+'center4/train/'+'/**/*OT*/*nii'))\n",
    "center4_lbl_paths_valid  = sorted(glob(isles_data_root+'center4/valid/'+'/**/*OT*/*nii'))\n",
    "center4_lbl_paths_test   = sorted(glob(isles_data_root+'center4/test/'+'/**/*OT*/*nii'))\n",
    "print(\"===============CENTER1====================\")\n",
    "print(len(center1_cbf_paths_train),len(center1_lbl_paths_train))\n",
    "print(len(center1_cbf_paths_valid), len(center1_lbl_paths_valid))\n",
    "print(len(center1_cbf_paths_test),  len(center1_lbl_paths_test))\n",
    "print(\"===============CENTER2====================\")\n",
    "print(len(center2_cbf_paths_train),len(center2_lbl_paths_train))\n",
    "print(len(center2_cbf_paths_valid), len(center2_lbl_paths_valid))\n",
    "print(len(center2_cbf_paths_test),  len(center2_lbl_paths_test))\n",
    "print(\"===============CENTER3====================\")\n",
    "print(len(center3_cbf_paths_train),len(center3_lbl_paths_train))\n",
    "print(len(center3_cbf_paths_valid), len(center3_lbl_paths_valid))\n",
    "print(len(center3_cbf_paths_test),  len(center3_lbl_paths_test))\n",
    "print(\"===============CENTER4====================\")\n",
    "print(len(center4_cbf_paths_train),len(center4_lbl_paths_train))\n",
    "print(len(center4_cbf_paths_valid), len(center4_lbl_paths_valid))\n",
    "print(len(center4_cbf_paths_test),  len(center4_lbl_paths_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70789ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "imtrans = Compose(\n",
    "    [   LoadImage(image_only=True),\n",
    "        #RandScaleIntensity( factors=0.1, prob=0.5),\n",
    "        ScaleIntensity(minv=0.0, maxv=1200),\n",
    "        AddChannel(),\n",
    "        RandRotate90( prob=0.5, spatial_axes=[0, 1]),\n",
    "        RandSpatialCrop((224, 224,1), random_size=False),\n",
    "        EnsureType(),\n",
    "        #Resized\n",
    "    ]\n",
    ")\n",
    "\n",
    "segtrans = Compose(\n",
    "    [   LoadImage(image_only=True),\n",
    "        AddChannel(),\n",
    "        RandRotate90( prob=0.5, spatial_axes=[0, 1]),\n",
    "        RandSpatialCrop((224, 224,1), random_size=False),\n",
    "        EnsureType(),\n",
    "        #Resized\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da6b3895",
   "metadata": {},
   "outputs": [],
   "source": [
    "imtrans_test = Compose(\n",
    "    [   LoadImage(image_only=True),\n",
    "        ScaleIntensity(minv=0.0, maxv=1200),\n",
    "        AddChannel(),\n",
    "        #RandSpatialCrop((224, 224,1), random_size=False), In test we would like to process ALL slices\n",
    "        EnsureType(),\n",
    "        #Resized\n",
    "    ]\n",
    ")\n",
    "\n",
    "segtrans_test = Compose(\n",
    "    [   LoadImage(image_only=True),\n",
    "        AddChannel(),\n",
    "        #RandSpatialCrop((224, 224,1), random_size=False),\n",
    "        EnsureType(),\n",
    "        #Resized\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcc103b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df40802d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 224, 224, 1]) torch.Size([2, 1, 224, 224, 1])\n",
      "(array([    0,     0,     0,     0,     0, 50176,     0,     0,     0,\n",
      "           0]), array([-0.5, -0.4, -0.3, -0.2, -0.1,  0. ,  0.1,  0.2,  0.3,  0.4,  0.5],\n",
      "      dtype=float32))\n",
      "tensor(1200.)\n"
     ]
    }
   ],
   "source": [
    "##################C1\n",
    "c1_ds_train = ArrayDataset(center1_cbf_paths_train, imtrans, center1_lbl_paths_train, segtrans)\n",
    "c1_train_loader   = torch.utils.data.DataLoader(\n",
    "    c1_ds_train, batch_size=batch_size, num_workers=1, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "c1_ds_valid = ArrayDataset(center1_cbf_paths_valid, imtrans, center1_lbl_paths_valid, segtrans)\n",
    "c1_valid_loader   = torch.utils.data.DataLoader(\n",
    "    c1_ds_valid, batch_size=1, num_workers=1, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "c1_ds_test = ArrayDataset(center1_cbf_paths_test, imtrans_test, center1_lbl_paths_test, segtrans_test)\n",
    "c1_test_loader   = torch.utils.data.DataLoader(\n",
    "    c1_ds_test, batch_size=1, num_workers=1, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "\n",
    "##################C2\n",
    "c2_ds_train = ArrayDataset(center2_cbf_paths_train, imtrans, center2_lbl_paths_train, segtrans)\n",
    "c2_train_loader   = torch.utils.data.DataLoader(\n",
    "    c2_ds_train, batch_size=batch_size, num_workers=1, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "c2_ds_valid = ArrayDataset(center2_cbf_paths_valid, imtrans, center2_lbl_paths_valid, segtrans)\n",
    "c2_valid_loader   = torch.utils.data.DataLoader(\n",
    "    c2_ds_valid, batch_size=1, num_workers=1, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "c2_ds_test = ArrayDataset(center2_cbf_paths_test, imtrans_test, center2_lbl_paths_test, segtrans_test)\n",
    "c2_test_loader   = torch.utils.data.DataLoader(\n",
    "    c2_ds_test, batch_size=1, num_workers=1, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "##################C3\n",
    "c3_ds_train = ArrayDataset(center3_cbf_paths_train, imtrans, center3_lbl_paths_train, segtrans)\n",
    "c3_train_loader   = torch.utils.data.DataLoader(\n",
    "    c3_ds_train, batch_size=1, num_workers=1, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "c3_ds_valid = ArrayDataset(center3_cbf_paths_valid, imtrans, center3_lbl_paths_valid, segtrans)\n",
    "c3_valid_loader   = torch.utils.data.DataLoader(\n",
    "    c3_ds_valid, batch_size=1, num_workers=1, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "c3_ds_test = ArrayDataset(center3_cbf_paths_test, imtrans_test, center3_lbl_paths_test, segtrans_test)\n",
    "c3_test_loader   = torch.utils.data.DataLoader(\n",
    "    c3_ds_test, batch_size=1, num_workers=1, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "##################C4\n",
    "c4_ds_train = ArrayDataset(center4_cbf_paths_train, imtrans, center4_lbl_paths_train, segtrans)\n",
    "c4_train_loader   = torch.utils.data.DataLoader(\n",
    "    c4_ds_train, batch_size=batch_size, num_workers=1, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "c4_ds_valid = ArrayDataset(center4_cbf_paths_valid, imtrans, center4_lbl_paths_valid, segtrans)\n",
    "c4_valid_loader   = torch.utils.data.DataLoader(\n",
    "    c4_ds_valid, batch_size=1, num_workers=1, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "c4_ds_test = ArrayDataset(center4_cbf_paths_test, imtrans_test, center4_lbl_paths_test, segtrans_test)\n",
    "c4_test_loader   = torch.utils.data.DataLoader(\n",
    "    c4_ds_test, batch_size=1, num_workers=1, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "\n",
    "im, seg = first(c1_train_loader)\n",
    "print(im.shape, seg.shape)\n",
    "print(np.histogram(seg[0,0,:,:,0]))\n",
    "print(im.max())\n",
    "\n",
    "\n",
    "\n",
    "all_ds_valid = ArrayDataset(center1_cbf_paths_valid+center2_cbf_paths_valid+center3_cbf_paths_valid+center4_cbf_paths_valid,\n",
    "                            imtrans, center1_lbl_paths_valid+center2_lbl_paths_valid+center3_lbl_paths_valid+center4_lbl_paths_valid,\n",
    "                            segtrans)\n",
    "all_valid_loader   = torch.utils.data.DataLoader(\n",
    "    all_ds_valid, batch_size=1, num_workers=1, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "all_ds_test = ArrayDataset(center1_cbf_paths_test+center2_cbf_paths_test+center3_cbf_paths_test+center4_cbf_paths_test,\n",
    "                            imtrans, center1_lbl_paths_test+center2_lbl_paths_test+center3_lbl_paths_test+center4_lbl_paths_test,\n",
    "                            segtrans)\n",
    "all_test_loader   = torch.utils.data.DataLoader(\n",
    "    all_ds_test, batch_size=1, num_workers=1, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddc1142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "im, seg = first(c2_train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dbd5cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe5ac72e070>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(im[0,0,:,:,0],cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d45d06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe5ac4171f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(seg[0,0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8806101",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = np.squeeze([np.random.rand(1)*1e-1, np.random.rand(1)*1e-2, np.random.rand(1)*1e-2, np.random.rand(1)*1e-3, np.random.rand(1)*1e-3])\n",
    "num_epochs = 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1ce6cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfb4661c",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_trans = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold=0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c651195b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "175ba26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = monai.networks.nets.UNet(\n",
    "            spatial_dims=2,\n",
    "            in_channels=1,\n",
    "            out_channels=1,\n",
    "            channels=(16, 32, 64, 128),\n",
    "            strides=(2, 2, 2),\n",
    "            kernel_size = (3,3),\n",
    "            #dropout = 0.2,\n",
    "            num_res_units=2,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54694415",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning_rate = lrs[0] #To comment in the loop\n",
    "learning_rate = 0.00132\n",
    "\n",
    "loss_function = monai.losses.DiceLoss(sigmoid=True)\n",
    "optimizer = torch.optim.Adam(global_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d138038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start a typical PyTorch training\n",
    "val_interval = 2\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = list()\n",
    "metric_values = list()\n",
    "writer = SummaryWriter(comment=\"FEDAVG_LR_\"+str(learning_rate)+\"_BATCH_\"+str(batch_size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8d99b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 224, 224, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_data = next(iter(c1_train_loader))\n",
    "print(batch_data[0].shape)\n",
    "batch_data[0][:,:,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbc87b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 224, 224]) torch.Size([2, 1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "batch_data = next(iter(c1_train_loader))\n",
    "inputs, labels = batch_data[0][:,:,:,:,0].to(device),batch_data[1][:,:,:,:,0].to(device)\n",
    "#torch.swapaxes(batch_data[0][0], 1, -1).to(device), torch.swapaxes(batch_data[1][0], 1, -1).to(device).to(device)\n",
    "print(inputs.shape,labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "102cfdc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (model): Sequential(\n",
       "    (0): ResidualUnit(\n",
       "      (conv): Sequential(\n",
       "        (unit0): Convolution(\n",
       "          (conv): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (adn): ADN(\n",
       "            (N): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (D): Dropout(p=0.0, inplace=False)\n",
       "            (A): PReLU(num_parameters=1)\n",
       "          )\n",
       "        )\n",
       "        (unit1): Convolution(\n",
       "          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (adn): ADN(\n",
       "            (N): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (D): Dropout(p=0.0, inplace=False)\n",
       "            (A): PReLU(num_parameters=1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (residual): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (1): SkipConnection(\n",
       "      (submodule): Sequential(\n",
       "        (0): ResidualUnit(\n",
       "          (conv): Sequential(\n",
       "            (unit0): Convolution(\n",
       "              (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "              (adn): ADN(\n",
       "                (N): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "                (D): Dropout(p=0.0, inplace=False)\n",
       "                (A): PReLU(num_parameters=1)\n",
       "              )\n",
       "            )\n",
       "            (unit1): Convolution(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (adn): ADN(\n",
       "                (N): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "                (D): Dropout(p=0.0, inplace=False)\n",
       "                (A): PReLU(num_parameters=1)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (residual): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "        (1): SkipConnection(\n",
       "          (submodule): Sequential(\n",
       "            (0): ResidualUnit(\n",
       "              (conv): Sequential(\n",
       "                (unit0): Convolution(\n",
       "                  (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "                  (adn): ADN(\n",
       "                    (N): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "                    (D): Dropout(p=0.0, inplace=False)\n",
       "                    (A): PReLU(num_parameters=1)\n",
       "                  )\n",
       "                )\n",
       "                (unit1): Convolution(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  (adn): ADN(\n",
       "                    (N): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "                    (D): Dropout(p=0.0, inplace=False)\n",
       "                    (A): PReLU(num_parameters=1)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (residual): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "            )\n",
       "            (1): SkipConnection(\n",
       "              (submodule): ResidualUnit(\n",
       "                (conv): Sequential(\n",
       "                  (unit0): Convolution(\n",
       "                    (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (adn): ADN(\n",
       "                      (N): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "                      (D): Dropout(p=0.0, inplace=False)\n",
       "                      (A): PReLU(num_parameters=1)\n",
       "                    )\n",
       "                  )\n",
       "                  (unit1): Convolution(\n",
       "                    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (adn): ADN(\n",
       "                      (N): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "                      (D): Dropout(p=0.0, inplace=False)\n",
       "                      (A): PReLU(num_parameters=1)\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "                (residual): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "            )\n",
       "            (2): Sequential(\n",
       "              (0): Convolution(\n",
       "                (conv): ConvTranspose2d(192, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "                (adn): ADN(\n",
       "                  (N): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "                  (D): Dropout(p=0.0, inplace=False)\n",
       "                  (A): PReLU(num_parameters=1)\n",
       "                )\n",
       "              )\n",
       "              (1): ResidualUnit(\n",
       "                (conv): Sequential(\n",
       "                  (unit0): Convolution(\n",
       "                    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (adn): ADN(\n",
       "                      (N): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "                      (D): Dropout(p=0.0, inplace=False)\n",
       "                      (A): PReLU(num_parameters=1)\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "                (residual): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Convolution(\n",
       "            (conv): ConvTranspose2d(64, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "            (adn): ADN(\n",
       "              (N): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "              (D): Dropout(p=0.0, inplace=False)\n",
       "              (A): PReLU(num_parameters=1)\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualUnit(\n",
       "            (conv): Sequential(\n",
       "              (unit0): Convolution(\n",
       "                (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (adn): ADN(\n",
       "                  (N): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "                  (D): Dropout(p=0.0, inplace=False)\n",
       "                  (A): PReLU(num_parameters=1)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (residual): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Convolution(\n",
       "        (conv): ConvTranspose2d(32, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): PReLU(num_parameters=1)\n",
       "        )\n",
       "      )\n",
       "      (1): ResidualUnit(\n",
       "        (conv): Sequential(\n",
       "          (unit0): Convolution(\n",
       "            (conv): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (residual): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3da193b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy weights\n",
    "global_weights = global_model.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20067892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.0278, device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_weights['model.0.conv.unit0.conv.weight'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7aa233c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.0278, device='cuda:0')\n",
      "tensor(0.1607, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n",
      "tensor(-0.6188, device='cuda:0')\n",
      "tensor(-0.1649, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n",
      "tensor(-1.6243, device='cuda:0')\n",
      "tensor(1.2386, device='cuda:0')\n",
      "tensor(7.1315, device='cuda:0')\n",
      "tensor(-0.1906, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n",
      "tensor(3.2600, device='cuda:0')\n",
      "tensor(-0.0917, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n",
      "tensor(-3.7047, device='cuda:0')\n",
      "tensor(-0.2098, device='cuda:0')\n",
      "tensor(1.6758, device='cuda:0')\n",
      "tensor(-0.5321, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n",
      "tensor(1.2918, device='cuda:0')\n",
      "tensor(-0.0452, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n",
      "tensor(-2.1241, device='cuda:0')\n",
      "tensor(0.2131, device='cuda:0')\n",
      "tensor(-0.9343, device='cuda:0')\n",
      "tensor(0.5969, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n",
      "tensor(-2.2816, device='cuda:0')\n",
      "tensor(0.0705, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n",
      "tensor(5.5403, device='cuda:0')\n",
      "tensor(-1.1405, device='cuda:0')\n",
      "tensor(21.5035, device='cuda:0')\n",
      "tensor(0.0058, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n",
      "tensor(0.6697, device='cuda:0')\n",
      "tensor(0.0214, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n",
      "tensor(0.0600, device='cuda:0')\n",
      "tensor(0.3539, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n",
      "tensor(0.1265, device='cuda:0')\n",
      "tensor(-0.0238, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n",
      "tensor(1.1169, device='cuda:0')\n",
      "tensor(0.2890, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n",
      "tensor(0.0472, device='cuda:0')\n",
      "tensor(0.0418, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for key in global_weights:\n",
    "    print(global_weights[key].sum())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2fa9c11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70e61b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing that the model works in one iteration\n",
    "optimizer.zero_grad()\n",
    "outputs = global_model(inputs)\n",
    "loss    = loss_function(outputs, labels)\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3bfa330a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 224, 224])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44b2db1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 224, 224])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fab968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(optimizer_name, cur_lr, model, cur_momentum, weight_decay=1e-4):\n",
    "    if optimizer_name == 'sgd':\n",
    "        optimizer_name = optim.SGD(model.parameters(),\n",
    "                              lr= cur_lr,\n",
    "                              momentum=cur_momentum)\n",
    "    elif optimizer_name == 'adam':\n",
    "        optimizer_name = optim.Adam(model.parameters(),\n",
    "                               lr=cur_lr,\n",
    "                               weight_decay=weight_decay)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3101a8a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "local epoch 1/300\n",
      "local epoch for train_loader 1: 1/300\n",
      "Loss C1: 0.9920086860656738\n",
      "local epoch for train_loader 2: 1/300\n",
      "Loss C2: 0.9817575812339783\n",
      "local epoch for train_loader 4: 1/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9783\n",
      "----------\n",
      "local epoch 2/300\n",
      "local epoch for train_loader 1: 2/300\n",
      "Loss C1: 0.9917690753936768\n",
      "local epoch for train_loader 2: 2/300\n",
      "Loss C2: 0.9786638617515564\n",
      "local epoch for train_loader 4: 2/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9767\n",
      "saved new best metric model\n",
      "current epoch: 2 current mean dice: 0.1399 best mean dice: 0.1399 at epoch 2\n",
      "----------\n",
      "local epoch 3/300\n",
      "local epoch for train_loader 1: 3/300\n",
      "Loss C1: 0.9912644624710083\n",
      "local epoch for train_loader 2: 3/300\n",
      "Loss C2: 0.9765093922615051\n",
      "local epoch for train_loader 4: 3/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9744\n",
      "----------\n",
      "local epoch 4/300\n",
      "local epoch for train_loader 1: 4/300\n",
      "Loss C1: 0.9909108877182007\n",
      "local epoch for train_loader 2: 4/300\n",
      "Loss C2: 0.9741009473800659\n",
      "local epoch for train_loader 4: 4/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9718\n",
      "saved new best metric model\n",
      "current epoch: 4 current mean dice: 0.2377 best mean dice: 0.2377 at epoch 4\n",
      "----------\n",
      "local epoch 5/300\n",
      "local epoch for train_loader 1: 5/300\n",
      "Loss C1: 0.9906500577926636\n",
      "local epoch for train_loader 2: 5/300\n",
      "Loss C2: 0.9702430367469788\n",
      "local epoch for train_loader 4: 5/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9687\n",
      "----------\n",
      "local epoch 6/300\n",
      "local epoch for train_loader 1: 6/300\n",
      "Loss C1: 0.9897767901420593\n",
      "local epoch for train_loader 2: 6/300\n",
      "Loss C2: 0.9692150354385376\n",
      "local epoch for train_loader 4: 6/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9667\n",
      "saved new best metric model\n",
      "current epoch: 6 current mean dice: 0.2478 best mean dice: 0.2478 at epoch 6\n",
      "----------\n",
      "local epoch 7/300\n",
      "local epoch for train_loader 1: 7/300\n",
      "Loss C1: 0.9881494045257568\n",
      "local epoch for train_loader 2: 7/300\n",
      "Loss C2: 0.968914806842804\n",
      "local epoch for train_loader 4: 7/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9653\n",
      "----------\n",
      "local epoch 8/300\n",
      "local epoch for train_loader 1: 8/300\n",
      "Loss C1: 0.9874297976493835\n",
      "local epoch for train_loader 2: 8/300\n",
      "Loss C2: 0.9681910872459412\n",
      "local epoch for train_loader 4: 8/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9645\n",
      "saved new best metric model\n",
      "current epoch: 8 current mean dice: 0.2844 best mean dice: 0.2844 at epoch 8\n",
      "----------\n",
      "local epoch 9/300\n",
      "local epoch for train_loader 1: 9/300\n",
      "Loss C1: 0.9936254024505615\n",
      "local epoch for train_loader 2: 9/300\n",
      "Loss C2: 0.968636691570282\n",
      "local epoch for train_loader 4: 9/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9656\n",
      "----------\n",
      "local epoch 10/300\n",
      "local epoch for train_loader 1: 10/300\n",
      "Loss C1: 0.9872915744781494\n",
      "local epoch for train_loader 2: 10/300\n",
      "Loss C2: 0.967302143573761\n",
      "local epoch for train_loader 4: 10/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9634\n",
      "current epoch: 10 current mean dice: 0.2678 best mean dice: 0.2844 at epoch 8\n",
      "----------\n",
      "local epoch 11/300\n",
      "local epoch for train_loader 1: 11/300\n",
      "Loss C1: 0.9868147969245911\n",
      "local epoch for train_loader 2: 11/300\n",
      "Loss C2: 0.9672679901123047\n",
      "local epoch for train_loader 4: 11/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9630\n",
      "----------\n",
      "local epoch 12/300\n",
      "local epoch for train_loader 1: 12/300\n",
      "Loss C1: 0.9881389737129211\n",
      "local epoch for train_loader 2: 12/300\n",
      "Loss C2: 0.9669014811515808\n",
      "local epoch for train_loader 4: 12/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9624\n",
      "saved new best metric model\n",
      "current epoch: 12 current mean dice: 0.2859 best mean dice: 0.2859 at epoch 12\n",
      "----------\n",
      "local epoch 13/300\n",
      "local epoch for train_loader 1: 13/300\n",
      "Loss C1: 0.985161542892456\n",
      "local epoch for train_loader 2: 13/300\n",
      "Loss C2: 0.9658678770065308\n",
      "local epoch for train_loader 4: 13/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9611\n",
      "----------\n",
      "local epoch 14/300\n",
      "local epoch for train_loader 1: 14/300\n",
      "Loss C1: 0.9950287342071533\n",
      "local epoch for train_loader 2: 14/300\n",
      "Loss C2: 0.9651223421096802\n",
      "local epoch for train_loader 4: 14/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9621\n",
      "saved new best metric model\n",
      "current epoch: 14 current mean dice: 0.3100 best mean dice: 0.3100 at epoch 14\n",
      "----------\n",
      "local epoch 15/300\n",
      "local epoch for train_loader 1: 15/300\n",
      "Loss C1: 0.9846286177635193\n",
      "local epoch for train_loader 2: 15/300\n",
      "Loss C2: 0.9651728272438049\n",
      "local epoch for train_loader 4: 15/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9607\n",
      "----------\n",
      "local epoch 16/300\n",
      "local epoch for train_loader 1: 16/300\n",
      "Loss C1: 0.9841333031654358\n",
      "local epoch for train_loader 2: 16/300\n",
      "Loss C2: 0.9645083546638489\n",
      "local epoch for train_loader 4: 16/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9588\n",
      "saved new best metric model\n",
      "current epoch: 16 current mean dice: 0.3342 best mean dice: 0.3342 at epoch 16\n",
      "----------\n",
      "local epoch 17/300\n",
      "local epoch for train_loader 1: 17/300\n",
      "Loss C1: 0.9846192598342896\n",
      "local epoch for train_loader 2: 17/300\n",
      "Loss C2: 0.963918149471283\n",
      "local epoch for train_loader 4: 17/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9583\n",
      "----------\n",
      "local epoch 18/300\n",
      "local epoch for train_loader 1: 18/300\n",
      "Loss C1: 0.9843703508377075\n",
      "local epoch for train_loader 2: 18/300\n",
      "Loss C2: 0.962111234664917\n",
      "local epoch for train_loader 4: 18/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9576\n",
      "current epoch: 18 current mean dice: 0.3173 best mean dice: 0.3342 at epoch 16\n",
      "----------\n",
      "local epoch 19/300\n",
      "local epoch for train_loader 1: 19/300\n",
      "Loss C1: 0.9831802845001221\n",
      "local epoch for train_loader 2: 19/300\n",
      "Loss C2: 0.9626163244247437\n",
      "local epoch for train_loader 4: 19/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9564\n",
      "----------\n",
      "local epoch 20/300\n",
      "local epoch for train_loader 1: 20/300\n",
      "Loss C1: 0.9878608584403992\n",
      "local epoch for train_loader 2: 20/300\n",
      "Loss C2: 0.9610520005226135\n",
      "local epoch for train_loader 4: 20/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9573\n",
      "current epoch: 20 current mean dice: 0.3293 best mean dice: 0.3342 at epoch 16\n",
      "----------\n",
      "local epoch 21/300\n",
      "local epoch for train_loader 1: 21/300\n",
      "Loss C1: 0.9832977056503296\n",
      "local epoch for train_loader 2: 21/300\n",
      "Loss C2: 0.9602627158164978\n",
      "local epoch for train_loader 4: 21/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9548\n",
      "----------\n",
      "local epoch 22/300\n",
      "local epoch for train_loader 1: 22/300\n",
      "Loss C1: 0.9823825359344482\n",
      "local epoch for train_loader 2: 22/300\n",
      "Loss C2: 0.9607226848602295\n",
      "local epoch for train_loader 4: 22/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9541\n",
      "current epoch: 22 current mean dice: 0.3011 best mean dice: 0.3342 at epoch 16\n",
      "----------\n",
      "local epoch 23/300\n",
      "local epoch for train_loader 1: 23/300\n",
      "Loss C1: 0.9820066094398499\n",
      "local epoch for train_loader 2: 23/300\n",
      "Loss C2: 0.9587122201919556\n",
      "local epoch for train_loader 4: 23/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9529\n",
      "----------\n",
      "local epoch 24/300\n",
      "local epoch for train_loader 1: 24/300\n",
      "Loss C1: 0.9816145300865173\n",
      "local epoch for train_loader 2: 24/300\n",
      "Loss C2: 0.9587801098823547\n",
      "local epoch for train_loader 4: 24/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9519\n",
      "saved new best metric model\n",
      "current epoch: 24 current mean dice: 0.3355 best mean dice: 0.3355 at epoch 24\n",
      "----------\n",
      "local epoch 25/300\n",
      "local epoch for train_loader 1: 25/300\n",
      "Loss C1: 0.9813477396965027\n",
      "local epoch for train_loader 2: 25/300\n",
      "Loss C2: 0.9567656517028809\n",
      "local epoch for train_loader 4: 25/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9504\n",
      "----------\n",
      "local epoch 26/300\n",
      "local epoch for train_loader 1: 26/300\n",
      "Loss C1: 0.9806588888168335\n",
      "local epoch for train_loader 2: 26/300\n",
      "Loss C2: 0.9563586711883545\n",
      "local epoch for train_loader 4: 26/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9496\n",
      "saved new best metric model\n",
      "current epoch: 26 current mean dice: 0.3473 best mean dice: 0.3473 at epoch 26\n",
      "----------\n",
      "local epoch 27/300\n",
      "local epoch for train_loader 1: 27/300\n",
      "Loss C1: 0.9804918766021729\n",
      "local epoch for train_loader 2: 27/300\n",
      "Loss C2: 0.9548127055168152\n",
      "local epoch for train_loader 4: 27/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9485\n",
      "----------\n",
      "local epoch 28/300\n",
      "local epoch for train_loader 1: 28/300\n",
      "Loss C1: 0.9799285531044006\n",
      "local epoch for train_loader 2: 28/300\n",
      "Loss C2: 0.9537315964698792\n",
      "local epoch for train_loader 4: 28/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9475\n",
      "current epoch: 28 current mean dice: 0.3403 best mean dice: 0.3473 at epoch 26\n",
      "----------\n",
      "local epoch 29/300\n",
      "local epoch for train_loader 1: 29/300\n",
      "Loss C1: 0.9793456792831421\n",
      "local epoch for train_loader 2: 29/300\n",
      "Loss C2: 0.9555410146713257\n",
      "local epoch for train_loader 4: 29/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9478\n",
      "----------\n",
      "local epoch 30/300\n",
      "local epoch for train_loader 1: 30/300\n",
      "Loss C1: 0.978890061378479\n",
      "local epoch for train_loader 2: 30/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss C2: 0.9518834948539734\n",
      "local epoch for train_loader 4: 30/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9457\n",
      "current epoch: 30 current mean dice: 0.3271 best mean dice: 0.3473 at epoch 26\n",
      "----------\n",
      "local epoch 31/300\n",
      "local epoch for train_loader 1: 31/300\n",
      "Loss C1: 0.978908360004425\n",
      "local epoch for train_loader 2: 31/300\n",
      "Loss C2: 0.9514461159706116\n",
      "local epoch for train_loader 4: 31/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9448\n",
      "----------\n",
      "local epoch 32/300\n",
      "local epoch for train_loader 1: 32/300\n",
      "Loss C1: 0.9775288701057434\n",
      "local epoch for train_loader 2: 32/300\n",
      "Loss C2: 0.9498967528343201\n",
      "local epoch for train_loader 4: 32/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9427\n",
      "current epoch: 32 current mean dice: 0.3447 best mean dice: 0.3473 at epoch 26\n",
      "----------\n",
      "local epoch 33/300\n",
      "local epoch for train_loader 1: 33/300\n",
      "Loss C1: 0.9772849082946777\n",
      "local epoch for train_loader 2: 33/300\n",
      "Loss C2: 0.9482881426811218\n",
      "local epoch for train_loader 4: 33/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9418\n",
      "----------\n",
      "local epoch 34/300\n",
      "local epoch for train_loader 1: 34/300\n",
      "Loss C1: 0.9762481451034546\n",
      "local epoch for train_loader 2: 34/300\n",
      "Loss C2: 0.9483984112739563\n",
      "local epoch for train_loader 4: 34/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9405\n",
      "saved new best metric model\n",
      "current epoch: 34 current mean dice: 0.3478 best mean dice: 0.3478 at epoch 34\n",
      "----------\n",
      "local epoch 35/300\n",
      "local epoch for train_loader 1: 35/300\n",
      "Loss C1: 0.9766384363174438\n",
      "local epoch for train_loader 2: 35/300\n",
      "Loss C2: 0.9459725022315979\n",
      "local epoch for train_loader 4: 35/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9387\n",
      "----------\n",
      "local epoch 36/300\n",
      "local epoch for train_loader 1: 36/300\n",
      "Loss C1: 0.9757825136184692\n",
      "local epoch for train_loader 2: 36/300\n",
      "Loss C2: 0.9447078704833984\n",
      "local epoch for train_loader 4: 36/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9382\n",
      "saved new best metric model\n",
      "current epoch: 36 current mean dice: 0.3549 best mean dice: 0.3549 at epoch 36\n",
      "----------\n",
      "local epoch 37/300\n",
      "local epoch for train_loader 1: 37/300\n",
      "Loss C1: 0.9752865433692932\n",
      "local epoch for train_loader 2: 37/300\n",
      "Loss C2: 0.9424692988395691\n",
      "local epoch for train_loader 4: 37/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9354\n",
      "----------\n",
      "local epoch 38/300\n",
      "local epoch for train_loader 1: 38/300\n",
      "Loss C1: 0.9745949506759644\n",
      "local epoch for train_loader 2: 38/300\n",
      "Loss C2: 0.9432734847068787\n",
      "local epoch for train_loader 4: 38/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9360\n",
      "current epoch: 38 current mean dice: 0.3441 best mean dice: 0.3549 at epoch 36\n",
      "----------\n",
      "local epoch 39/300\n",
      "local epoch for train_loader 1: 39/300\n",
      "Loss C1: 0.973877489566803\n",
      "local epoch for train_loader 2: 39/300\n",
      "Loss C2: 0.9401817917823792\n",
      "local epoch for train_loader 4: 39/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9334\n",
      "----------\n",
      "local epoch 40/300\n",
      "local epoch for train_loader 1: 40/300\n",
      "Loss C1: 0.9734141826629639\n",
      "local epoch for train_loader 2: 40/300\n",
      "Loss C2: 0.9394745826721191\n",
      "local epoch for train_loader 4: 40/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9316\n",
      "saved new best metric model\n",
      "current epoch: 40 current mean dice: 0.3911 best mean dice: 0.3911 at epoch 40\n",
      "----------\n",
      "local epoch 41/300\n",
      "local epoch for train_loader 1: 41/300\n",
      "Loss C1: 0.972509503364563\n",
      "local epoch for train_loader 2: 41/300\n",
      "Loss C2: 0.938569962978363\n",
      "local epoch for train_loader 4: 41/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9301\n",
      "----------\n",
      "local epoch 42/300\n",
      "local epoch for train_loader 1: 42/300\n",
      "Loss C1: 0.972370445728302\n",
      "local epoch for train_loader 2: 42/300\n",
      "Loss C2: 0.9340690970420837\n",
      "local epoch for train_loader 4: 42/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9279\n",
      "current epoch: 42 current mean dice: 0.3792 best mean dice: 0.3911 at epoch 40\n",
      "----------\n",
      "local epoch 43/300\n",
      "local epoch for train_loader 1: 43/300\n",
      "Loss C1: 0.9719319343566895\n",
      "local epoch for train_loader 2: 43/300\n",
      "Loss C2: 0.936357855796814\n",
      "local epoch for train_loader 4: 43/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9275\n",
      "----------\n",
      "local epoch 44/300\n",
      "local epoch for train_loader 1: 44/300\n",
      "Loss C1: 0.9708306193351746\n",
      "local epoch for train_loader 2: 44/300\n",
      "Loss C2: 0.9299049973487854\n",
      "local epoch for train_loader 4: 44/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9241\n",
      "current epoch: 44 current mean dice: 0.3763 best mean dice: 0.3911 at epoch 40\n",
      "----------\n",
      "local epoch 45/300\n",
      "local epoch for train_loader 1: 45/300\n",
      "Loss C1: 0.9685409665107727\n",
      "local epoch for train_loader 2: 45/300\n",
      "Loss C2: 0.9313845038414001\n",
      "local epoch for train_loader 4: 45/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9229\n",
      "----------\n",
      "local epoch 46/300\n",
      "local epoch for train_loader 1: 46/300\n",
      "Loss C1: 0.9704459309577942\n",
      "local epoch for train_loader 2: 46/300\n",
      "Loss C2: 0.929658830165863\n",
      "local epoch for train_loader 4: 46/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9217\n",
      "current epoch: 46 current mean dice: 0.3377 best mean dice: 0.3911 at epoch 40\n",
      "----------\n",
      "local epoch 47/300\n",
      "local epoch for train_loader 1: 47/300\n",
      "Loss C1: 0.9684687852859497\n",
      "local epoch for train_loader 2: 47/300\n",
      "Loss C2: 0.9275872707366943\n",
      "local epoch for train_loader 4: 47/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9195\n",
      "----------\n",
      "local epoch 48/300\n",
      "local epoch for train_loader 1: 48/300\n",
      "Loss C1: 0.969632625579834\n",
      "local epoch for train_loader 2: 48/300\n",
      "Loss C2: 0.9265495538711548\n",
      "local epoch for train_loader 4: 48/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9177\n",
      "current epoch: 48 current mean dice: 0.3623 best mean dice: 0.3911 at epoch 40\n",
      "----------\n",
      "local epoch 49/300\n",
      "local epoch for train_loader 1: 49/300\n",
      "Loss C1: 0.9665601849555969\n",
      "local epoch for train_loader 2: 49/300\n",
      "Loss C2: 0.9201629161834717\n",
      "local epoch for train_loader 4: 49/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9155\n",
      "----------\n",
      "local epoch 50/300\n",
      "local epoch for train_loader 1: 50/300\n",
      "Loss C1: 0.9705962538719177\n",
      "local epoch for train_loader 2: 50/300\n",
      "Loss C2: 0.9220595359802246\n",
      "local epoch for train_loader 4: 50/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9141\n",
      "current epoch: 50 current mean dice: 0.3787 best mean dice: 0.3911 at epoch 40\n",
      "----------\n",
      "local epoch 51/300\n",
      "local epoch for train_loader 1: 51/300\n",
      "Loss C1: 0.9713753461837769\n",
      "local epoch for train_loader 2: 51/300\n",
      "Loss C2: 0.9169433116912842\n",
      "local epoch for train_loader 4: 51/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9114\n",
      "----------\n",
      "local epoch 52/300\n",
      "local epoch for train_loader 1: 52/300\n",
      "Loss C1: 0.9942787885665894\n",
      "local epoch for train_loader 2: 52/300\n",
      "Loss C2: 0.9162594079971313\n",
      "local epoch for train_loader 4: 52/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9119\n",
      "saved new best metric model\n",
      "current epoch: 52 current mean dice: 0.4411 best mean dice: 0.4411 at epoch 52\n",
      "----------\n",
      "local epoch 53/300\n",
      "local epoch for train_loader 1: 53/300\n",
      "Loss C1: 0.9652653336524963\n",
      "local epoch for train_loader 2: 53/300\n",
      "Loss C2: 0.9132067561149597\n",
      "local epoch for train_loader 4: 53/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9105\n",
      "----------\n",
      "local epoch 54/300\n",
      "local epoch for train_loader 1: 54/300\n",
      "Loss C1: 0.9912049174308777\n",
      "local epoch for train_loader 2: 54/300\n",
      "Loss C2: 0.9086505174636841\n",
      "local epoch for train_loader 4: 54/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9071\n",
      "current epoch: 54 current mean dice: 0.4094 best mean dice: 0.4411 at epoch 52\n",
      "----------\n",
      "local epoch 55/300\n",
      "local epoch for train_loader 1: 55/300\n",
      "Loss C1: 0.966199517250061\n",
      "local epoch for train_loader 2: 55/300\n",
      "Loss C2: 0.9091576337814331\n",
      "local epoch for train_loader 4: 55/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9035\n",
      "----------\n",
      "local epoch 56/300\n",
      "local epoch for train_loader 1: 56/300\n",
      "Loss C1: 0.9645382165908813\n",
      "local epoch for train_loader 2: 56/300\n",
      "Loss C2: 0.9087352156639099\n",
      "local epoch for train_loader 4: 56/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.9028\n",
      "current epoch: 56 current mean dice: 0.4089 best mean dice: 0.4411 at epoch 52\n",
      "----------\n",
      "local epoch 57/300\n",
      "local epoch for train_loader 1: 57/300\n",
      "Loss C1: 0.9613209366798401\n",
      "local epoch for train_loader 2: 57/300\n",
      "Loss C2: 0.9047735929489136\n",
      "local epoch for train_loader 4: 57/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8999\n",
      "----------\n",
      "local epoch 58/300\n",
      "local epoch for train_loader 1: 58/300\n",
      "Loss C1: 0.9622385501861572\n",
      "local epoch for train_loader 2: 58/300\n",
      "Loss C2: 0.9067997932434082\n",
      "local epoch for train_loader 4: 58/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8973\n",
      "current epoch: 58 current mean dice: 0.4136 best mean dice: 0.4411 at epoch 52\n",
      "----------\n",
      "local epoch 59/300\n",
      "local epoch for train_loader 1: 59/300\n",
      "Loss C1: 0.9635005593299866\n",
      "local epoch for train_loader 2: 59/300\n",
      "Loss C2: 0.9084603190422058\n",
      "local epoch for train_loader 4: 59/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8960\n",
      "----------\n",
      "local epoch 60/300\n",
      "local epoch for train_loader 1: 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss C1: 0.9616379737854004\n",
      "local epoch for train_loader 2: 60/300\n",
      "Loss C2: 0.8941878080368042\n",
      "local epoch for train_loader 4: 60/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8923\n",
      "saved new best metric model\n",
      "current epoch: 60 current mean dice: 0.4463 best mean dice: 0.4463 at epoch 60\n",
      "----------\n",
      "local epoch 61/300\n",
      "local epoch for train_loader 1: 61/300\n",
      "Loss C1: 0.9600076079368591\n",
      "local epoch for train_loader 2: 61/300\n",
      "Loss C2: 0.9016867280006409\n",
      "local epoch for train_loader 4: 61/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8910\n",
      "----------\n",
      "local epoch 62/300\n",
      "local epoch for train_loader 1: 62/300\n",
      "Loss C1: 0.9635385274887085\n",
      "local epoch for train_loader 2: 62/300\n",
      "Loss C2: 0.8964612483978271\n",
      "local epoch for train_loader 4: 62/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8896\n",
      "current epoch: 62 current mean dice: 0.4226 best mean dice: 0.4463 at epoch 60\n",
      "----------\n",
      "local epoch 63/300\n",
      "local epoch for train_loader 1: 63/300\n",
      "Loss C1: 0.9575796127319336\n",
      "local epoch for train_loader 2: 63/300\n",
      "Loss C2: 0.8938170075416565\n",
      "local epoch for train_loader 4: 63/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8853\n",
      "----------\n",
      "local epoch 64/300\n",
      "local epoch for train_loader 1: 64/300\n",
      "Loss C1: 0.9669737219810486\n",
      "local epoch for train_loader 2: 64/300\n",
      "Loss C2: 0.894329309463501\n",
      "local epoch for train_loader 4: 64/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8884\n",
      "current epoch: 64 current mean dice: 0.4421 best mean dice: 0.4463 at epoch 60\n",
      "----------\n",
      "local epoch 65/300\n",
      "local epoch for train_loader 1: 65/300\n",
      "Loss C1: 0.9535810947418213\n",
      "local epoch for train_loader 2: 65/300\n",
      "Loss C2: 0.8840810656547546\n",
      "local epoch for train_loader 4: 65/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8803\n",
      "----------\n",
      "local epoch 66/300\n",
      "local epoch for train_loader 1: 66/300\n",
      "Loss C1: 0.9755820631980896\n",
      "local epoch for train_loader 2: 66/300\n",
      "Loss C2: 0.8804168701171875\n",
      "local epoch for train_loader 4: 66/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8814\n",
      "current epoch: 66 current mean dice: 0.4215 best mean dice: 0.4463 at epoch 60\n",
      "----------\n",
      "local epoch 67/300\n",
      "local epoch for train_loader 1: 67/300\n",
      "Loss C1: 0.9586083292961121\n",
      "local epoch for train_loader 2: 67/300\n",
      "Loss C2: 0.8831495642662048\n",
      "local epoch for train_loader 4: 67/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8813\n",
      "----------\n",
      "local epoch 68/300\n",
      "local epoch for train_loader 1: 68/300\n",
      "Loss C1: 0.9498676061630249\n",
      "local epoch for train_loader 2: 68/300\n",
      "Loss C2: 0.8758954405784607\n",
      "local epoch for train_loader 4: 68/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8745\n",
      "saved new best metric model\n",
      "current epoch: 68 current mean dice: 0.4665 best mean dice: 0.4665 at epoch 68\n",
      "----------\n",
      "local epoch 69/300\n",
      "local epoch for train_loader 1: 69/300\n",
      "Loss C1: 0.9671128988265991\n",
      "local epoch for train_loader 2: 69/300\n",
      "Loss C2: 0.8712995648384094\n",
      "local epoch for train_loader 4: 69/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8786\n",
      "----------\n",
      "local epoch 70/300\n",
      "local epoch for train_loader 1: 70/300\n",
      "Loss C1: 0.9545345306396484\n",
      "local epoch for train_loader 2: 70/300\n",
      "Loss C2: 0.8741970658302307\n",
      "local epoch for train_loader 4: 70/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8719\n",
      "current epoch: 70 current mean dice: 0.4318 best mean dice: 0.4665 at epoch 68\n",
      "----------\n",
      "local epoch 71/300\n",
      "local epoch for train_loader 1: 71/300\n",
      "Loss C1: 0.9945093989372253\n",
      "local epoch for train_loader 2: 71/300\n",
      "Loss C2: 0.885182797908783\n",
      "local epoch for train_loader 4: 71/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8686\n",
      "----------\n",
      "local epoch 72/300\n",
      "local epoch for train_loader 1: 72/300\n",
      "Loss C1: 0.98319011926651\n",
      "local epoch for train_loader 2: 72/300\n",
      "Loss C2: 0.8673598766326904\n",
      "local epoch for train_loader 4: 72/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8670\n",
      "current epoch: 72 current mean dice: 0.4586 best mean dice: 0.4665 at epoch 68\n",
      "----------\n",
      "local epoch 73/300\n",
      "local epoch for train_loader 1: 73/300\n",
      "Loss C1: 0.9911195635795593\n",
      "local epoch for train_loader 2: 73/300\n",
      "Loss C2: 0.8682023882865906\n",
      "local epoch for train_loader 4: 73/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8643\n",
      "----------\n",
      "local epoch 74/300\n",
      "local epoch for train_loader 1: 74/300\n",
      "Loss C1: 0.9784826636314392\n",
      "local epoch for train_loader 2: 74/300\n",
      "Loss C2: 0.8636620044708252\n",
      "local epoch for train_loader 4: 74/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8632\n",
      "current epoch: 74 current mean dice: 0.4406 best mean dice: 0.4665 at epoch 68\n",
      "----------\n",
      "local epoch 75/300\n",
      "local epoch for train_loader 1: 75/300\n",
      "Loss C1: 0.9804486036300659\n",
      "local epoch for train_loader 2: 75/300\n",
      "Loss C2: 0.8803597688674927\n",
      "local epoch for train_loader 4: 75/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8649\n",
      "----------\n",
      "local epoch 76/300\n",
      "local epoch for train_loader 1: 76/300\n",
      "Loss C1: 0.9965431094169617\n",
      "local epoch for train_loader 2: 76/300\n",
      "Loss C2: 0.8532718420028687\n",
      "local epoch for train_loader 4: 76/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8606\n",
      "saved new best metric model\n",
      "current epoch: 76 current mean dice: 0.4802 best mean dice: 0.4802 at epoch 76\n",
      "----------\n",
      "local epoch 77/300\n",
      "local epoch for train_loader 1: 77/300\n",
      "Loss C1: 0.9927709698677063\n",
      "local epoch for train_loader 2: 77/300\n",
      "Loss C2: 0.8464159369468689\n",
      "local epoch for train_loader 4: 77/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8612\n",
      "----------\n",
      "local epoch 78/300\n",
      "local epoch for train_loader 1: 78/300\n",
      "Loss C1: 0.943104088306427\n",
      "local epoch for train_loader 2: 78/300\n",
      "Loss C2: 0.8774837255477905\n",
      "local epoch for train_loader 4: 78/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8559\n",
      "current epoch: 78 current mean dice: 0.4199 best mean dice: 0.4802 at epoch 76\n",
      "----------\n",
      "local epoch 79/300\n",
      "local epoch for train_loader 1: 79/300\n",
      "Loss C1: 0.9962693452835083\n",
      "local epoch for train_loader 2: 79/300\n",
      "Loss C2: 0.8439661264419556\n",
      "local epoch for train_loader 4: 79/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8526\n",
      "----------\n",
      "local epoch 80/300\n",
      "local epoch for train_loader 1: 80/300\n",
      "Loss C1: 0.9363380670547485\n",
      "local epoch for train_loader 2: 80/300\n",
      "Loss C2: 0.8528670072555542\n",
      "local epoch for train_loader 4: 80/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8542\n",
      "current epoch: 80 current mean dice: 0.4212 best mean dice: 0.4802 at epoch 76\n",
      "----------\n",
      "local epoch 81/300\n",
      "local epoch for train_loader 1: 81/300\n",
      "Loss C1: 0.9869303107261658\n",
      "local epoch for train_loader 2: 81/300\n",
      "Loss C2: 0.843073308467865\n",
      "local epoch for train_loader 4: 81/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8470\n",
      "----------\n",
      "local epoch 82/300\n",
      "local epoch for train_loader 1: 82/300\n",
      "Loss C1: 0.9741272330284119\n",
      "local epoch for train_loader 2: 82/300\n",
      "Loss C2: 0.8310863971710205\n",
      "local epoch for train_loader 4: 82/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8517\n",
      "current epoch: 82 current mean dice: 0.4572 best mean dice: 0.4802 at epoch 76\n",
      "----------\n",
      "local epoch 83/300\n",
      "local epoch for train_loader 1: 83/300\n",
      "Loss C1: 0.9978333711624146\n",
      "local epoch for train_loader 2: 83/300\n",
      "Loss C2: 0.8606396317481995\n",
      "local epoch for train_loader 4: 83/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8449\n",
      "----------\n",
      "local epoch 84/300\n",
      "local epoch for train_loader 1: 84/300\n",
      "Loss C1: 0.9360406398773193\n",
      "local epoch for train_loader 2: 84/300\n",
      "Loss C2: 0.8280625343322754\n",
      "local epoch for train_loader 4: 84/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8390\n",
      "current epoch: 84 current mean dice: 0.4420 best mean dice: 0.4802 at epoch 76\n",
      "----------\n",
      "local epoch 85/300\n",
      "local epoch for train_loader 1: 85/300\n",
      "Loss C1: 0.9678876399993896\n",
      "local epoch for train_loader 2: 85/300\n",
      "Loss C2: 0.8424675464630127\n",
      "local epoch for train_loader 4: 85/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8380\n",
      "----------\n",
      "local epoch 86/300\n",
      "local epoch for train_loader 1: 86/300\n",
      "Loss C1: 0.9989483952522278\n",
      "local epoch for train_loader 2: 86/300\n",
      "Loss C2: 0.9999561905860901\n",
      "local epoch for train_loader 4: 86/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8616\n",
      "current epoch: 86 current mean dice: 0.4181 best mean dice: 0.4802 at epoch 76\n",
      "----------\n",
      "local epoch 87/300\n",
      "local epoch for train_loader 1: 87/300\n",
      "Loss C1: 0.9627048373222351\n",
      "local epoch for train_loader 2: 87/300\n",
      "Loss C2: 0.8511301279067993\n",
      "local epoch for train_loader 4: 87/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8468\n",
      "----------\n",
      "local epoch 88/300\n",
      "local epoch for train_loader 1: 88/300\n",
      "Loss C1: 0.9817638397216797\n",
      "local epoch for train_loader 2: 88/300\n",
      "Loss C2: 0.8462615609169006\n",
      "local epoch for train_loader 4: 88/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8370\n",
      "current epoch: 88 current mean dice: 0.4171 best mean dice: 0.4802 at epoch 76\n",
      "----------\n",
      "local epoch 89/300\n",
      "local epoch for train_loader 1: 89/300\n",
      "Loss C1: 0.9258008003234863\n",
      "local epoch for train_loader 2: 89/300\n",
      "Loss C2: 0.7972543239593506\n",
      "local epoch for train_loader 4: 89/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss C4: 1.0\n",
      "train_loss: 0.8251\n",
      "----------\n",
      "local epoch 90/300\n",
      "local epoch for train_loader 1: 90/300\n",
      "Loss C1: 0.995050847530365\n",
      "local epoch for train_loader 2: 90/300\n",
      "Loss C2: 0.8490175008773804\n",
      "local epoch for train_loader 4: 90/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8306\n",
      "current epoch: 90 current mean dice: 0.4776 best mean dice: 0.4802 at epoch 76\n",
      "----------\n",
      "local epoch 91/300\n",
      "local epoch for train_loader 1: 91/300\n",
      "Loss C1: 0.9748902320861816\n",
      "local epoch for train_loader 2: 91/300\n",
      "Loss C2: 0.8200487494468689\n",
      "local epoch for train_loader 4: 91/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8237\n",
      "----------\n",
      "local epoch 92/300\n",
      "local epoch for train_loader 1: 92/300\n",
      "Loss C1: 0.9845830798149109\n",
      "local epoch for train_loader 2: 92/300\n",
      "Loss C2: 0.7869884967803955\n",
      "local epoch for train_loader 4: 92/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8239\n",
      "saved new best metric model\n",
      "current epoch: 92 current mean dice: 0.4979 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 93/300\n",
      "local epoch for train_loader 1: 93/300\n",
      "Loss C1: 0.9297149181365967\n",
      "local epoch for train_loader 2: 93/300\n",
      "Loss C2: 0.8149325847625732\n",
      "local epoch for train_loader 4: 93/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8213\n",
      "----------\n",
      "local epoch 94/300\n",
      "local epoch for train_loader 1: 94/300\n",
      "Loss C1: 0.9980192184448242\n",
      "local epoch for train_loader 2: 94/300\n",
      "Loss C2: 0.7949377298355103\n",
      "local epoch for train_loader 4: 94/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8146\n",
      "current epoch: 94 current mean dice: 0.4849 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 95/300\n",
      "local epoch for train_loader 1: 95/300\n",
      "Loss C1: 0.9453684687614441\n",
      "local epoch for train_loader 2: 95/300\n",
      "Loss C2: 0.8095095157623291\n",
      "local epoch for train_loader 4: 95/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8137\n",
      "----------\n",
      "local epoch 96/300\n",
      "local epoch for train_loader 1: 96/300\n",
      "Loss C1: 0.9227662086486816\n",
      "local epoch for train_loader 2: 96/300\n",
      "Loss C2: 0.827288031578064\n",
      "local epoch for train_loader 4: 96/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8084\n",
      "current epoch: 96 current mean dice: 0.4843 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 97/300\n",
      "local epoch for train_loader 1: 97/300\n",
      "Loss C1: 0.9951058030128479\n",
      "local epoch for train_loader 2: 97/300\n",
      "Loss C2: 0.7864528298377991\n",
      "local epoch for train_loader 4: 97/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8135\n",
      "----------\n",
      "local epoch 98/300\n",
      "local epoch for train_loader 1: 98/300\n",
      "Loss C1: 0.998148500919342\n",
      "local epoch for train_loader 2: 98/300\n",
      "Loss C2: 0.8141447305679321\n",
      "local epoch for train_loader 4: 98/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8117\n",
      "current epoch: 98 current mean dice: 0.4883 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 99/300\n",
      "local epoch for train_loader 1: 99/300\n",
      "Loss C1: 0.9705743789672852\n",
      "local epoch for train_loader 2: 99/300\n",
      "Loss C2: 0.8241890668869019\n",
      "local epoch for train_loader 4: 99/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8115\n",
      "----------\n",
      "local epoch 100/300\n",
      "local epoch for train_loader 1: 100/300\n",
      "Loss C1: 0.9304978251457214\n",
      "local epoch for train_loader 2: 100/300\n",
      "Loss C2: 0.8197581171989441\n",
      "local epoch for train_loader 4: 100/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8124\n",
      "current epoch: 100 current mean dice: 0.4303 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 101/300\n",
      "local epoch for train_loader 1: 101/300\n",
      "Loss C1: 0.9725134372711182\n",
      "local epoch for train_loader 2: 101/300\n",
      "Loss C2: 0.8424860239028931\n",
      "local epoch for train_loader 4: 101/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8056\n",
      "----------\n",
      "local epoch 102/300\n",
      "local epoch for train_loader 1: 102/300\n",
      "Loss C1: 0.996589720249176\n",
      "local epoch for train_loader 2: 102/300\n",
      "Loss C2: 0.7522408366203308\n",
      "local epoch for train_loader 4: 102/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8030\n",
      "current epoch: 102 current mean dice: 0.4783 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 103/300\n",
      "local epoch for train_loader 1: 103/300\n",
      "Loss C1: 0.9831250905990601\n",
      "local epoch for train_loader 2: 103/300\n",
      "Loss C2: 0.7780058979988098\n",
      "local epoch for train_loader 4: 103/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8047\n",
      "----------\n",
      "local epoch 104/300\n",
      "local epoch for train_loader 1: 104/300\n",
      "Loss C1: 0.970598578453064\n",
      "local epoch for train_loader 2: 104/300\n",
      "Loss C2: 0.790534257888794\n",
      "local epoch for train_loader 4: 104/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8125\n",
      "current epoch: 104 current mean dice: 0.4711 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 105/300\n",
      "local epoch for train_loader 1: 105/300\n",
      "Loss C1: 0.9988965392112732\n",
      "local epoch for train_loader 2: 105/300\n",
      "Loss C2: 0.8417163491249084\n",
      "local epoch for train_loader 4: 105/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.8104\n",
      "----------\n",
      "local epoch 106/300\n",
      "local epoch for train_loader 1: 106/300\n",
      "Loss C1: 0.9127550721168518\n",
      "local epoch for train_loader 2: 106/300\n",
      "Loss C2: 0.8010492324829102\n",
      "local epoch for train_loader 4: 106/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7932\n",
      "current epoch: 106 current mean dice: 0.4543 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 107/300\n",
      "local epoch for train_loader 1: 107/300\n",
      "Loss C1: 0.992236316204071\n",
      "local epoch for train_loader 2: 107/300\n",
      "Loss C2: 0.7448619604110718\n",
      "local epoch for train_loader 4: 107/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7931\n",
      "----------\n",
      "local epoch 108/300\n",
      "local epoch for train_loader 1: 108/300\n",
      "Loss C1: 0.9087488651275635\n",
      "local epoch for train_loader 2: 108/300\n",
      "Loss C2: 0.7642266154289246\n",
      "local epoch for train_loader 4: 108/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7909\n",
      "current epoch: 108 current mean dice: 0.4735 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 109/300\n",
      "local epoch for train_loader 1: 109/300\n",
      "Loss C1: 0.9980987906455994\n",
      "local epoch for train_loader 2: 109/300\n",
      "Loss C2: 0.7917850017547607\n",
      "local epoch for train_loader 4: 109/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7822\n",
      "----------\n",
      "local epoch 110/300\n",
      "local epoch for train_loader 1: 110/300\n",
      "Loss C1: 0.9638869166374207\n",
      "local epoch for train_loader 2: 110/300\n",
      "Loss C2: 0.7967250347137451\n",
      "local epoch for train_loader 4: 110/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7932\n",
      "current epoch: 110 current mean dice: 0.4836 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 111/300\n",
      "local epoch for train_loader 1: 111/300\n",
      "Loss C1: 0.9984065294265747\n",
      "local epoch for train_loader 2: 111/300\n",
      "Loss C2: 0.8092643022537231\n",
      "local epoch for train_loader 4: 111/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7970\n",
      "----------\n",
      "local epoch 112/300\n",
      "local epoch for train_loader 1: 112/300\n",
      "Loss C1: 0.9631368517875671\n",
      "local epoch for train_loader 2: 112/300\n",
      "Loss C2: 0.800273060798645\n",
      "local epoch for train_loader 4: 112/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7899\n",
      "current epoch: 112 current mean dice: 0.4655 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 113/300\n",
      "local epoch for train_loader 1: 113/300\n",
      "Loss C1: 0.9728390574455261\n",
      "local epoch for train_loader 2: 113/300\n",
      "Loss C2: 0.7073215246200562\n",
      "local epoch for train_loader 4: 113/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7724\n",
      "----------\n",
      "local epoch 114/300\n",
      "local epoch for train_loader 1: 114/300\n",
      "Loss C1: 0.9703989624977112\n",
      "local epoch for train_loader 2: 114/300\n",
      "Loss C2: 0.8055319786071777\n",
      "local epoch for train_loader 4: 114/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7752\n",
      "current epoch: 114 current mean dice: 0.4710 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 115/300\n",
      "local epoch for train_loader 1: 115/300\n",
      "Loss C1: 0.9792842864990234\n",
      "local epoch for train_loader 2: 115/300\n",
      "Loss C2: 0.7220789790153503\n",
      "local epoch for train_loader 4: 115/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7720\n",
      "----------\n",
      "local epoch 116/300\n",
      "local epoch for train_loader 1: 116/300\n",
      "Loss C1: 0.9702662825584412\n",
      "local epoch for train_loader 2: 116/300\n",
      "Loss C2: 0.8530567288398743\n",
      "local epoch for train_loader 4: 116/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7749\n",
      "current epoch: 116 current mean dice: 0.4856 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 117/300\n",
      "local epoch for train_loader 1: 117/300\n",
      "Loss C1: 0.9088300466537476\n",
      "local epoch for train_loader 2: 117/300\n",
      "Loss C2: 0.7621492147445679\n",
      "local epoch for train_loader 4: 117/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7878\n",
      "----------\n",
      "local epoch 118/300\n",
      "local epoch for train_loader 1: 118/300\n",
      "Loss C1: 0.996996283531189\n",
      "local epoch for train_loader 2: 118/300\n",
      "Loss C2: 0.7575459480285645\n",
      "local epoch for train_loader 4: 118/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7702\n",
      "current epoch: 118 current mean dice: 0.4331 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 119/300\n",
      "local epoch for train_loader 1: 119/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss C1: 0.973967432975769\n",
      "local epoch for train_loader 2: 119/300\n",
      "Loss C2: 0.9176346063613892\n",
      "local epoch for train_loader 4: 119/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7868\n",
      "----------\n",
      "local epoch 120/300\n",
      "local epoch for train_loader 1: 120/300\n",
      "Loss C1: 0.9981533288955688\n",
      "local epoch for train_loader 2: 120/300\n",
      "Loss C2: 0.6963221430778503\n",
      "local epoch for train_loader 4: 120/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7598\n",
      "current epoch: 120 current mean dice: 0.4605 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 121/300\n",
      "local epoch for train_loader 1: 121/300\n",
      "Loss C1: 0.862665057182312\n",
      "local epoch for train_loader 2: 121/300\n",
      "Loss C2: 0.7449424266815186\n",
      "local epoch for train_loader 4: 121/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7573\n",
      "----------\n",
      "local epoch 122/300\n",
      "local epoch for train_loader 1: 122/300\n",
      "Loss C1: 0.989027738571167\n",
      "local epoch for train_loader 2: 122/300\n",
      "Loss C2: 0.7524451613426208\n",
      "local epoch for train_loader 4: 122/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7502\n",
      "current epoch: 122 current mean dice: 0.4584 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 123/300\n",
      "local epoch for train_loader 1: 123/300\n",
      "Loss C1: 0.9552257061004639\n",
      "local epoch for train_loader 2: 123/300\n",
      "Loss C2: 0.6549568176269531\n",
      "local epoch for train_loader 4: 123/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7540\n",
      "----------\n",
      "local epoch 124/300\n",
      "local epoch for train_loader 1: 124/300\n",
      "Loss C1: 0.9083726406097412\n",
      "local epoch for train_loader 2: 124/300\n",
      "Loss C2: 0.7261453866958618\n",
      "local epoch for train_loader 4: 124/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7557\n",
      "current epoch: 124 current mean dice: 0.4622 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 125/300\n",
      "local epoch for train_loader 1: 125/300\n",
      "Loss C1: 0.9611250162124634\n",
      "local epoch for train_loader 2: 125/300\n",
      "Loss C2: 0.6478571891784668\n",
      "local epoch for train_loader 4: 125/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7514\n",
      "----------\n",
      "local epoch 126/300\n",
      "local epoch for train_loader 1: 126/300\n",
      "Loss C1: 0.9985537528991699\n",
      "local epoch for train_loader 2: 126/300\n",
      "Loss C2: 0.72713702917099\n",
      "local epoch for train_loader 4: 126/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7465\n",
      "current epoch: 126 current mean dice: 0.4556 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 127/300\n",
      "local epoch for train_loader 1: 127/300\n",
      "Loss C1: 0.9335470199584961\n",
      "local epoch for train_loader 2: 127/300\n",
      "Loss C2: 0.7079676389694214\n",
      "local epoch for train_loader 4: 127/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7514\n",
      "----------\n",
      "local epoch 128/300\n",
      "local epoch for train_loader 1: 128/300\n",
      "Loss C1: 0.9990741014480591\n",
      "local epoch for train_loader 2: 128/300\n",
      "Loss C2: 0.7382396459579468\n",
      "local epoch for train_loader 4: 128/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7382\n",
      "current epoch: 128 current mean dice: 0.4486 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 129/300\n",
      "local epoch for train_loader 1: 129/300\n",
      "Loss C1: 0.932759165763855\n",
      "local epoch for train_loader 2: 129/300\n",
      "Loss C2: 0.7319685220718384\n",
      "local epoch for train_loader 4: 129/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7598\n",
      "----------\n",
      "local epoch 130/300\n",
      "local epoch for train_loader 1: 130/300\n",
      "Loss C1: 0.976198136806488\n",
      "local epoch for train_loader 2: 130/300\n",
      "Loss C2: 0.8990875482559204\n",
      "local epoch for train_loader 4: 130/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7559\n",
      "current epoch: 130 current mean dice: 0.4569 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 131/300\n",
      "local epoch for train_loader 1: 131/300\n",
      "Loss C1: 0.9298225045204163\n",
      "local epoch for train_loader 2: 131/300\n",
      "Loss C2: 0.7701988220214844\n",
      "local epoch for train_loader 4: 131/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7380\n",
      "----------\n",
      "local epoch 132/300\n",
      "local epoch for train_loader 1: 132/300\n",
      "Loss C1: 0.9767324924468994\n",
      "local epoch for train_loader 2: 132/300\n",
      "Loss C2: 0.7402554750442505\n",
      "local epoch for train_loader 4: 132/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7435\n",
      "current epoch: 132 current mean dice: 0.4451 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 133/300\n",
      "local epoch for train_loader 1: 133/300\n",
      "Loss C1: 0.9025098085403442\n",
      "local epoch for train_loader 2: 133/300\n",
      "Loss C2: 0.5711151361465454\n",
      "local epoch for train_loader 4: 133/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7403\n",
      "----------\n",
      "local epoch 134/300\n",
      "local epoch for train_loader 1: 134/300\n",
      "Loss C1: 0.9953218698501587\n",
      "local epoch for train_loader 2: 134/300\n",
      "Loss C2: 0.7105687856674194\n",
      "local epoch for train_loader 4: 134/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7399\n",
      "current epoch: 134 current mean dice: 0.4585 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 135/300\n",
      "local epoch for train_loader 1: 135/300\n",
      "Loss C1: 0.9584940671920776\n",
      "local epoch for train_loader 2: 135/300\n",
      "Loss C2: 0.7301322817802429\n",
      "local epoch for train_loader 4: 135/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7250\n",
      "----------\n",
      "local epoch 136/300\n",
      "local epoch for train_loader 1: 136/300\n",
      "Loss C1: 0.8502326011657715\n",
      "local epoch for train_loader 2: 136/300\n",
      "Loss C2: 0.6557239890098572\n",
      "local epoch for train_loader 4: 136/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7142\n",
      "current epoch: 136 current mean dice: 0.4750 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 137/300\n",
      "local epoch for train_loader 1: 137/300\n",
      "Loss C1: 0.9865942001342773\n",
      "local epoch for train_loader 2: 137/300\n",
      "Loss C2: 0.6751683950424194\n",
      "local epoch for train_loader 4: 137/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7214\n",
      "----------\n",
      "local epoch 138/300\n",
      "local epoch for train_loader 1: 138/300\n",
      "Loss C1: 0.8548442721366882\n",
      "local epoch for train_loader 2: 138/300\n",
      "Loss C2: 0.6803374290466309\n",
      "local epoch for train_loader 4: 138/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7293\n",
      "current epoch: 138 current mean dice: 0.4669 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 139/300\n",
      "local epoch for train_loader 1: 139/300\n",
      "Loss C1: 0.8380079865455627\n",
      "local epoch for train_loader 2: 139/300\n",
      "Loss C2: 0.6647671461105347\n",
      "local epoch for train_loader 4: 139/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7149\n",
      "----------\n",
      "local epoch 140/300\n",
      "local epoch for train_loader 1: 140/300\n",
      "Loss C1: 0.9709795713424683\n",
      "local epoch for train_loader 2: 140/300\n",
      "Loss C2: 0.6557086706161499\n",
      "local epoch for train_loader 4: 140/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7161\n",
      "current epoch: 140 current mean dice: 0.4748 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 141/300\n",
      "local epoch for train_loader 1: 141/300\n",
      "Loss C1: 0.9752064943313599\n",
      "local epoch for train_loader 2: 141/300\n",
      "Loss C2: 0.7041951417922974\n",
      "local epoch for train_loader 4: 141/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7133\n",
      "----------\n",
      "local epoch 142/300\n",
      "local epoch for train_loader 1: 142/300\n",
      "Loss C1: 0.8758167624473572\n",
      "local epoch for train_loader 2: 142/300\n",
      "Loss C2: 0.5393883585929871\n",
      "local epoch for train_loader 4: 142/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.6948\n",
      "current epoch: 142 current mean dice: 0.4609 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 143/300\n",
      "local epoch for train_loader 1: 143/300\n",
      "Loss C1: 0.9910088777542114\n",
      "local epoch for train_loader 2: 143/300\n",
      "Loss C2: 0.6905776262283325\n",
      "local epoch for train_loader 4: 143/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7123\n",
      "----------\n",
      "local epoch 144/300\n",
      "local epoch for train_loader 1: 144/300\n",
      "Loss C1: 0.9948524832725525\n",
      "local epoch for train_loader 2: 144/300\n",
      "Loss C2: 0.655392050743103\n",
      "local epoch for train_loader 4: 144/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7086\n",
      "current epoch: 144 current mean dice: 0.4201 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 145/300\n",
      "local epoch for train_loader 1: 145/300\n",
      "Loss C1: 0.9806230068206787\n",
      "local epoch for train_loader 2: 145/300\n",
      "Loss C2: 0.5323721766471863\n",
      "local epoch for train_loader 4: 145/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7099\n",
      "----------\n",
      "local epoch 146/300\n",
      "local epoch for train_loader 1: 146/300\n",
      "Loss C1: 0.9986947178840637\n",
      "local epoch for train_loader 2: 146/300\n",
      "Loss C2: 0.5482351779937744\n",
      "local epoch for train_loader 4: 146/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.7009\n",
      "current epoch: 146 current mean dice: 0.4348 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 147/300\n",
      "local epoch for train_loader 1: 147/300\n",
      "Loss C1: 0.990769624710083\n",
      "local epoch for train_loader 2: 147/300\n",
      "Loss C2: 0.7279212474822998\n",
      "local epoch for train_loader 4: 147/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.6937\n",
      "----------\n",
      "local epoch 148/300\n",
      "local epoch for train_loader 1: 148/300\n",
      "Loss C1: 0.8843586444854736\n",
      "local epoch for train_loader 2: 148/300\n",
      "Loss C2: 0.6289282441139221\n",
      "local epoch for train_loader 4: 148/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.6899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch: 148 current mean dice: 0.4342 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 149/300\n",
      "local epoch for train_loader 1: 149/300\n",
      "Loss C1: 0.9997621774673462\n",
      "local epoch for train_loader 2: 149/300\n",
      "Loss C2: 0.6248199939727783\n",
      "local epoch for train_loader 4: 149/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.6815\n",
      "----------\n",
      "local epoch 150/300\n",
      "local epoch for train_loader 1: 150/300\n",
      "Loss C1: 0.9976399540901184\n",
      "local epoch for train_loader 2: 150/300\n",
      "Loss C2: 0.5185710191726685\n",
      "local epoch for train_loader 4: 150/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.6693\n",
      "current epoch: 150 current mean dice: 0.4157 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 151/300\n",
      "local epoch for train_loader 1: 151/300\n",
      "Loss C1: 0.9299557209014893\n",
      "local epoch for train_loader 2: 151/300\n",
      "Loss C2: 0.61761873960495\n",
      "local epoch for train_loader 4: 151/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.6605\n",
      "----------\n",
      "local epoch 152/300\n",
      "local epoch for train_loader 1: 152/300\n",
      "Loss C1: 0.9993407726287842\n",
      "local epoch for train_loader 2: 152/300\n",
      "Loss C2: 0.7243310213088989\n",
      "local epoch for train_loader 4: 152/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.6675\n",
      "current epoch: 152 current mean dice: 0.3633 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 153/300\n",
      "local epoch for train_loader 1: 153/300\n",
      "Loss C1: 0.9270088076591492\n",
      "local epoch for train_loader 2: 153/300\n",
      "Loss C2: 0.3644338846206665\n",
      "local epoch for train_loader 4: 153/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.6840\n",
      "----------\n",
      "local epoch 154/300\n",
      "local epoch for train_loader 1: 154/300\n",
      "Loss C1: 0.9954811334609985\n",
      "local epoch for train_loader 2: 154/300\n",
      "Loss C2: 0.549068808555603\n",
      "local epoch for train_loader 4: 154/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.6677\n",
      "current epoch: 154 current mean dice: 0.3710 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 155/300\n",
      "local epoch for train_loader 1: 155/300\n",
      "Loss C1: 0.9858317375183105\n",
      "local epoch for train_loader 2: 155/300\n",
      "Loss C2: 0.9401040077209473\n",
      "local epoch for train_loader 4: 155/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.6915\n",
      "----------\n",
      "local epoch 156/300\n",
      "local epoch for train_loader 1: 156/300\n",
      "Loss C1: 0.9723004698753357\n",
      "local epoch for train_loader 2: 156/300\n",
      "Loss C2: 0.5969622135162354\n",
      "local epoch for train_loader 4: 156/300\n",
      "Loss C4: 0.9999999403953552\n",
      "train_loss: 0.6731\n",
      "current epoch: 156 current mean dice: 0.4102 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 157/300\n",
      "local epoch for train_loader 1: 157/300\n",
      "Loss C1: 0.8981919288635254\n",
      "local epoch for train_loader 2: 157/300\n",
      "Loss C2: 0.433207631111145\n",
      "local epoch for train_loader 4: 157/300\n",
      "Loss C4: 0.9999999403953552\n",
      "train_loss: 0.6543\n",
      "----------\n",
      "local epoch 158/300\n",
      "local epoch for train_loader 1: 158/300\n",
      "Loss C1: 0.9937750101089478\n",
      "local epoch for train_loader 2: 158/300\n",
      "Loss C2: 0.5116934180259705\n",
      "local epoch for train_loader 4: 158/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.6820\n",
      "current epoch: 158 current mean dice: 0.3616 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 159/300\n",
      "local epoch for train_loader 1: 159/300\n",
      "Loss C1: 0.8591010570526123\n",
      "local epoch for train_loader 2: 159/300\n",
      "Loss C2: 0.6908425092697144\n",
      "local epoch for train_loader 4: 159/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.6386\n",
      "----------\n",
      "local epoch 160/300\n",
      "local epoch for train_loader 1: 160/300\n",
      "Loss C1: 0.9183003306388855\n",
      "local epoch for train_loader 2: 160/300\n",
      "Loss C2: 0.30090808868408203\n",
      "local epoch for train_loader 4: 160/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.6348\n",
      "current epoch: 160 current mean dice: 0.4133 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 161/300\n",
      "local epoch for train_loader 1: 161/300\n",
      "Loss C1: 0.9994921684265137\n",
      "local epoch for train_loader 2: 161/300\n",
      "Loss C2: 0.45357275009155273\n",
      "local epoch for train_loader 4: 161/300\n",
      "Loss C4: 0.9999999403953552\n",
      "train_loss: 0.6326\n",
      "----------\n",
      "local epoch 162/300\n",
      "local epoch for train_loader 1: 162/300\n",
      "Loss C1: 0.831649661064148\n",
      "local epoch for train_loader 2: 162/300\n",
      "Loss C2: 0.393180251121521\n",
      "local epoch for train_loader 4: 162/300\n",
      "Loss C4: 0.9999998211860657\n",
      "train_loss: 0.6262\n",
      "current epoch: 162 current mean dice: 0.3426 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 163/300\n",
      "local epoch for train_loader 1: 163/300\n",
      "Loss C1: 0.929802656173706\n",
      "local epoch for train_loader 2: 163/300\n",
      "Loss C2: 0.5220482349395752\n",
      "local epoch for train_loader 4: 163/300\n",
      "Loss C4: 0.9999999403953552\n",
      "train_loss: 0.6553\n",
      "----------\n",
      "local epoch 164/300\n",
      "local epoch for train_loader 1: 164/300\n",
      "Loss C1: 0.9972642660140991\n",
      "local epoch for train_loader 2: 164/300\n",
      "Loss C2: 0.4450008273124695\n",
      "local epoch for train_loader 4: 164/300\n",
      "Loss C4: 0.9999997019767761\n",
      "train_loss: 0.6166\n",
      "current epoch: 164 current mean dice: 0.3963 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 165/300\n",
      "local epoch for train_loader 1: 165/300\n",
      "Loss C1: 0.9994651675224304\n",
      "local epoch for train_loader 2: 165/300\n",
      "Loss C2: 0.3646063804626465\n",
      "local epoch for train_loader 4: 165/300\n",
      "Loss C4: 0.9999998807907104\n",
      "train_loss: 0.6102\n",
      "----------\n",
      "local epoch 166/300\n",
      "local epoch for train_loader 1: 166/300\n",
      "Loss C1: 0.8406670689582825\n",
      "local epoch for train_loader 2: 166/300\n",
      "Loss C2: 0.4529705047607422\n",
      "local epoch for train_loader 4: 166/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.6082\n",
      "current epoch: 166 current mean dice: 0.3851 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 167/300\n",
      "local epoch for train_loader 1: 167/300\n",
      "Loss C1: 0.9990748763084412\n",
      "local epoch for train_loader 2: 167/300\n",
      "Loss C2: 0.4010443687438965\n",
      "local epoch for train_loader 4: 167/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.6005\n",
      "----------\n",
      "local epoch 168/300\n",
      "local epoch for train_loader 1: 168/300\n",
      "Loss C1: 0.998872697353363\n",
      "local epoch for train_loader 2: 168/300\n",
      "Loss C2: 0.23745262622833252\n",
      "local epoch for train_loader 4: 168/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.5934\n",
      "current epoch: 168 current mean dice: 0.4008 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 169/300\n",
      "local epoch for train_loader 1: 169/300\n",
      "Loss C1: 0.9972904920578003\n",
      "local epoch for train_loader 2: 169/300\n",
      "Loss C2: 0.2657029628753662\n",
      "local epoch for train_loader 4: 169/300\n",
      "Loss C4: 0.9999999403953552\n",
      "train_loss: 0.6217\n",
      "----------\n",
      "local epoch 170/300\n",
      "local epoch for train_loader 1: 170/300\n",
      "Loss C1: 0.9977051615715027\n",
      "local epoch for train_loader 2: 170/300\n",
      "Loss C2: 0.589431643486023\n",
      "local epoch for train_loader 4: 170/300\n",
      "Loss C4: 0.9999986290931702\n",
      "train_loss: 0.6100\n",
      "current epoch: 170 current mean dice: 0.3364 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 171/300\n",
      "local epoch for train_loader 1: 171/300\n",
      "Loss C1: 0.9999566078186035\n",
      "local epoch for train_loader 2: 171/300\n",
      "Loss C2: 0.6935791969299316\n",
      "local epoch for train_loader 4: 171/300\n",
      "Loss C4: 0.9999999403953552\n",
      "train_loss: 0.6218\n",
      "----------\n",
      "local epoch 172/300\n",
      "local epoch for train_loader 1: 172/300\n",
      "Loss C1: 0.9999703168869019\n",
      "local epoch for train_loader 2: 172/300\n",
      "Loss C2: 0.5413395762443542\n",
      "local epoch for train_loader 4: 172/300\n",
      "Loss C4: 0.9999999403953552\n",
      "train_loss: 0.6037\n",
      "current epoch: 172 current mean dice: 0.4178 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 173/300\n",
      "local epoch for train_loader 1: 173/300\n",
      "Loss C1: 0.999617874622345\n",
      "local epoch for train_loader 2: 173/300\n",
      "Loss C2: 0.28544551134109497\n",
      "local epoch for train_loader 4: 173/300\n",
      "Loss C4: 1.0\n",
      "train_loss: 0.6224\n",
      "----------\n",
      "local epoch 174/300\n",
      "local epoch for train_loader 1: 174/300\n",
      "Loss C1: 0.6866204738616943\n",
      "local epoch for train_loader 2: 174/300\n",
      "Loss C2: 0.48458731174468994\n",
      "local epoch for train_loader 4: 174/300\n",
      "Loss C4: 0.9999997615814209\n",
      "train_loss: 0.5904\n",
      "current epoch: 174 current mean dice: 0.4069 best mean dice: 0.4979 at epoch 92\n",
      "----------\n",
      "local epoch 175/300\n",
      "local epoch for train_loader 1: 175/300\n",
      "Loss C1: 0.9511911869049072\n",
      "local epoch for train_loader 2: 175/300\n",
      "Loss C2: 0.34874773025512695\n",
      "local epoch for train_loader 4: 175/300\n",
      "Loss C4: 0.9999992847442627\n",
      "train_loss: 0.5922\n",
      "----------\n",
      "local epoch 176/300\n",
      "local epoch for train_loader 1: 176/300\n",
      "Loss C1: 0.9997527003288269\n",
      "local epoch for train_loader 2: 176/300\n",
      "Loss C2: 0.4882689118385315\n",
      "local epoch for train_loader 4: 176/300\n",
      "Loss C4: 0.9999996423721313\n",
      "train_loss: 0.5958\n"
     ]
    }
   ],
   "source": [
    "global_model.train()\n",
    "epoch_loss = 0\n",
    "modelc1, modelc2, modelc4 = copy.deepcopy(global_model), copy.deepcopy(global_model), copy.deepcopy(global_model)\n",
    "\n",
    "#optimizerc1 = get_optimizer(optimizer_name='adam', cur_lr=learning_rate,  model=modelc1, cur_momentum=0)\n",
    "#optimizerc2 = get_optimizer(optimizer_name='adam', cur_lr=learning_rate,  model=modelc2, cur_momentum=0)\n",
    "#optimizerc4 = get_optimizer(optimizer_name='adam', cur_lr=learning_rate,  model=modelc4, cur_momentum=0)\n",
    "\n",
    "train_loss, train_dice = [], []\n",
    "#modelc1, modelc2, modelc4 = copy.deepcopy(global_model), copy.deepcopy(global_model), copy.deepcopy(global_model)\n",
    "for epoch in range(num_epochs):\n",
    "    #Local update loop\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"local epoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    local_weights, local_losses = [], []\n",
    "    global_model.train()\n",
    "    \n",
    "    global_weights = global_model.state_dict()\n",
    "    modelc1, modelc2, modelc4 = copy.deepcopy(global_model), copy.deepcopy(global_model), copy.deepcopy(global_model)\n",
    "    optimizerc1 = torch.optim.Adam(modelc1.parameters(), learning_rate)\n",
    "    optimizerc2 = torch.optim.Adam(modelc2.parameters(), learning_rate)\n",
    "    optimizerc4 = torch.optim.Adam(modelc4.parameters(), learning_rate)\n",
    "    \n",
    "    modelc1.train()\n",
    "    modelc2.train()\n",
    "    modelc4.train()\n",
    "\n",
    "    batch_loss_c1, epoch_loss_c1 = [], []\n",
    "    print(f\"local epoch for train_loader 1: {epoch + 1}/{num_epochs}\")\n",
    "    for batch_data in c1_train_loader:\n",
    "        #inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "        #Swaping axes to have a batch of Batch_size, Channels, width and height\n",
    "        #inputs, labels = torch.swapaxes(batch_data[0][0], 1, -1).to(device), torch.swapaxes(batch_data[1][0], 1, -1).to(device)\n",
    "        inputs, labels = batch_data[0][:,:,:,:,0].to(device), batch_data[1][:,:,:,:,0].to(device)\n",
    "        modelc1.zero_grad()        \n",
    "        #print(inputs.shape)\n",
    "        outputs = modelc1(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizerc1.step()\n",
    "        batch_loss_c1.append(loss.item())\n",
    "    local_losses.append(copy.deepcopy(sum(batch_loss_c1) / len(batch_loss_c1)))\n",
    "    print(\"Loss C1: \" + str(batch_loss_c1[-1]))\n",
    "    \n",
    "    batch_loss_c2,epoch_loss_c2 = [], []\n",
    "    print(f\"local epoch for train_loader 2: {epoch + 1}/{num_epochs}\")\n",
    "    for batch_data in c2_train_loader:\n",
    "        #inputs, labels = torch.swapaxes(batch_data[0][0], 1, -1).to(device), torch.swapaxes(batch_data[1][0], 1, -1).to(device)\n",
    "        inputs, labels = batch_data[0][:,:,:,:,0].to(device), batch_data[1][:,:,:,:,0].to(device)\n",
    "        modelc2.zero_grad()\n",
    "        outputs = modelc2(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizerc2.step()\n",
    "        batch_loss_c2.append(loss.item())\n",
    "    local_losses.append(copy.deepcopy(sum(batch_loss_c2) / len(batch_loss_c2)))\n",
    "    print(\"Loss C2: \" + str(batch_loss_c2[-1]))\n",
    "    \n",
    "    \n",
    "    #C3 is the Siemens data loader for which we have only one data point\n",
    "    batch_loss_c4,epoch_loss_c4 = [], []\n",
    "    print(f\"local epoch for train_loader 4: {epoch + 1}/{num_epochs}\")\n",
    "    for batch_data in c4_train_loader:\n",
    "        #inputs, labels = torch.swapaxes(batch_data[0][0], 1, -1).to(device), torch.swapaxes(batch_data[1][0], 1, -1).to(device)\n",
    "        inputs, labels = batch_data[0][:,:,:,:,0].to(device), batch_data[1][:,:,:,:,0].to(device)\n",
    "        modelc4.zero_grad()\n",
    "        outputs = modelc4(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizerc4.step()\n",
    "        batch_loss_c4.append(loss.item())\n",
    "    local_losses.append(copy.deepcopy(sum(batch_loss_c4) / len(batch_loss_c4)))\n",
    "    print(\"Loss C4: \" + str(batch_loss_c4[-1]))\n",
    "    \n",
    "    loss_avg = sum(local_losses) / len(local_losses)\n",
    "    train_loss.append(loss_avg)\n",
    "    \n",
    "\n",
    "    print(f\"train_loss: {train_loss[-1]:.4f}\")\n",
    "    writer.add_scalar(\"train_loss\", loss_avg, epoch)        \n",
    "    \n",
    "    #Agregating the weights with the FedAvg aproach    \n",
    "    global_weights = average_weights([copy.deepcopy(modelc1.state_dict()),copy.deepcopy(modelc2.state_dict()),copy.deepcopy(modelc4.state_dict())])\n",
    "    # Update global weights with the averaged model weights.\n",
    "    global_model.load_state_dict(global_weights)\n",
    "    \n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        global_model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_images = None\n",
    "            val_labels = None\n",
    "            val_outputs = None\n",
    "            for val_data in all_valid_loader:\n",
    "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "                roi_size = (128, 128)\n",
    "                sw_batch_size = 1\n",
    "                val_outputs = global_model(val_images[:,:,:,:,0])\n",
    "                val_outputs = val_outputs>0.5 #This assumes one slice in the last dim\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels[:,:,:,:,0])\n",
    "            # aggregate the final mean dice result\n",
    "            metric = dice_metric.aggregate().item()\n",
    "            # reset the status for next validation round\n",
    "            dice_metric.reset()\n",
    "            metric_values.append(metric)\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(global_model.state_dict(), \"federated_AVG_best_metric_model_segmentation2d_array.pth\")\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                \"current epoch: {} current mean dice: {:.4f} best mean dice: {:.4f} at epoch {}\".format(\n",
    "                    epoch + 1, metric, best_metric, best_metric_epoch\n",
    "                )\n",
    "            )\n",
    "            writer.add_scalar(\"val_mean_dice\", metric, epoch + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22757f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecad5b2",
   "metadata": {},
   "source": [
    "## Testing the best validation model in an unseen test volume (slice-wise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c94c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep= 40\n",
    "cur_checkpoint_path = '/home/otarola/miccai22/metric_model_segmentation2d_array_ep_'+str(ep)+'.pth'\n",
    "\n",
    "checkpoint = torch.load('/home/otarola/miccai22/federated_AVG_best_metric_model_segmentation2d_array.pth')\n",
    "\n",
    "global_model.load_state_dict(checkpoint)\n",
    "outputs = global_model(inputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66e0669",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_volume = 0\n",
    "dice_metric.reset()\n",
    "metric_values_test = []\n",
    "for test_data in all_test_loader:\n",
    "    count_volume = count_volume+1\n",
    "    cur_image, cur_label = test_data\n",
    "    cur_outputs = []\n",
    "    cur_labels  = []\n",
    "    labels   = torch.tensor(cur_label).to(device)\n",
    "    for ct_slice in range(cur_image.shape[-1]):\n",
    "        cur_ct_slice = torch.tensor(cur_image[:,:,:,:,ct_slice]).to(device)        \n",
    "        label    = labels[:,:,:,:,ct_slice]\n",
    "        outputs = global_model(cur_ct_slice)\n",
    "\n",
    "        cur_outputs.append(outputs.cpu().detach().numpy()>0.5)\n",
    "        cur_labels.append(label.cpu().detach().numpy()>0.5)\n",
    "        #print(torch.tensor(cur_outputs[-1]).shape)\n",
    "        #print(torch.tensor(cur_labels[-1]).shape)\n",
    "        dice_metric(y_pred=torch.tensor(cur_outputs[-1]), y=torch.tensor(cur_labels[-1]))\n",
    "\n",
    "    # aggregate the final mean dice result\n",
    "    metric = dice_metric.aggregate().item()\n",
    "    dice_metric.reset()\n",
    "    metric_values_test.append(metric)\n",
    "print(\"AVG TEST DICE SCORE FOR LEARNING RATE \"+str(learning_rate) + \": \" + str(np.mean(metric_values_test)) + \" - STD: \" + str(np.std(metric_values_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b16af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(label.cpu().detach().numpy()>0.5).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b73294",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_values_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dab66f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_test_case = '/str/data/ASAP/miccai22_data/isles/federated/center1/test/case_21/SMIR.Brain.XX.O.CT_CBF.345691/SMIR.Brain.XX.O.CT_CBF.345691.nii'\n",
    "path_test_label= '/str/data/ASAP/miccai22_data/isles/federated/center1/test/case_21/SMIR.Brain.XX.O.OT.345694/SMIR.Brain.XX.O.OT.345694.nii'\n",
    "\n",
    "test_vol = nib.load(path_test_case)\n",
    "test_lbl = nib.load(path_test_label)\n",
    "\n",
    "test_vol_pxls = test_vol.get_fdata()\n",
    "test_vol_pxls = np.array(test_vol_pxls, dtype = np.float32)\n",
    "test_lbl_pxls = test_lbl.get_fdata()\n",
    "test_lbl_pxls = np.array(test_lbl_pxls)\n",
    "test_vol_pxls[test_vol_pxls>1200] = 0\n",
    "\n",
    "print(test_vol_pxls.shape, test_lbl_pxls.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ae6240",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_vol_pxls[:,:,1],cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7209b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_test = global_model(torch.tensor(test_vol_pxls[np.newaxis, np.newaxis, :,:,1]/1200).to(device))\n",
    "out_test = out_test.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b452f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.array(out_test[0,0,:,:]>0.5, dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599b7cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_lbl = test_lbl_pxls[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2117b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_metric(torch.tensor(pred[np.newaxis,np.newaxis,:,:]),torch.tensor(pred[np.newaxis,np.newaxis,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d17b1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(out_test[0,0,:,:]>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4380e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_values_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73e3812",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(outputs[0,0,:,:].cpu().detach().numpy()>0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efef822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(label[0,0,:,:].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed86a805",
   "metadata": {},
   "outputs": [],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acb9b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972a39ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(c4_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dcda0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(c3_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71def59",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(c1_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398bd702",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(c1_valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09380606",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(c1_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fe1714",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(c2_train_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
