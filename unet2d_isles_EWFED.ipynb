{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "433c64ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "import monai\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import copy\n",
    "from scipy.spatial import distance_matrix\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AsChannelFirstD,\n",
    "    AddChannel,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandRotate90,\n",
    "    RandSpatialCrop,\n",
    "    ScaleIntensity,\n",
    "    EnsureType,\n",
    "    Resized\n",
    ")\n",
    "\n",
    "from monai.data import (\n",
    "    ArrayDataset, GridPatchDataset, create_test_image_3d, PatchIter)\n",
    "from monai.utils import first\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import DataLoader, decollate_batch\n",
    "from natsort import natsorted\n",
    "import umap\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.special import softmax\n",
    "\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a88b48f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n"
     ]
    }
   ],
   "source": [
    "LIEU = 'sebastian_insel'\n",
    "\n",
    "if LIEU=='sebastian_insel':\n",
    "    root_exp  = '/home/otarola/miccai22/fedem/'\n",
    "    root_data = '/str/data/ASAP/miccai22_data/isles/federated/'\n",
    "    isles_nifti__dir_paths = natsorted(glob(root_data+\"**/**/**/\"))\n",
    "\n",
    "if LIEU=='sebastian_laptop':\n",
    "    root_exp  = '/Users/sebastianotalora/work/postdoc/federated_learning/fedem/'\n",
    "    root_data = '/Users/sebastianotalora/work/postdoc/federated_learning/data/'\n",
    "    isles_nifti__dir_paths = natsorted(glob(root_data+'brats/'\"**/**/\"))\n",
    "print(len(isles_nifti__dir_paths))#Should be 94\n",
    "#print(isles_nifti__dir_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "82371c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_weights_with_smax_samplesweight(local_trained_weights, loaders_lengths):\n",
    "    \"\"\"Returns the average of the weights.\n",
    "       local_trained_weights: The list of tensors (of the same shape) that will be averaged\n",
    "    \"\"\"\n",
    "    weights_samples_scaling = softmax(loaders_lengths)    \n",
    "    avg_weights = copy.deepcopy(local_trained_weights[0])\n",
    "    \n",
    "    for key in avg_weights.keys():\n",
    "        avg_weights[key] = avg_weights[key]*weights_samples_scaling[0]\n",
    "        \n",
    "    for key in avg_weights.keys():\n",
    "        for i in range(1, len(local_trained_weights)):\n",
    "            avg_weights[key] += (weights_samples_scaling[i])*local_trained_weights[i][key]\n",
    "        avg_weights[key] = torch.div(avg_weights[key], len(local_trained_weights))\n",
    "    return avg_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb66b720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_weights_with_numsamplesweight(local_trained_weights, loaders_lengths):\n",
    "    \"\"\"Returns the average of the weights.\n",
    "       local_trained_weights: The list of tensors (of the same shape) that will be averaged\n",
    "    \"\"\"\n",
    "    #weights_samples_scaling = softmax(loaders_lengths)\n",
    "    # Initialize copy model weights with the untrained model weights.\n",
    "    #weights_samples_scaling = np.array(loaders_lengths)/np.array(loaders_lengths).sum()\n",
    "\n",
    "    avg_weights = copy.deepcopy(local_trained_weights[0])\n",
    "    for key in avg_weights.keys():\n",
    "        avg_weights[key] = avg_weights[key]*loaders_lengths[0]\n",
    "        \n",
    "    for key in avg_weights.keys():\n",
    "        for i in range(1, len(local_trained_weights)):\n",
    "            avg_weights[key] += (loaders_lengths[i])*local_trained_weights[i][key]\n",
    "        avg_weights[key] = torch.div(avg_weights[key], len(local_trained_weights))\n",
    "    return avg_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ab4c841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_weights_with_embeddings(local_trained_weights, embeddings):\n",
    "    \"\"\"Returns the average of the weights.\n",
    "       local_trained_weights: The list of tensors (of the same shape) that will be averaged\n",
    "    \"\"\"\n",
    "    # Initialize copy model weights with the untrained model weights.\n",
    "    avg_weights = copy.deepcopy(local_trained_weights[0])\n",
    "    for key in avg_weights.keys():\n",
    "        for i in range(1, len(local_trained_weights)):\n",
    "            avg_weights[key] += local_trained_weights[i][key]\n",
    "        avg_weights[key] = torch.div(avg_weights[key], len(local_trained_weights))\n",
    "    return avg_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e0f971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_weights(local_trained_weights):\n",
    "    \"\"\"Returns the average of the weights.\n",
    "       local_trained_weights: The list of tensors (of the same shape) that will be averaged\n",
    "    \"\"\"\n",
    "    # Initialize copy model weights with the untrained model weights.\n",
    "    avg_weights = copy.deepcopy(local_trained_weights[0])\n",
    "    for key in avg_weights.keys():\n",
    "        for i in range(1, len(local_trained_weights)):\n",
    "            avg_weights[key] += local_trained_weights[i][key]\n",
    "        avg_weights[key] = torch.div(avg_weights[key], len(local_trained_weights))\n",
    "    return avg_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c28369c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============CENTER1====================\n",
      "15 15\n",
      "3 3\n",
      "4 4\n",
      "===============CENTER2====================\n",
      "41 41\n",
      "8 8\n",
      "8 8\n",
      "===============CENTER3====================\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "===============CENTER4====================\n",
      "9 9\n",
      "2 2\n",
      "2 2\n"
     ]
    }
   ],
   "source": [
    "#loading volume paths\n",
    "LOCATION = 'scan' #laptop\n",
    "if LOCATION == 'scan':\n",
    "    isles_data_root = '/str/data/ASAP/miccai22_data/isles/federated/'\n",
    "    exp_root = '/home/otarola/miccai22/fedem/'\n",
    "\n",
    "if LOCATION == 'laptop':\n",
    "    isles_data_root = '/data/ASAP/miccai22_data/isles/federated/'\n",
    "\n",
    "modality = 'Tmax'\n",
    "\n",
    "center1_cbf_paths_train  = sorted(glob(isles_data_root+'center1/train/'+'/**/*'+modality+'*/*.nii'))\n",
    "center1_cbf_paths_valid  = sorted(glob(isles_data_root+'center1/valid/'+'/**/*'+modality+'*/*.nii'))\n",
    "center1_cbf_paths_test   = sorted(glob(isles_data_root+'center1/test/'+'/**/*'+modality+'*/*.nii'))\n",
    "center1_lbl_paths_train  = sorted(glob(isles_data_root+'center1/train/'+'/**/*OT*/*nii'))\n",
    "center1_lbl_paths_valid  = sorted(glob(isles_data_root+'center1/valid/'+'/**/*OT*/*nii'))\n",
    "center1_lbl_paths_test  = sorted(glob(isles_data_root+'center1/test/'+'/**/*OT*/*nii'))\n",
    "\n",
    "center2_cbf_paths_train  = sorted(glob(isles_data_root+'center2/train/'+'/**/*'+modality+'*/*.nii'))\n",
    "center2_cbf_paths_valid  = sorted(glob(isles_data_root+'center2/valid/'+'/**/*'+modality+'*/*.nii'))\n",
    "center2_cbf_paths_test   = sorted(glob(isles_data_root+'center2/test/'+'/**/*'+modality+'*/*.nii'))\n",
    "center2_lbl_paths_train  = sorted(glob(isles_data_root+'center2/train/'+'/**/*OT*/*nii'))\n",
    "center2_lbl_paths_valid  = sorted(glob(isles_data_root+'center2/valid/'+'/**/*OT*/*nii'))\n",
    "center2_lbl_paths_test   = sorted(glob(isles_data_root+'center2/test/'+'/**/*OT*/*nii'))\n",
    "\n",
    "center3_cbf_paths_train  = sorted(glob(isles_data_root+'center3/train/'+'/**/*'+modality+'*/*.nii'))\n",
    "center3_cbf_paths_valid  = sorted(glob(isles_data_root+'center3/valid/'+'/**/*'+modality+'*/*.nii'))\n",
    "center3_cbf_paths_test   = sorted(glob(isles_data_root+'center3/test/'+'/**/*'+modality+'*/*.nii'))\n",
    "center3_lbl_paths_train  = sorted(glob(isles_data_root+'center3/train/'+'/**/*OT*/*nii'))\n",
    "center3_lbl_paths_valid  = sorted(glob(isles_data_root+'center3/valid/'+'/**/*OT*/*nii'))\n",
    "center3_lbl_paths_test   = sorted(glob(isles_data_root+'center3/test/'+'/**/*OT*/*nii'))\n",
    "\n",
    "center4_cbf_paths_train  = sorted(glob(isles_data_root+'center4/train/'+'/**/*'+modality+'*/*.nii'))\n",
    "center4_cbf_paths_valid  = sorted(glob(isles_data_root+'center4/valid/'+'/**/*'+modality+'*/*.nii'))\n",
    "center4_cbf_paths_test   = sorted(glob(isles_data_root+'center4/test/'+'/**/*'+modality+'*/*.nii'))\n",
    "center4_lbl_paths_train  = sorted(glob(isles_data_root+'center4/train/'+'/**/*OT*/*nii'))\n",
    "center4_lbl_paths_valid  = sorted(glob(isles_data_root+'center4/valid/'+'/**/*OT*/*nii'))\n",
    "center4_lbl_paths_test   = sorted(glob(isles_data_root+'center4/test/'+'/**/*OT*/*nii'))\n",
    "print(\"===============CENTER1====================\")\n",
    "print(len(center1_cbf_paths_train),len(center1_lbl_paths_train))\n",
    "print(len(center1_cbf_paths_valid), len(center1_lbl_paths_valid))\n",
    "print(len(center1_cbf_paths_test),  len(center1_lbl_paths_test))\n",
    "print(\"===============CENTER2====================\")\n",
    "print(len(center2_cbf_paths_train),len(center2_lbl_paths_train))\n",
    "print(len(center2_cbf_paths_valid), len(center2_lbl_paths_valid))\n",
    "print(len(center2_cbf_paths_test),  len(center2_lbl_paths_test))\n",
    "print(\"===============CENTER3====================\")\n",
    "print(len(center3_cbf_paths_train),len(center3_lbl_paths_train))\n",
    "print(len(center3_cbf_paths_valid), len(center3_lbl_paths_valid))\n",
    "print(len(center3_cbf_paths_test),  len(center3_lbl_paths_test))\n",
    "print(\"===============CENTER4====================\")\n",
    "print(len(center4_cbf_paths_train),len(center4_lbl_paths_train))\n",
    "print(len(center4_cbf_paths_valid), len(center4_lbl_paths_valid))\n",
    "print(len(center4_cbf_paths_test),  len(center4_lbl_paths_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70789ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the dataloader for 10 ISLES volumes using the T_max and the CBF\n",
    "#For cbf we are windowing 1-1024\n",
    "#For tmax we'll window 0-60\n",
    "#For CBV we'll window 0-200\n",
    "if modality =='CBF':\n",
    "    max_intensity = 1200\n",
    "if modality =='CBV':\n",
    "    max_intensity = 200\n",
    "if modality =='Tmax' or modality =='MTT':\n",
    "    max_intensity = 30\n",
    "\n",
    "imtrans = Compose(\n",
    "    [   LoadImage(image_only=True),\n",
    "        #RandScaleIntensity( factors=0.1, prob=0.5),\n",
    "        ScaleIntensity(minv=0.0, maxv=max_intensity),\n",
    "        AddChannel(),\n",
    "        RandRotate90( prob=0.5, spatial_axes=[0, 1]),\n",
    "        RandSpatialCrop((224, 224,1), random_size=False),\n",
    "        EnsureType(),\n",
    "        #Resized\n",
    "    ]\n",
    ")\n",
    "\n",
    "segtrans = Compose(\n",
    "    [   LoadImage(image_only=True),\n",
    "        AddChannel(),\n",
    "        RandRotate90( prob=0.5, spatial_axes=[0, 1]),\n",
    "        RandSpatialCrop((224, 224,1), random_size=False),\n",
    "        EnsureType(),\n",
    "        #Resized\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67353bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "imtrans_neutral = Compose(\n",
    "    [   LoadImage(image_only=True),\n",
    "        #RandScaleIntensity( factors=0.1, prob=0.5),\n",
    "        ScaleIntensity(minv=0.0, maxv=max_intensity),\n",
    "        AddChannel(),\n",
    "        RandSpatialCrop((224, 224,1), random_size=False),\n",
    "        EnsureType(),\n",
    "        #Resized\n",
    "    ]\n",
    ")\n",
    "\n",
    "segtrans_neutral = Compose(\n",
    "    [   LoadImage(image_only=True),\n",
    "        AddChannel(),\n",
    "        RandSpatialCrop((224, 224,1), random_size=False),\n",
    "        EnsureType(),\n",
    "        #Resized\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da6b3895",
   "metadata": {},
   "outputs": [],
   "source": [
    "imtrans_test = Compose(\n",
    "    [   LoadImage(image_only=True),\n",
    "        ScaleIntensity(minv=0.0, maxv=max_intensity),\n",
    "        AddChannel(),\n",
    "        #RandSpatialCrop((224, 224,1), random_size=False), In test we would like to process ALL slices\n",
    "        EnsureType(),\n",
    "        #Resized\n",
    "    ]\n",
    ")\n",
    "\n",
    "segtrans_test = Compose(\n",
    "    [   LoadImage(image_only=True),\n",
    "        AddChannel(),\n",
    "        #RandSpatialCrop((224, 224,1), random_size=False),\n",
    "        EnsureType(),\n",
    "        #Resized\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af0a62eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df40802d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 224, 224, 1]) torch.Size([2, 1, 224, 224, 1])\n",
      "(array([49852,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "         324]), array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ],\n",
      "      dtype=float32))\n",
      "tensor(30.)\n"
     ]
    }
   ],
   "source": [
    "##################C1\n",
    "c1_ds_train = ArrayDataset(center1_cbf_paths_train, imtrans, center1_lbl_paths_train, segtrans)\n",
    "c1_train_loader   = torch.utils.data.DataLoader(\n",
    "    c1_ds_train, batch_size=batch_size, num_workers=1, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "c1_ds_valid = ArrayDataset(center1_cbf_paths_valid, imtrans, center1_lbl_paths_valid, segtrans)\n",
    "c1_valid_loader   = torch.utils.data.DataLoader(\n",
    "    c1_ds_valid, batch_size=1, num_workers=1, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "c1_ds_test = ArrayDataset(center1_cbf_paths_test, imtrans_test, center1_lbl_paths_test, segtrans_test)\n",
    "c1_test_loader   = torch.utils.data.DataLoader(\n",
    "    c1_ds_test, batch_size=1, num_workers=1, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "\n",
    "##################C2\n",
    "c2_ds_train = ArrayDataset(center2_cbf_paths_train, imtrans, center2_lbl_paths_train, segtrans)\n",
    "c2_train_loader   = torch.utils.data.DataLoader(\n",
    "    c2_ds_train, batch_size=batch_size, num_workers=1, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "c2_ds_valid = ArrayDataset(center2_cbf_paths_valid, imtrans, center2_lbl_paths_valid, segtrans)\n",
    "c2_valid_loader   = torch.utils.data.DataLoader(\n",
    "    c2_ds_valid, batch_size=1, num_workers=1, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "c2_ds_test = ArrayDataset(center2_cbf_paths_test, imtrans_test, center2_lbl_paths_test, segtrans_test)\n",
    "c2_test_loader   = torch.utils.data.DataLoader(\n",
    "    c2_ds_test, batch_size=1, num_workers=1, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "##################C3\n",
    "c3_ds_train = ArrayDataset(center3_cbf_paths_train, imtrans, center3_lbl_paths_train, segtrans)\n",
    "c3_train_loader   = torch.utils.data.DataLoader(\n",
    "    c3_ds_train, batch_size=1, num_workers=1, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "c3_ds_valid = ArrayDataset(center3_cbf_paths_valid, imtrans, center3_lbl_paths_valid, segtrans)\n",
    "c3_valid_loader   = torch.utils.data.DataLoader(\n",
    "    c3_ds_valid, batch_size=1, num_workers=1, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "c3_ds_test = ArrayDataset(center3_cbf_paths_test, imtrans_test, center3_lbl_paths_test, segtrans_test)\n",
    "c3_test_loader   = torch.utils.data.DataLoader(\n",
    "    c3_ds_test, batch_size=1, num_workers=1, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "##################C4\n",
    "c4_ds_train = ArrayDataset(center4_cbf_paths_train, imtrans, center4_lbl_paths_train, segtrans)\n",
    "c4_train_loader   = torch.utils.data.DataLoader(\n",
    "    c4_ds_train, batch_size=batch_size, num_workers=1, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "c4_ds_valid = ArrayDataset(center4_cbf_paths_valid, imtrans, center4_lbl_paths_valid, segtrans)\n",
    "c4_valid_loader   = torch.utils.data.DataLoader(\n",
    "    c4_ds_valid, batch_size=1, num_workers=1, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "c4_ds_test = ArrayDataset(center4_cbf_paths_test, imtrans_test, center4_lbl_paths_test, segtrans_test)\n",
    "c4_test_loader   = torch.utils.data.DataLoader(\n",
    "    c4_ds_test, batch_size=1, num_workers=1, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "\n",
    "im, seg = first(c1_train_loader)\n",
    "print(im.shape, seg.shape)\n",
    "print(np.histogram(seg[0,0,:,:,0]))\n",
    "print(im.max())\n",
    "\n",
    "\n",
    "\n",
    "all_ds_valid = ArrayDataset(center1_cbf_paths_valid+center2_cbf_paths_valid+center3_cbf_paths_valid+center4_cbf_paths_valid,\n",
    "                            imtrans, center1_lbl_paths_valid+center2_lbl_paths_valid+center3_lbl_paths_valid+center4_lbl_paths_valid,\n",
    "                            segtrans)\n",
    "all_valid_loader   = torch.utils.data.DataLoader(\n",
    "    all_ds_valid, batch_size=1, num_workers=1, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "all_ds_test = ArrayDataset(center1_cbf_paths_test+center2_cbf_paths_test+center3_cbf_paths_test+center4_cbf_paths_test,\n",
    "                            imtrans, center1_lbl_paths_test+center2_lbl_paths_test+center3_lbl_paths_test+center4_lbl_paths_test,\n",
    "                            segtrans)\n",
    "all_test_loader   = torch.utils.data.DataLoader(\n",
    "    all_ds_test, batch_size=1, num_workers=1, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad00e10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 41, 9]\n",
      "[0.1259273180814282, 0.10134821448516575, 0.16324411477092318]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1259273180814282, 0.10134821448516575, 0.16324411477092318]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders_lengths = [len(c1_ds_train),len(c2_ds_train),len(c4_ds_train)]\n",
    "\n",
    "beta = 0.9\n",
    "\n",
    "weight_classes = [(1-beta)/(1-np.power(beta,length)) for length in loaders_lengths]\n",
    "print(loaders_lengths)\n",
    "print(weight_classes)\n",
    "\n",
    "weight_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e4a4219",
   "metadata": {},
   "outputs": [],
   "source": [
    "im, seg = first(c1_train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dbd5cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe478819730>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(im[0,0,:,:,0],cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d45d06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe478c75580>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(seg[0,0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "890c90a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = np.squeeze([np.random.rand(1)*1e-1, np.random.rand(1)*1e-2, np.random.rand(1)*1e-2, np.random.rand(1)*1e-3, np.random.rand(1)*1e-3])\n",
    "num_epochs = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1ce6cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfb4661c",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_trans = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold=0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c651195b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "175ba26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = monai.networks.nets.UNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54694415",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.000132#lrs[0] #To comment in the loop\n",
    "loss_function = monai.losses.DiceLoss(sigmoid=True)\n",
    "optimizer = torch.optim.Adam(global_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "967fa658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000132\n"
     ]
    }
   ],
   "source": [
    "print(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d138038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start a typical PyTorch training\n",
    "val_interval = 2\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = list()\n",
    "metric_values = list()\n",
    "writer = SummaryWriter(comment=modality+\"_FEDAVG_LR_\"+str(learning_rate)+\"_BATCH_\"+str(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "438fb8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = next(iter(c1_train_loader))\n",
    "#print(batch_data[0].shape)\n",
    "#batch_data[0][:,:,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bbc87b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 224, 224]) torch.Size([2, 1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "batch_data = next(iter(c1_train_loader))\n",
    "inputs, labels = batch_data[0][:,:,:,:,0].to(device),batch_data[1][:,:,:,:,0].to(device)\n",
    "#torch.swapaxes(batch_data[0][0], 1, -1).to(device), torch.swapaxes(batch_data[1][0], 1, -1).to(device).to(device)\n",
    "print(inputs.shape,labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "102cfdc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (model): Sequential(\n",
       "    (0): ResidualUnit(\n",
       "      (conv): Sequential(\n",
       "        (unit0): Convolution(\n",
       "          (conv): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (adn): ADN(\n",
       "            (N): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (D): Dropout(p=0.0, inplace=False)\n",
       "            (A): PReLU(num_parameters=1)\n",
       "          )\n",
       "        )\n",
       "        (unit1): Convolution(\n",
       "          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (adn): ADN(\n",
       "            (N): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (D): Dropout(p=0.0, inplace=False)\n",
       "            (A): PReLU(num_parameters=1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (residual): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (1): SkipConnection(\n",
       "      (submodule): Sequential(\n",
       "        (0): ResidualUnit(\n",
       "          (conv): Sequential(\n",
       "            (unit0): Convolution(\n",
       "              (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "              (adn): ADN(\n",
       "                (N): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "                (D): Dropout(p=0.0, inplace=False)\n",
       "                (A): PReLU(num_parameters=1)\n",
       "              )\n",
       "            )\n",
       "            (unit1): Convolution(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (adn): ADN(\n",
       "                (N): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "                (D): Dropout(p=0.0, inplace=False)\n",
       "                (A): PReLU(num_parameters=1)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (residual): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "        (1): SkipConnection(\n",
       "          (submodule): Sequential(\n",
       "            (0): ResidualUnit(\n",
       "              (conv): Sequential(\n",
       "                (unit0): Convolution(\n",
       "                  (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "                  (adn): ADN(\n",
       "                    (N): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "                    (D): Dropout(p=0.0, inplace=False)\n",
       "                    (A): PReLU(num_parameters=1)\n",
       "                  )\n",
       "                )\n",
       "                (unit1): Convolution(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  (adn): ADN(\n",
       "                    (N): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "                    (D): Dropout(p=0.0, inplace=False)\n",
       "                    (A): PReLU(num_parameters=1)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (residual): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "            )\n",
       "            (1): SkipConnection(\n",
       "              (submodule): ResidualUnit(\n",
       "                (conv): Sequential(\n",
       "                  (unit0): Convolution(\n",
       "                    (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (adn): ADN(\n",
       "                      (N): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "                      (D): Dropout(p=0.0, inplace=False)\n",
       "                      (A): PReLU(num_parameters=1)\n",
       "                    )\n",
       "                  )\n",
       "                  (unit1): Convolution(\n",
       "                    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (adn): ADN(\n",
       "                      (N): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "                      (D): Dropout(p=0.0, inplace=False)\n",
       "                      (A): PReLU(num_parameters=1)\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "                (residual): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "            )\n",
       "            (2): Sequential(\n",
       "              (0): Convolution(\n",
       "                (conv): ConvTranspose2d(192, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "                (adn): ADN(\n",
       "                  (N): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "                  (D): Dropout(p=0.0, inplace=False)\n",
       "                  (A): PReLU(num_parameters=1)\n",
       "                )\n",
       "              )\n",
       "              (1): ResidualUnit(\n",
       "                (conv): Sequential(\n",
       "                  (unit0): Convolution(\n",
       "                    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (adn): ADN(\n",
       "                      (N): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "                      (D): Dropout(p=0.0, inplace=False)\n",
       "                      (A): PReLU(num_parameters=1)\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "                (residual): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Convolution(\n",
       "            (conv): ConvTranspose2d(64, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "            (adn): ADN(\n",
       "              (N): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "              (D): Dropout(p=0.0, inplace=False)\n",
       "              (A): PReLU(num_parameters=1)\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualUnit(\n",
       "            (conv): Sequential(\n",
       "              (unit0): Convolution(\n",
       "                (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (adn): ADN(\n",
       "                  (N): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "                  (D): Dropout(p=0.0, inplace=False)\n",
       "                  (A): PReLU(num_parameters=1)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (residual): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Convolution(\n",
       "        (conv): ConvTranspose2d(32, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): PReLU(num_parameters=1)\n",
       "        )\n",
       "      )\n",
       "      (1): ResidualUnit(\n",
       "        (conv): Sequential(\n",
       "          (unit0): Convolution(\n",
       "            (conv): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (residual): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "018f45cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy weights\n",
    "global_weights = global_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97f21351",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.3790, device='cuda:0')\n",
      "tensor(-1.0359, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n",
      "tensor(-2.4708, device='cuda:0')\n",
      "tensor(-0.0303, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n",
      "tensor(-3.9149, device='cuda:0')\n",
      "tensor(0.3286, device='cuda:0')\n",
      "tensor(-3.1637, device='cuda:0')\n",
      "tensor(-0.2809, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n",
      "tensor(-0.7374, device='cuda:0')\n",
      "tensor(-0.1061, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n",
      "tensor(1.2495, device='cuda:0')\n",
      "tensor(0.1613, device='cuda:0')\n",
      "tensor(-3.9697, device='cuda:0')\n",
      "tensor(-0.3542, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n",
      "tensor(-1.3277, device='cuda:0')\n",
      "tensor(0.1931, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n",
      "tensor(0.5394, device='cuda:0')\n",
      "tensor(-0.1832, device='cuda:0')\n",
      "tensor(-1.6025, device='cuda:0')\n",
      "tensor(0.1034, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n",
      "tensor(4.0550, device='cuda:0')\n",
      "tensor(0.1324, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n",
      "tensor(11.2147, device='cuda:0')\n",
      "tensor(0.0119, device='cuda:0')\n",
      "tensor(-0.7725, device='cuda:0')\n",
      "tensor(-0.1523, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n",
      "tensor(2.7330, device='cuda:0')\n",
      "tensor(-0.1133, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n",
      "tensor(-1.5396, device='cuda:0')\n",
      "tensor(-0.0424, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n",
      "tensor(-1.7663, device='cuda:0')\n",
      "tensor(-0.1103, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n",
      "tensor(0.2770, device='cuda:0')\n",
      "tensor(0.3037, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n",
      "tensor(-0.2540, device='cuda:0')\n",
      "tensor(-0.0196, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for key in global_weights:\n",
    "    print(global_weights[key].sum())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9a7f106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e197f976",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing that the model works in one iteration\n",
    "optimizer.zero_grad()\n",
    "outputs = global_model(inputs)\n",
    "loss    = loss_function(outputs, labels)\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e1d519a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 224, 224])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "901ddc96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 224, 224])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a7bdaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(optimizer_name, cur_lr, model, cur_momentum, weight_decay=1e-4):\n",
    "    if optimizer_name == 'sgd':\n",
    "        optimizer_name = optim.SGD(model.parameters(),\n",
    "                              lr= cur_lr,\n",
    "                              momentum=cur_momentum)\n",
    "    elif optimizer_name == 'adam':\n",
    "        optimizer_name = optim.Adam(model.parameters(),\n",
    "                               lr=cur_lr,\n",
    "                               weight_decay=weight_decay)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "826ec4b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "local epoch 1/200\n",
      "local epoch for train_loader 1: 1/200\n",
      "Loss C1: 0.9679384604096413\n",
      "local epoch for train_loader 2: 1/200\n",
      "Loss C2: 0.9428163085665021\n",
      "local epoch for train_loader 4: 1/200\n",
      "Loss C4: 0.9745126724243164\n",
      "train_loss: 0.9618\n",
      "----------\n",
      "local epoch 2/200\n",
      "local epoch for train_loader 1: 2/200\n",
      "Loss C1: 0.9631997123360634\n",
      "local epoch for train_loader 2: 2/200\n",
      "Loss C2: 0.9325045063382104\n",
      "local epoch for train_loader 4: 2/200\n",
      "Loss C4: 0.9736987829208374\n",
      "train_loss: 0.9565\n",
      "saved new best metric model\n",
      "current epoch: 2 current mean dice: 0.3768 best mean dice: 0.3768 at epoch 2\n",
      "----------\n",
      "local epoch 3/200\n",
      "local epoch for train_loader 1: 3/200\n",
      "Loss C1: 0.9600429460406303\n",
      "local epoch for train_loader 2: 3/200\n",
      "Loss C2: 0.9284576035681225\n",
      "local epoch for train_loader 4: 3/200\n",
      "Loss C4: 0.967967975139618\n",
      "train_loss: 0.9522\n",
      "----------\n",
      "local epoch 4/200\n",
      "local epoch for train_loader 1: 4/200\n",
      "Loss C1: 0.9586041569709778\n",
      "local epoch for train_loader 2: 4/200\n",
      "Loss C2: 0.9276358683904012\n",
      "local epoch for train_loader 4: 4/200\n",
      "Loss C4: 0.9703011035919189\n",
      "train_loss: 0.9522\n",
      "saved new best metric model\n",
      "current epoch: 4 current mean dice: 0.4843 best mean dice: 0.4843 at epoch 4\n",
      "----------\n",
      "local epoch 5/200\n",
      "local epoch for train_loader 1: 5/200\n",
      "Loss C1: 0.9608129113912582\n",
      "local epoch for train_loader 2: 5/200\n",
      "Loss C2: 0.9280495643615723\n",
      "local epoch for train_loader 4: 5/200\n",
      "Loss C4: 0.9707854747772217\n",
      "train_loss: 0.9532\n",
      "----------\n",
      "local epoch 6/200\n",
      "local epoch for train_loader 1: 6/200\n",
      "Loss C1: 0.9599367454648018\n",
      "local epoch for train_loader 2: 6/200\n",
      "Loss C2: 0.9295807140214103\n",
      "local epoch for train_loader 4: 6/200\n",
      "Loss C4: 0.9779603362083436\n",
      "train_loss: 0.9558\n",
      "current epoch: 6 current mean dice: 0.0185 best mean dice: 0.4843 at epoch 4\n",
      "----------\n",
      "local epoch 7/200\n",
      "local epoch for train_loader 1: 7/200\n",
      "Loss C1: 0.9605348259210587\n",
      "local epoch for train_loader 2: 7/200\n",
      "Loss C2: 0.9282489929880414\n",
      "local epoch for train_loader 4: 7/200\n",
      "Loss C4: 0.9775354504585266\n",
      "train_loss: 0.9554\n",
      "----------\n",
      "local epoch 8/200\n",
      "local epoch for train_loader 1: 8/200\n",
      "Loss C1: 0.9606626927852631\n",
      "local epoch for train_loader 2: 8/200\n",
      "Loss C2: 0.9279312803631737\n",
      "local epoch for train_loader 4: 8/200\n",
      "Loss C4: 0.9744072079658508\n",
      "train_loss: 0.9543\n",
      "current epoch: 8 current mean dice: 0.4528 best mean dice: 0.4843 at epoch 4\n",
      "----------\n",
      "local epoch 9/200\n",
      "local epoch for train_loader 1: 9/200\n",
      "Loss C1: 0.9629006087779999\n",
      "local epoch for train_loader 2: 9/200\n",
      "Loss C2: 0.9290899322146461\n",
      "local epoch for train_loader 4: 9/200\n",
      "Loss C4: 0.9702964186668396\n",
      "train_loss: 0.9541\n",
      "----------\n",
      "local epoch 10/200\n",
      "local epoch for train_loader 1: 10/200\n",
      "Loss C1: 0.9601266905665398\n",
      "local epoch for train_loader 2: 10/200\n",
      "Loss C2: 0.9280781774293809\n",
      "local epoch for train_loader 4: 10/200\n",
      "Loss C4: 0.9775009870529174\n",
      "train_loss: 0.9552\n",
      "current epoch: 10 current mean dice: 0.4593 best mean dice: 0.4843 at epoch 4\n",
      "----------\n",
      "local epoch 11/200\n",
      "local epoch for train_loader 1: 11/200\n",
      "Loss C1: 0.9594103097915649\n",
      "local epoch for train_loader 2: 11/200\n",
      "Loss C2: 0.9314065433683849\n",
      "local epoch for train_loader 4: 11/200\n",
      "Loss C4: 0.968609881401062\n",
      "train_loss: 0.9531\n",
      "----------\n",
      "local epoch 12/200\n",
      "local epoch for train_loader 1: 12/200\n",
      "Loss C1: 0.9597603306174278\n",
      "local epoch for train_loader 2: 12/200\n",
      "Loss C2: 0.9278076716831752\n",
      "local epoch for train_loader 4: 12/200\n",
      "Loss C4: 0.9785181999206543\n",
      "train_loss: 0.9554\n",
      "current epoch: 12 current mean dice: 0.4745 best mean dice: 0.4843 at epoch 4\n",
      "----------\n",
      "local epoch 13/200\n",
      "local epoch for train_loader 1: 13/200\n",
      "Loss C1: 0.973828062415123\n",
      "local epoch for train_loader 2: 13/200\n",
      "Loss C2: 0.9281862094288781\n",
      "local epoch for train_loader 4: 13/200\n",
      "Loss C4: 0.9700239658355713\n",
      "train_loss: 0.9573\n",
      "----------\n",
      "local epoch 14/200\n",
      "local epoch for train_loader 1: 14/200\n",
      "Loss C1: 0.9594634473323822\n",
      "local epoch for train_loader 2: 14/200\n",
      "Loss C2: 0.9286358640307472\n",
      "local epoch for train_loader 4: 14/200\n",
      "Loss C4: 0.9779338598251343\n",
      "train_loss: 0.9553\n",
      "current epoch: 14 current mean dice: 0.4529 best mean dice: 0.4843 at epoch 4\n",
      "----------\n",
      "local epoch 15/200\n",
      "local epoch for train_loader 1: 15/200\n",
      "Loss C1: 0.9601668193936348\n",
      "local epoch for train_loader 2: 15/200\n",
      "Loss C2: 0.9300143037523542\n",
      "local epoch for train_loader 4: 15/200\n",
      "Loss C4: 0.9689459443092346\n",
      "train_loss: 0.9530\n",
      "----------\n",
      "local epoch 16/200\n",
      "local epoch for train_loader 1: 16/200\n",
      "Loss C1: 0.9599898532032967\n",
      "local epoch for train_loader 2: 16/200\n",
      "Loss C2: 0.92881330989656\n",
      "local epoch for train_loader 4: 16/200\n",
      "Loss C4: 0.9783385038375855\n",
      "train_loss: 0.9557\n",
      "current epoch: 16 current mean dice: 0.4705 best mean dice: 0.4843 at epoch 4\n",
      "----------\n",
      "local epoch 17/200\n",
      "local epoch for train_loader 1: 17/200\n",
      "Loss C1: 0.9592225849628448\n",
      "local epoch for train_loader 2: 17/200\n",
      "Loss C2: 0.9276580100967771\n",
      "local epoch for train_loader 4: 17/200\n",
      "Loss C4: 0.9716627597808838\n",
      "train_loss: 0.9528\n",
      "----------\n",
      "local epoch 18/200\n",
      "local epoch for train_loader 1: 18/200\n",
      "Loss C1: 0.9622586518526077\n",
      "local epoch for train_loader 2: 18/200\n",
      "Loss C2: 0.9280480543772379\n",
      "local epoch for train_loader 4: 18/200\n",
      "Loss C4: 0.9688461303710938\n",
      "train_loss: 0.9531\n",
      "saved new best metric model\n",
      "current epoch: 18 current mean dice: 0.4917 best mean dice: 0.4917 at epoch 18\n",
      "----------\n",
      "local epoch 19/200\n",
      "local epoch for train_loader 1: 19/200\n",
      "Loss C1: 0.9583323821425438\n",
      "local epoch for train_loader 2: 19/200\n",
      "Loss C2: 0.9281815148535228\n",
      "local epoch for train_loader 4: 19/200\n",
      "Loss C4: 0.9774523377418518\n",
      "train_loss: 0.9547\n",
      "----------\n",
      "local epoch 20/200\n",
      "local epoch for train_loader 1: 20/200\n",
      "Loss C1: 0.9598173946142197\n",
      "local epoch for train_loader 2: 20/200\n",
      "Loss C2: 0.9309008518854777\n",
      "local epoch for train_loader 4: 20/200\n",
      "Loss C4: 0.9684953093528748\n",
      "train_loss: 0.9531\n",
      "current epoch: 20 current mean dice: 0.0607 best mean dice: 0.4917 at epoch 18\n",
      "----------\n",
      "local epoch 21/200\n",
      "local epoch for train_loader 1: 21/200\n",
      "Loss C1: 0.9631650522351265\n",
      "local epoch for train_loader 2: 21/200\n",
      "Loss C2: 0.9322352352596465\n",
      "local epoch for train_loader 4: 21/200\n",
      "Loss C4: 0.9774432063102723\n",
      "train_loss: 0.9576\n",
      "----------\n",
      "local epoch 22/200\n",
      "local epoch for train_loader 1: 22/200\n",
      "Loss C1: 0.9611933380365372\n",
      "local epoch for train_loader 2: 22/200\n",
      "Loss C2: 0.9321007189296541\n",
      "local epoch for train_loader 4: 22/200\n",
      "Loss C4: 0.9765861511230469\n",
      "train_loss: 0.9566\n",
      "current epoch: 22 current mean dice: 0.3993 best mean dice: 0.4917 at epoch 18\n",
      "----------\n",
      "local epoch 23/200\n",
      "local epoch for train_loader 1: 23/200\n",
      "Loss C1: 0.9609822183847427\n",
      "local epoch for train_loader 2: 23/200\n",
      "Loss C2: 0.929064100696927\n",
      "local epoch for train_loader 4: 23/200\n",
      "Loss C4: 0.9762685060501098\n",
      "train_loss: 0.9554\n",
      "----------\n",
      "local epoch 24/200\n",
      "local epoch for train_loader 1: 24/200\n",
      "Loss C1: 0.9595173075795174\n",
      "local epoch for train_loader 2: 24/200\n",
      "Loss C2: 0.931290138335455\n",
      "local epoch for train_loader 4: 24/200\n",
      "Loss C4: 0.9754272818565368\n",
      "train_loss: 0.9554\n",
      "saved new best metric model\n",
      "current epoch: 24 current mean dice: 0.5088 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 25/200\n",
      "local epoch for train_loader 1: 25/200\n",
      "Loss C1: 0.9612151384353638\n",
      "local epoch for train_loader 2: 25/200\n",
      "Loss C2: 0.9330483249255589\n",
      "local epoch for train_loader 4: 25/200\n",
      "Loss C4: 0.9753605604171753\n",
      "train_loss: 0.9565\n",
      "----------\n",
      "local epoch 26/200\n",
      "local epoch for train_loader 1: 26/200\n",
      "Loss C1: 0.9613481238484383\n",
      "local epoch for train_loader 2: 26/200\n",
      "Loss C2: 0.9300360821542286\n",
      "local epoch for train_loader 4: 26/200\n",
      "Loss C4: 0.972721004486084\n",
      "train_loss: 0.9547\n",
      "current epoch: 26 current mean dice: 0.4289 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 27/200\n",
      "local epoch for train_loader 1: 27/200\n",
      "Loss C1: 0.9615075811743736\n",
      "local epoch for train_loader 2: 27/200\n",
      "Loss C2: 0.928950792267209\n",
      "local epoch for train_loader 4: 27/200\n",
      "Loss C4: 0.9763378500938416\n",
      "train_loss: 0.9556\n",
      "----------\n",
      "local epoch 28/200\n",
      "local epoch for train_loader 1: 28/200\n",
      "Loss C1: 0.9612276628613472\n",
      "local epoch for train_loader 2: 28/200\n",
      "Loss C2: 0.9300180304618109\n",
      "local epoch for train_loader 4: 28/200\n",
      "Loss C4: 0.9768567085266113\n",
      "train_loss: 0.9560\n",
      "current epoch: 28 current mean dice: 0.4132 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 29/200\n",
      "local epoch for train_loader 1: 29/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss C1: 0.9618208259344101\n",
      "local epoch for train_loader 2: 29/200\n",
      "Loss C2: 0.929922566527412\n",
      "local epoch for train_loader 4: 29/200\n",
      "Loss C4: 0.9761750936508179\n",
      "train_loss: 0.9560\n",
      "----------\n",
      "local epoch 30/200\n",
      "local epoch for train_loader 1: 30/200\n",
      "Loss C1: 0.9602549895644188\n",
      "local epoch for train_loader 2: 30/200\n",
      "Loss C2: 0.929525165330796\n",
      "local epoch for train_loader 4: 30/200\n",
      "Loss C4: 0.9781901240348816\n",
      "train_loss: 0.9560\n",
      "current epoch: 30 current mean dice: 0.4579 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 31/200\n",
      "local epoch for train_loader 1: 31/200\n",
      "Loss C1: 0.9625479429960251\n",
      "local epoch for train_loader 2: 31/200\n",
      "Loss C2: 0.9285605691728138\n",
      "local epoch for train_loader 4: 31/200\n",
      "Loss C4: 0.977494764328003\n",
      "train_loss: 0.9562\n",
      "----------\n",
      "local epoch 32/200\n",
      "local epoch for train_loader 1: 32/200\n",
      "Loss C1: 0.9590500667691231\n",
      "local epoch for train_loader 2: 32/200\n",
      "Loss C2: 0.9295255172820318\n",
      "local epoch for train_loader 4: 32/200\n",
      "Loss C4: 0.9771817445755004\n",
      "train_loss: 0.9553\n",
      "current epoch: 32 current mean dice: 0.4346 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 33/200\n",
      "local epoch for train_loader 1: 33/200\n",
      "Loss C1: 0.963146910071373\n",
      "local epoch for train_loader 2: 33/200\n",
      "Loss C2: 0.9330084806396848\n",
      "local epoch for train_loader 4: 33/200\n",
      "Loss C4: 0.9709537148475647\n",
      "train_loss: 0.9557\n",
      "----------\n",
      "local epoch 34/200\n",
      "local epoch for train_loader 1: 34/200\n",
      "Loss C1: 0.9610427841544151\n",
      "local epoch for train_loader 2: 34/200\n",
      "Loss C2: 0.9332391392616999\n",
      "local epoch for train_loader 4: 34/200\n",
      "Loss C4: 0.9757907390594482\n",
      "train_loss: 0.9567\n",
      "current epoch: 34 current mean dice: 0.3939 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 35/200\n",
      "local epoch for train_loader 1: 35/200\n",
      "Loss C1: 0.9638840928673744\n",
      "local epoch for train_loader 2: 35/200\n",
      "Loss C2: 0.9336571863719395\n",
      "local epoch for train_loader 4: 35/200\n",
      "Loss C4: 0.9759957075119019\n",
      "train_loss: 0.9578\n",
      "----------\n",
      "local epoch 36/200\n",
      "local epoch for train_loader 1: 36/200\n",
      "Loss C1: 0.9606677889823914\n",
      "local epoch for train_loader 2: 36/200\n",
      "Loss C2: 0.9301639028957912\n",
      "local epoch for train_loader 4: 36/200\n",
      "Loss C4: 0.9759596586227417\n",
      "train_loss: 0.9556\n",
      "current epoch: 36 current mean dice: 0.4566 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 37/200\n",
      "local epoch for train_loader 1: 37/200\n",
      "Loss C1: 0.9598301127552986\n",
      "local epoch for train_loader 2: 37/200\n",
      "Loss C2: 0.9298269464856103\n",
      "local epoch for train_loader 4: 37/200\n",
      "Loss C4: 0.973506498336792\n",
      "train_loss: 0.9544\n",
      "----------\n",
      "local epoch 38/200\n",
      "local epoch for train_loader 1: 38/200\n",
      "Loss C1: 0.9616292044520378\n",
      "local epoch for train_loader 2: 38/200\n",
      "Loss C2: 0.9311358361017137\n",
      "local epoch for train_loader 4: 38/200\n",
      "Loss C4: 0.9718669533729554\n",
      "train_loss: 0.9549\n",
      "current epoch: 38 current mean dice: 0.4529 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 39/200\n",
      "local epoch for train_loader 1: 39/200\n",
      "Loss C1: 0.9605964049696922\n",
      "local epoch for train_loader 2: 39/200\n",
      "Loss C2: 0.9308621996924991\n",
      "local epoch for train_loader 4: 39/200\n",
      "Loss C4: 0.9729287624359131\n",
      "train_loss: 0.9548\n",
      "----------\n",
      "local epoch 40/200\n",
      "local epoch for train_loader 1: 40/200\n",
      "Loss C1: 0.9608649015426636\n",
      "local epoch for train_loader 2: 40/200\n",
      "Loss C2: 0.930610770270938\n",
      "local epoch for train_loader 4: 40/200\n",
      "Loss C4: 0.9727596521377564\n",
      "train_loss: 0.9547\n",
      "current epoch: 40 current mean dice: 0.4370 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 41/200\n",
      "local epoch for train_loader 1: 41/200\n",
      "Loss C1: 0.9600956067442894\n",
      "local epoch for train_loader 2: 41/200\n",
      "Loss C2: 0.9308606925464812\n",
      "local epoch for train_loader 4: 41/200\n",
      "Loss C4: 0.9722365140914917\n",
      "train_loss: 0.9544\n",
      "----------\n",
      "local epoch 42/200\n",
      "local epoch for train_loader 1: 42/200\n",
      "Loss C1: 0.960096962749958\n",
      "local epoch for train_loader 2: 42/200\n",
      "Loss C2: 0.9298453018778846\n",
      "local epoch for train_loader 4: 42/200\n",
      "Loss C4: 0.9722473859786988\n",
      "train_loss: 0.9541\n",
      "current epoch: 42 current mean dice: 0.4510 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 43/200\n",
      "local epoch for train_loader 1: 43/200\n",
      "Loss C1: 0.960252933204174\n",
      "local epoch for train_loader 2: 43/200\n",
      "Loss C2: 0.9307499669847035\n",
      "local epoch for train_loader 4: 43/200\n",
      "Loss C4: 0.9735801458358765\n",
      "train_loss: 0.9549\n",
      "----------\n",
      "local epoch 44/200\n",
      "local epoch for train_loader 1: 44/200\n",
      "Loss C1: 0.9605476558208466\n",
      "local epoch for train_loader 2: 44/200\n",
      "Loss C2: 0.9306024369739351\n",
      "local epoch for train_loader 4: 44/200\n",
      "Loss C4: 0.9722184300422668\n",
      "train_loss: 0.9545\n",
      "current epoch: 44 current mean dice: 0.4301 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 45/200\n",
      "local epoch for train_loader 1: 45/200\n",
      "Loss C1: 0.9604325890541077\n",
      "local epoch for train_loader 2: 45/200\n",
      "Loss C2: 0.9301937392779759\n",
      "local epoch for train_loader 4: 45/200\n",
      "Loss C4: 0.9720596075057983\n",
      "train_loss: 0.9542\n",
      "----------\n",
      "local epoch 46/200\n",
      "local epoch for train_loader 1: 46/200\n",
      "Loss C1: 0.9601859524846077\n",
      "local epoch for train_loader 2: 46/200\n",
      "Loss C2: 0.9303214493251982\n",
      "local epoch for train_loader 4: 46/200\n",
      "Loss C4: 0.9723316669464112\n",
      "train_loss: 0.9543\n",
      "current epoch: 46 current mean dice: 0.4371 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 47/200\n",
      "local epoch for train_loader 1: 47/200\n",
      "Loss C1: 0.9605056717991829\n",
      "local epoch for train_loader 2: 47/200\n",
      "Loss C2: 0.9302150238127935\n",
      "local epoch for train_loader 4: 47/200\n",
      "Loss C4: 0.9725591897964477\n",
      "train_loss: 0.9544\n",
      "----------\n",
      "local epoch 48/200\n",
      "local epoch for train_loader 1: 48/200\n",
      "Loss C1: 0.9604361355304718\n",
      "local epoch for train_loader 2: 48/200\n",
      "Loss C2: 0.9308486325400216\n",
      "local epoch for train_loader 4: 48/200\n",
      "Loss C4: 0.9724895119667053\n",
      "train_loss: 0.9546\n",
      "current epoch: 48 current mean dice: 0.4322 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 49/200\n",
      "local epoch for train_loader 1: 49/200\n",
      "Loss C1: 0.9602190554141998\n",
      "local epoch for train_loader 2: 49/200\n",
      "Loss C2: 0.9307876569884164\n",
      "local epoch for train_loader 4: 49/200\n",
      "Loss C4: 0.9722625970840454\n",
      "train_loss: 0.9544\n",
      "----------\n",
      "local epoch 50/200\n",
      "local epoch for train_loader 1: 50/200\n",
      "Loss C1: 0.9606465175747871\n",
      "local epoch for train_loader 2: 50/200\n",
      "Loss C2: 0.9311469310805911\n",
      "local epoch for train_loader 4: 50/200\n",
      "Loss C4: 0.9720470905303955\n",
      "train_loss: 0.9546\n",
      "current epoch: 50 current mean dice: 0.4323 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 51/200\n",
      "local epoch for train_loader 1: 51/200\n",
      "Loss C1: 0.9597879648208618\n",
      "local epoch for train_loader 2: 51/200\n",
      "Loss C2: 0.930639215878078\n",
      "local epoch for train_loader 4: 51/200\n",
      "Loss C4: 0.9721402168273926\n",
      "train_loss: 0.9542\n",
      "----------\n",
      "local epoch 52/200\n",
      "local epoch for train_loader 1: 52/200\n",
      "Loss C1: 0.9607562646269798\n",
      "local epoch for train_loader 2: 52/200\n",
      "Loss C2: 0.9323329812004453\n",
      "local epoch for train_loader 4: 52/200\n",
      "Loss C4: 0.9721349000930786\n",
      "train_loss: 0.9551\n",
      "current epoch: 52 current mean dice: 0.4432 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 53/200\n",
      "local epoch for train_loader 1: 53/200\n",
      "Loss C1: 0.9604765027761459\n",
      "local epoch for train_loader 2: 53/200\n",
      "Loss C2: 0.9311746330488295\n",
      "local epoch for train_loader 4: 53/200\n",
      "Loss C4: 0.9721969604492188\n",
      "train_loss: 0.9546\n",
      "----------\n",
      "local epoch 54/200\n",
      "local epoch for train_loader 1: 54/200\n",
      "Loss C1: 0.9603729471564293\n",
      "local epoch for train_loader 2: 54/200\n",
      "Loss C2: 0.9308699397813707\n",
      "local epoch for train_loader 4: 54/200\n",
      "Loss C4: 0.9730865120887756\n",
      "train_loss: 0.9548\n",
      "current epoch: 54 current mean dice: 0.4450 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 55/200\n",
      "local epoch for train_loader 1: 55/200\n",
      "Loss C1: 0.9603421166539192\n",
      "local epoch for train_loader 2: 55/200\n",
      "Loss C2: 0.9305957101640248\n",
      "local epoch for train_loader 4: 55/200\n",
      "Loss C4: 0.9732264280319214\n",
      "train_loss: 0.9547\n",
      "----------\n",
      "local epoch 56/200\n",
      "local epoch for train_loader 1: 56/200\n",
      "Loss C1: 0.9605160430073738\n",
      "local epoch for train_loader 2: 56/200\n",
      "Loss C2: 0.9303545469329471\n",
      "local epoch for train_loader 4: 56/200\n",
      "Loss C4: 0.9729286670684815\n",
      "train_loss: 0.9546\n",
      "current epoch: 56 current mean dice: 0.4453 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 57/200\n",
      "local epoch for train_loader 1: 57/200\n",
      "Loss C1: 0.9594778120517731\n",
      "local epoch for train_loader 2: 57/200\n",
      "Loss C2: 0.9282452180272057\n",
      "local epoch for train_loader 4: 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss C4: 0.9730707406997681\n",
      "train_loss: 0.9536\n",
      "----------\n",
      "local epoch 58/200\n",
      "local epoch for train_loader 1: 58/200\n",
      "Loss C1: 0.9606444239616394\n",
      "local epoch for train_loader 2: 58/200\n",
      "Loss C2: 0.9285167597589039\n",
      "local epoch for train_loader 4: 58/200\n",
      "Loss C4: 0.972669804096222\n",
      "train_loss: 0.9539\n",
      "current epoch: 58 current mean dice: 0.4597 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 59/200\n",
      "local epoch for train_loader 1: 59/200\n",
      "Loss C1: 0.9606919139623642\n",
      "local epoch for train_loader 2: 59/200\n",
      "Loss C2: 0.9310169163204375\n",
      "local epoch for train_loader 4: 59/200\n",
      "Loss C4: 0.9741514444351196\n",
      "train_loss: 0.9553\n",
      "----------\n",
      "local epoch 60/200\n",
      "local epoch for train_loader 1: 60/200\n",
      "Loss C1: 0.9601928070187569\n",
      "local epoch for train_loader 2: 60/200\n",
      "Loss C2: 0.9303767170224871\n",
      "local epoch for train_loader 4: 60/200\n",
      "Loss C4: 0.9738846063613892\n",
      "train_loss: 0.9548\n",
      "current epoch: 60 current mean dice: 0.4467 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 61/200\n",
      "local epoch for train_loader 1: 61/200\n",
      "Loss C1: 0.9596505090594292\n",
      "local epoch for train_loader 2: 61/200\n",
      "Loss C2: 0.9285966612043834\n",
      "local epoch for train_loader 4: 61/200\n",
      "Loss C4: 0.9731761693954468\n",
      "train_loss: 0.9538\n",
      "----------\n",
      "local epoch 62/200\n",
      "local epoch for train_loader 1: 62/200\n",
      "Loss C1: 0.9593366831541061\n",
      "local epoch for train_loader 2: 62/200\n",
      "Loss C2: 0.9296935512906029\n",
      "local epoch for train_loader 4: 62/200\n",
      "Loss C4: 0.9743183016777038\n",
      "train_loss: 0.9544\n",
      "current epoch: 62 current mean dice: 0.4276 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 63/200\n",
      "local epoch for train_loader 1: 63/200\n",
      "Loss C1: 0.9603392705321312\n",
      "local epoch for train_loader 2: 63/200\n",
      "Loss C2: 0.9300377198628017\n",
      "local epoch for train_loader 4: 63/200\n",
      "Loss C4: 0.9717149853706359\n",
      "train_loss: 0.9540\n",
      "----------\n",
      "local epoch 64/200\n",
      "local epoch for train_loader 1: 64/200\n",
      "Loss C1: 0.9596754610538483\n",
      "local epoch for train_loader 2: 64/200\n",
      "Loss C2: 0.9299603643871489\n",
      "local epoch for train_loader 4: 64/200\n",
      "Loss C4: 0.9729866504669189\n",
      "train_loss: 0.9542\n",
      "current epoch: 64 current mean dice: 0.4595 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 65/200\n",
      "local epoch for train_loader 1: 65/200\n",
      "Loss C1: 0.9600175395607948\n",
      "local epoch for train_loader 2: 65/200\n",
      "Loss C2: 0.9288311430386135\n",
      "local epoch for train_loader 4: 65/200\n",
      "Loss C4: 0.9712649583816528\n",
      "train_loss: 0.9534\n",
      "----------\n",
      "local epoch 66/200\n",
      "local epoch for train_loader 1: 66/200\n",
      "Loss C1: 0.9598574340343475\n",
      "local epoch for train_loader 2: 66/200\n",
      "Loss C2: 0.9291634502865019\n",
      "local epoch for train_loader 4: 66/200\n",
      "Loss C4: 0.971658730506897\n",
      "train_loss: 0.9536\n",
      "current epoch: 66 current mean dice: 0.4472 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 67/200\n",
      "local epoch for train_loader 1: 67/200\n",
      "Loss C1: 0.959398441016674\n",
      "local epoch for train_loader 2: 67/200\n",
      "Loss C2: 0.9289700899805341\n",
      "local epoch for train_loader 4: 67/200\n",
      "Loss C4: 0.9712322950363159\n",
      "train_loss: 0.9532\n",
      "----------\n",
      "local epoch 68/200\n",
      "local epoch for train_loader 1: 68/200\n",
      "Loss C1: 0.9593643993139267\n",
      "local epoch for train_loader 2: 68/200\n",
      "Loss C2: 0.9283087764467511\n",
      "local epoch for train_loader 4: 68/200\n",
      "Loss C4: 0.9718998670578003\n",
      "train_loss: 0.9532\n",
      "current epoch: 68 current mean dice: 0.4553 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 69/200\n",
      "local epoch for train_loader 1: 69/200\n",
      "Loss C1: 0.95975212007761\n",
      "local epoch for train_loader 2: 69/200\n",
      "Loss C2: 0.9291586052803766\n",
      "local epoch for train_loader 4: 69/200\n",
      "Loss C4: 0.9702281832695008\n",
      "train_loss: 0.9530\n",
      "----------\n",
      "local epoch 70/200\n",
      "local epoch for train_loader 1: 70/200\n",
      "Loss C1: 0.960053451359272\n",
      "local epoch for train_loader 2: 70/200\n",
      "Loss C2: 0.9285080745106652\n",
      "local epoch for train_loader 4: 70/200\n",
      "Loss C4: 0.9751538038253784\n",
      "train_loss: 0.9546\n",
      "current epoch: 70 current mean dice: 0.4625 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 71/200\n",
      "local epoch for train_loader 1: 71/200\n",
      "Loss C1: 0.9595317468047142\n",
      "local epoch for train_loader 2: 71/200\n",
      "Loss C2: 0.9284140127045768\n",
      "local epoch for train_loader 4: 71/200\n",
      "Loss C4: 0.9723378419876099\n",
      "train_loss: 0.9534\n",
      "----------\n",
      "local epoch 72/200\n",
      "local epoch for train_loader 1: 72/200\n",
      "Loss C1: 0.9595866650342941\n",
      "local epoch for train_loader 2: 72/200\n",
      "Loss C2: 0.9300123112542289\n",
      "local epoch for train_loader 4: 72/200\n",
      "Loss C4: 0.9696727991104126\n",
      "train_loss: 0.9531\n",
      "current epoch: 72 current mean dice: 0.4545 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 73/200\n",
      "local epoch for train_loader 1: 73/200\n",
      "Loss C1: 0.9594926461577415\n",
      "local epoch for train_loader 2: 73/200\n",
      "Loss C2: 0.9300201535224915\n",
      "local epoch for train_loader 4: 73/200\n",
      "Loss C4: 0.972215473651886\n",
      "train_loss: 0.9539\n",
      "----------\n",
      "local epoch 74/200\n",
      "local epoch for train_loader 1: 74/200\n",
      "Loss C1: 0.9593753069639206\n",
      "local epoch for train_loader 2: 74/200\n",
      "Loss C2: 0.928239955788567\n",
      "local epoch for train_loader 4: 74/200\n",
      "Loss C4: 0.9698774337768554\n",
      "train_loss: 0.9525\n",
      "current epoch: 74 current mean dice: 0.4382 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 75/200\n",
      "local epoch for train_loader 1: 75/200\n",
      "Loss C1: 0.9591854140162468\n",
      "local epoch for train_loader 2: 75/200\n",
      "Loss C2: 0.9292950090907869\n",
      "local epoch for train_loader 4: 75/200\n",
      "Loss C4: 0.9702334880828858\n",
      "train_loss: 0.9529\n",
      "----------\n",
      "local epoch 76/200\n",
      "local epoch for train_loader 1: 76/200\n",
      "Loss C1: 0.9592014625668526\n",
      "local epoch for train_loader 2: 76/200\n",
      "Loss C2: 0.9279894261133104\n",
      "local epoch for train_loader 4: 76/200\n",
      "Loss C4: 0.9701391100883484\n",
      "train_loss: 0.9524\n",
      "current epoch: 76 current mean dice: 0.4504 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 77/200\n",
      "local epoch for train_loader 1: 77/200\n",
      "Loss C1: 0.9602369964122772\n",
      "local epoch for train_loader 2: 77/200\n",
      "Loss C2: 0.9286313851674398\n",
      "local epoch for train_loader 4: 77/200\n",
      "Loss C4: 0.9697022676467896\n",
      "train_loss: 0.9529\n",
      "----------\n",
      "local epoch 78/200\n",
      "local epoch for train_loader 1: 78/200\n",
      "Loss C1: 0.959854245185852\n",
      "local epoch for train_loader 2: 78/200\n",
      "Loss C2: 0.9287746662185306\n",
      "local epoch for train_loader 4: 78/200\n",
      "Loss C4: 0.9702711462974548\n",
      "train_loss: 0.9530\n",
      "current epoch: 78 current mean dice: 0.4494 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 79/200\n",
      "local epoch for train_loader 1: 79/200\n",
      "Loss C1: 0.9588969722390175\n",
      "local epoch for train_loader 2: 79/200\n",
      "Loss C2: 0.9288886870656695\n",
      "local epoch for train_loader 4: 79/200\n",
      "Loss C4: 0.9708547830581665\n",
      "train_loss: 0.9529\n",
      "----------\n",
      "local epoch 80/200\n",
      "local epoch for train_loader 1: 80/200\n",
      "Loss C1: 0.9613246098160744\n",
      "local epoch for train_loader 2: 80/200\n",
      "Loss C2: 0.9291850129763285\n",
      "local epoch for train_loader 4: 80/200\n",
      "Loss C4: 0.9690958738327027\n",
      "train_loss: 0.9532\n",
      "current epoch: 80 current mean dice: 0.4623 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 81/200\n",
      "local epoch for train_loader 1: 81/200\n",
      "Loss C1: 0.9585738405585289\n",
      "local epoch for train_loader 2: 81/200\n",
      "Loss C2: 0.9287122601554507\n",
      "local epoch for train_loader 4: 81/200\n",
      "Loss C4: 0.9733347654342651\n",
      "train_loss: 0.9535\n",
      "----------\n",
      "local epoch 82/200\n",
      "local epoch for train_loader 1: 82/200\n",
      "Loss C1: 0.9599795341491699\n",
      "local epoch for train_loader 2: 82/200\n",
      "Loss C2: 0.930446329570952\n",
      "local epoch for train_loader 4: 82/200\n",
      "Loss C4: 0.9690346956253052\n",
      "train_loss: 0.9532\n",
      "current epoch: 82 current mean dice: 0.4439 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 83/200\n",
      "local epoch for train_loader 1: 83/200\n",
      "Loss C1: 0.9587684124708176\n",
      "local epoch for train_loader 2: 83/200\n",
      "Loss C2: 0.9287158052126566\n",
      "local epoch for train_loader 4: 83/200\n",
      "Loss C4: 0.9719965815544128\n",
      "train_loss: 0.9532\n",
      "----------\n",
      "local epoch 84/200\n",
      "local epoch for train_loader 1: 84/200\n",
      "Loss C1: 0.9598482251167297\n",
      "local epoch for train_loader 2: 84/200\n",
      "Loss C2: 0.9308815399805704\n",
      "local epoch for train_loader 4: 84/200\n",
      "Loss C4: 0.9689198970794678\n",
      "train_loss: 0.9532\n",
      "current epoch: 84 current mean dice: 0.4407 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 85/200\n",
      "local epoch for train_loader 1: 85/200\n",
      "Loss C1: 0.9592496305704117\n",
      "local epoch for train_loader 2: 85/200\n",
      "Loss C2: 0.9296150718416486\n",
      "local epoch for train_loader 4: 85/200\n",
      "Loss C4: 0.9705432653427124\n",
      "train_loss: 0.9531\n",
      "----------\n",
      "local epoch 86/200\n",
      "local epoch for train_loader 1: 86/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss C1: 0.9597070589661598\n",
      "local epoch for train_loader 2: 86/200\n",
      "Loss C2: 0.9289266892841884\n",
      "local epoch for train_loader 4: 86/200\n",
      "Loss C4: 0.9695591449737548\n",
      "train_loss: 0.9527\n",
      "current epoch: 86 current mean dice: 0.4386 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 87/200\n",
      "local epoch for train_loader 1: 87/200\n",
      "Loss C1: 0.959390290081501\n",
      "local epoch for train_loader 2: 87/200\n",
      "Loss C2: 0.9284236289206005\n",
      "local epoch for train_loader 4: 87/200\n",
      "Loss C4: 0.9703977346420288\n",
      "train_loss: 0.9527\n",
      "----------\n",
      "local epoch 88/200\n",
      "local epoch for train_loader 1: 88/200\n",
      "Loss C1: 0.9586488679051399\n",
      "local epoch for train_loader 2: 88/200\n",
      "Loss C2: 0.9295268030393691\n",
      "local epoch for train_loader 4: 88/200\n",
      "Loss C4: 0.9707183837890625\n",
      "train_loss: 0.9530\n",
      "current epoch: 88 current mean dice: 0.4445 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 89/200\n",
      "local epoch for train_loader 1: 89/200\n",
      "Loss C1: 0.9600296318531036\n",
      "local epoch for train_loader 2: 89/200\n",
      "Loss C2: 0.9328618390219552\n",
      "local epoch for train_loader 4: 89/200\n",
      "Loss C4: 0.9694943904876709\n",
      "train_loss: 0.9541\n",
      "----------\n",
      "local epoch 90/200\n",
      "local epoch for train_loader 1: 90/200\n",
      "Loss C1: 0.960038997232914\n",
      "local epoch for train_loader 2: 90/200\n",
      "Loss C2: 0.9289026203609648\n",
      "local epoch for train_loader 4: 90/200\n",
      "Loss C4: 0.9735275268554687\n",
      "train_loss: 0.9542\n",
      "current epoch: 90 current mean dice: 0.4178 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 91/200\n",
      "local epoch for train_loader 1: 91/200\n",
      "Loss C1: 0.9612089842557907\n",
      "local epoch for train_loader 2: 91/200\n",
      "Loss C2: 0.9297195275624593\n",
      "local epoch for train_loader 4: 91/200\n",
      "Loss C4: 0.9735822916030884\n",
      "train_loss: 0.9548\n",
      "----------\n",
      "local epoch 92/200\n",
      "local epoch for train_loader 1: 92/200\n",
      "Loss C1: 0.9594829902052879\n",
      "local epoch for train_loader 2: 92/200\n",
      "Loss C2: 0.9278991052082607\n",
      "local epoch for train_loader 4: 92/200\n",
      "Loss C4: 0.9723459243774414\n",
      "train_loss: 0.9532\n",
      "current epoch: 92 current mean dice: 0.4461 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 93/200\n",
      "local epoch for train_loader 1: 93/200\n",
      "Loss C1: 0.9608228579163551\n",
      "local epoch for train_loader 2: 93/200\n",
      "Loss C2: 0.9305774200530279\n",
      "local epoch for train_loader 4: 93/200\n",
      "Loss C4: 0.9688819408416748\n",
      "train_loss: 0.9534\n",
      "----------\n",
      "local epoch 94/200\n",
      "local epoch for train_loader 1: 94/200\n",
      "Loss C1: 0.9589314684271812\n",
      "local epoch for train_loader 2: 94/200\n",
      "Loss C2: 0.929303731237139\n",
      "local epoch for train_loader 4: 94/200\n",
      "Loss C4: 0.9730819582939148\n",
      "train_loss: 0.9538\n",
      "current epoch: 94 current mean dice: 0.4512 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 95/200\n",
      "local epoch for train_loader 1: 95/200\n",
      "Loss C1: 0.959919199347496\n",
      "local epoch for train_loader 2: 95/200\n",
      "Loss C2: 0.9283701550392878\n",
      "local epoch for train_loader 4: 95/200\n",
      "Loss C4: 0.97007155418396\n",
      "train_loss: 0.9528\n",
      "----------\n",
      "local epoch 96/200\n",
      "local epoch for train_loader 1: 96/200\n",
      "Loss C1: 0.959904134273529\n",
      "local epoch for train_loader 2: 96/200\n",
      "Loss C2: 0.9283610951332819\n",
      "local epoch for train_loader 4: 96/200\n",
      "Loss C4: 0.9704864740371704\n",
      "train_loss: 0.9529\n",
      "current epoch: 96 current mean dice: 0.4648 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 97/200\n",
      "local epoch for train_loader 1: 97/200\n",
      "Loss C1: 0.9603120684623718\n",
      "local epoch for train_loader 2: 97/200\n",
      "Loss C2: 0.9281578574861798\n",
      "local epoch for train_loader 4: 97/200\n",
      "Loss C4: 0.9692122220993042\n",
      "train_loss: 0.9526\n",
      "----------\n",
      "local epoch 98/200\n",
      "local epoch for train_loader 1: 98/200\n",
      "Loss C1: 0.959398977458477\n",
      "local epoch for train_loader 2: 98/200\n",
      "Loss C2: 0.9282997704687572\n",
      "local epoch for train_loader 4: 98/200\n",
      "Loss C4: 0.9716884613037109\n",
      "train_loss: 0.9531\n",
      "current epoch: 98 current mean dice: 0.4573 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 99/200\n",
      "local epoch for train_loader 1: 99/200\n",
      "Loss C1: 0.9600947201251984\n",
      "local epoch for train_loader 2: 99/200\n",
      "Loss C2: 0.9288883521443322\n",
      "local epoch for train_loader 4: 99/200\n",
      "Loss C4: 0.9684614896774292\n",
      "train_loss: 0.9525\n",
      "----------\n",
      "local epoch 100/200\n",
      "local epoch for train_loader 1: 100/200\n",
      "Loss C1: 0.9592157900333405\n",
      "local epoch for train_loader 2: 100/200\n",
      "Loss C2: 0.9289320054508391\n",
      "local epoch for train_loader 4: 100/200\n",
      "Loss C4: 0.9727851152420044\n",
      "train_loss: 0.9536\n",
      "current epoch: 100 current mean dice: 0.4428 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 101/200\n",
      "local epoch for train_loader 1: 101/200\n",
      "Loss C1: 0.9599593728780746\n",
      "local epoch for train_loader 2: 101/200\n",
      "Loss C2: 0.9307856871968224\n",
      "local epoch for train_loader 4: 101/200\n",
      "Loss C4: 0.968602979183197\n",
      "train_loss: 0.9531\n",
      "----------\n",
      "local epoch 102/200\n",
      "local epoch for train_loader 1: 102/200\n",
      "Loss C1: 0.9590693041682243\n",
      "local epoch for train_loader 2: 102/200\n",
      "Loss C2: 0.9281505743662516\n",
      "local epoch for train_loader 4: 102/200\n",
      "Loss C4: 0.9702499389648438\n",
      "train_loss: 0.9525\n",
      "current epoch: 102 current mean dice: 0.4472 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 103/200\n",
      "local epoch for train_loader 1: 103/200\n",
      "Loss C1: 0.9601552337408066\n",
      "local epoch for train_loader 2: 103/200\n",
      "Loss C2: 0.9295977013451713\n",
      "local epoch for train_loader 4: 103/200\n",
      "Loss C4: 0.9686835527420044\n",
      "train_loss: 0.9528\n",
      "----------\n",
      "local epoch 104/200\n",
      "local epoch for train_loader 1: 104/200\n",
      "Loss C1: 0.9590980559587479\n",
      "local epoch for train_loader 2: 104/200\n",
      "Loss C2: 0.9285688173203241\n",
      "local epoch for train_loader 4: 104/200\n",
      "Loss C4: 0.9721766114234924\n",
      "train_loss: 0.9533\n",
      "current epoch: 104 current mean dice: 0.4685 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 105/200\n",
      "local epoch for train_loader 1: 105/200\n",
      "Loss C1: 0.959288701415062\n",
      "local epoch for train_loader 2: 105/200\n",
      "Loss C2: 0.9294802404585338\n",
      "local epoch for train_loader 4: 105/200\n",
      "Loss C4: 0.9682517528533936\n",
      "train_loss: 0.9523\n",
      "----------\n",
      "local epoch 106/200\n",
      "local epoch for train_loader 1: 106/200\n",
      "Loss C1: 0.9599802568554878\n",
      "local epoch for train_loader 2: 106/200\n",
      "Loss C2: 0.9291175206502279\n",
      "local epoch for train_loader 4: 106/200\n",
      "Loss C4: 0.9698771953582763\n",
      "train_loss: 0.9530\n",
      "current epoch: 106 current mean dice: 0.4540 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 107/200\n",
      "local epoch for train_loader 1: 107/200\n",
      "Loss C1: 0.959698848426342\n",
      "local epoch for train_loader 2: 107/200\n",
      "Loss C2: 0.9282041192054749\n",
      "local epoch for train_loader 4: 107/200\n",
      "Loss C4: 0.9695178985595703\n",
      "train_loss: 0.9525\n",
      "----------\n",
      "local epoch 108/200\n",
      "local epoch for train_loader 1: 108/200\n",
      "Loss C1: 0.9602218791842461\n",
      "local epoch for train_loader 2: 108/200\n",
      "Loss C2: 0.9288094696544466\n",
      "local epoch for train_loader 4: 108/200\n",
      "Loss C4: 0.9691550374031067\n",
      "train_loss: 0.9527\n",
      "current epoch: 108 current mean dice: 0.4509 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 109/200\n",
      "local epoch for train_loader 1: 109/200\n",
      "Loss C1: 0.9606000706553459\n",
      "local epoch for train_loader 2: 109/200\n",
      "Loss C2: 0.9298348256519863\n",
      "local epoch for train_loader 4: 109/200\n",
      "Loss C4: 0.9696222066879272\n",
      "train_loss: 0.9534\n",
      "----------\n",
      "local epoch 110/200\n",
      "local epoch for train_loader 1: 110/200\n",
      "Loss C1: 0.9587616249918938\n",
      "local epoch for train_loader 2: 110/200\n",
      "Loss C2: 0.9281009095055717\n",
      "local epoch for train_loader 4: 110/200\n",
      "Loss C4: 0.9708781719207764\n",
      "train_loss: 0.9526\n",
      "current epoch: 110 current mean dice: 0.4651 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 111/200\n",
      "local epoch for train_loader 1: 111/200\n",
      "Loss C1: 0.9597890749573708\n",
      "local epoch for train_loader 2: 111/200\n",
      "Loss C2: 0.9319796164830526\n",
      "local epoch for train_loader 4: 111/200\n",
      "Loss C4: 0.9687443733215332\n",
      "train_loss: 0.9535\n",
      "----------\n",
      "local epoch 112/200\n",
      "local epoch for train_loader 1: 112/200\n",
      "Loss C1: 0.9604315757751465\n",
      "local epoch for train_loader 2: 112/200\n",
      "Loss C2: 0.9305787114869981\n",
      "local epoch for train_loader 4: 112/200\n",
      "Loss C4: 0.9745255231857299\n",
      "train_loss: 0.9552\n",
      "current epoch: 112 current mean dice: 0.4504 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 113/200\n",
      "local epoch for train_loader 1: 113/200\n",
      "Loss C1: 0.9594632536172867\n",
      "local epoch for train_loader 2: 113/200\n",
      "Loss C2: 0.9292316323234922\n",
      "local epoch for train_loader 4: 113/200\n",
      "Loss C4: 0.9726268887519837\n",
      "train_loss: 0.9538\n",
      "----------\n",
      "local epoch 114/200\n",
      "local epoch for train_loader 1: 114/200\n",
      "Loss C1: 0.95887241512537\n",
      "local epoch for train_loader 2: 114/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss C2: 0.9281847249893915\n",
      "local epoch for train_loader 4: 114/200\n",
      "Loss C4: 0.9694364070892334\n",
      "train_loss: 0.9522\n",
      "current epoch: 114 current mean dice: 0.4275 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 115/200\n",
      "local epoch for train_loader 1: 115/200\n",
      "Loss C1: 0.9602832272648811\n",
      "local epoch for train_loader 2: 115/200\n",
      "Loss C2: 0.9281851620901198\n",
      "local epoch for train_loader 4: 115/200\n",
      "Loss C4: 0.9696042895317077\n",
      "train_loss: 0.9527\n",
      "----------\n",
      "local epoch 116/200\n",
      "local epoch for train_loader 1: 116/200\n",
      "Loss C1: 0.9614027664065361\n",
      "local epoch for train_loader 2: 116/200\n",
      "Loss C2: 0.9277328451474508\n",
      "local epoch for train_loader 4: 116/200\n",
      "Loss C4: 0.9687635898590088\n",
      "train_loss: 0.9526\n",
      "current epoch: 116 current mean dice: 0.4451 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 117/200\n",
      "local epoch for train_loader 1: 117/200\n",
      "Loss C1: 0.9590916261076927\n",
      "local epoch for train_loader 2: 117/200\n",
      "Loss C2: 0.9287024963469732\n",
      "local epoch for train_loader 4: 117/200\n",
      "Loss C4: 0.971303391456604\n",
      "train_loss: 0.9530\n",
      "----------\n",
      "local epoch 118/200\n",
      "local epoch for train_loader 1: 118/200\n",
      "Loss C1: 0.9600967913866043\n",
      "local epoch for train_loader 2: 118/200\n",
      "Loss C2: 0.9301559016818092\n",
      "local epoch for train_loader 4: 118/200\n",
      "Loss C4: 0.9680736541748047\n",
      "train_loss: 0.9528\n",
      "current epoch: 118 current mean dice: 0.4644 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 119/200\n",
      "local epoch for train_loader 1: 119/200\n",
      "Loss C1: 0.95925322920084\n",
      "local epoch for train_loader 2: 119/200\n",
      "Loss C2: 0.9286116162935892\n",
      "local epoch for train_loader 4: 119/200\n",
      "Loss C4: 0.9731019973754883\n",
      "train_loss: 0.9537\n",
      "----------\n",
      "local epoch 120/200\n",
      "local epoch for train_loader 1: 120/200\n",
      "Loss C1: 0.9590711668133736\n",
      "local epoch for train_loader 2: 120/200\n",
      "Loss C2: 0.929276684919993\n",
      "local epoch for train_loader 4: 120/200\n",
      "Loss C4: 0.9684293508529663\n",
      "train_loss: 0.9523\n",
      "current epoch: 120 current mean dice: 0.4487 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 121/200\n",
      "local epoch for train_loader 1: 121/200\n",
      "Loss C1: 0.9593094438314438\n",
      "local epoch for train_loader 2: 121/200\n",
      "Loss C2: 0.9280376008578709\n",
      "local epoch for train_loader 4: 121/200\n",
      "Loss C4: 0.9703196525573731\n",
      "train_loss: 0.9526\n",
      "----------\n",
      "local epoch 122/200\n",
      "local epoch for train_loader 1: 122/200\n",
      "Loss C1: 0.9592413231730461\n",
      "local epoch for train_loader 2: 122/200\n",
      "Loss C2: 0.9285185280300322\n",
      "local epoch for train_loader 4: 122/200\n",
      "Loss C4: 0.9684492945671082\n",
      "train_loss: 0.9521\n",
      "current epoch: 122 current mean dice: 0.4479 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 123/200\n",
      "local epoch for train_loader 1: 123/200\n",
      "Loss C1: 0.9594737961888313\n",
      "local epoch for train_loader 2: 123/200\n",
      "Loss C2: 0.9289275351024809\n",
      "local epoch for train_loader 4: 123/200\n",
      "Loss C4: 0.971166729927063\n",
      "train_loss: 0.9532\n",
      "----------\n",
      "local epoch 124/200\n",
      "local epoch for train_loader 1: 124/200\n",
      "Loss C1: 0.9599327445030212\n",
      "local epoch for train_loader 2: 124/200\n",
      "Loss C2: 0.9279832187153044\n",
      "local epoch for train_loader 4: 124/200\n",
      "Loss C4: 0.9685162544250489\n",
      "train_loss: 0.9521\n",
      "current epoch: 124 current mean dice: 0.4503 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 125/200\n",
      "local epoch for train_loader 1: 125/200\n",
      "Loss C1: 0.9589389562606812\n",
      "local epoch for train_loader 2: 125/200\n",
      "Loss C2: 0.9284666918572926\n",
      "local epoch for train_loader 4: 125/200\n",
      "Loss C4: 0.9707850694656373\n",
      "train_loss: 0.9527\n",
      "----------\n",
      "local epoch 126/200\n",
      "local epoch for train_loader 1: 126/200\n",
      "Loss C1: 0.9605842679738998\n",
      "local epoch for train_loader 2: 126/200\n",
      "Loss C2: 0.934088735353379\n",
      "local epoch for train_loader 4: 126/200\n",
      "Loss C4: 0.9683902144432068\n",
      "train_loss: 0.9544\n",
      "current epoch: 126 current mean dice: 0.4582 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 127/200\n",
      "local epoch for train_loader 1: 127/200\n",
      "Loss C1: 0.959983229637146\n",
      "local epoch for train_loader 2: 127/200\n",
      "Loss C2: 0.9287891756920588\n",
      "local epoch for train_loader 4: 127/200\n",
      "Loss C4: 0.9739088654518128\n",
      "train_loss: 0.9542\n",
      "----------\n",
      "local epoch 128/200\n",
      "local epoch for train_loader 1: 128/200\n",
      "Loss C1: 0.9597301557660103\n",
      "local epoch for train_loader 2: 128/200\n",
      "Loss C2: 0.9318536037490481\n",
      "local epoch for train_loader 4: 128/200\n",
      "Loss C4: 0.969278359413147\n",
      "train_loss: 0.9536\n",
      "current epoch: 128 current mean dice: 0.4363 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 129/200\n",
      "local epoch for train_loader 1: 129/200\n",
      "Loss C1: 0.9593188613653183\n",
      "local epoch for train_loader 2: 129/200\n",
      "Loss C2: 0.927970738638015\n",
      "local epoch for train_loader 4: 129/200\n",
      "Loss C4: 0.9716179370880127\n",
      "train_loss: 0.9530\n",
      "----------\n",
      "local epoch 130/200\n",
      "local epoch for train_loader 1: 130/200\n",
      "Loss C1: 0.9604910612106323\n",
      "local epoch for train_loader 2: 130/200\n",
      "Loss C2: 0.928702712059021\n",
      "local epoch for train_loader 4: 130/200\n",
      "Loss C4: 0.9703587055206299\n",
      "train_loss: 0.9532\n",
      "current epoch: 130 current mean dice: 0.4527 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 131/200\n",
      "local epoch for train_loader 1: 131/200\n",
      "Loss C1: 0.9588426128029823\n",
      "local epoch for train_loader 2: 131/200\n",
      "Loss C2: 0.9285119204294114\n",
      "local epoch for train_loader 4: 131/200\n",
      "Loss C4: 0.9727174401283264\n",
      "train_loss: 0.9534\n",
      "----------\n",
      "local epoch 132/200\n",
      "local epoch for train_loader 1: 132/200\n",
      "Loss C1: 0.9595960080623627\n",
      "local epoch for train_loader 2: 132/200\n",
      "Loss C2: 0.9315303847903297\n",
      "local epoch for train_loader 4: 132/200\n",
      "Loss C4: 0.9686892032623291\n",
      "train_loss: 0.9533\n",
      "current epoch: 132 current mean dice: 0.4578 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 133/200\n",
      "local epoch for train_loader 1: 133/200\n",
      "Loss C1: 0.9587013944983482\n",
      "local epoch for train_loader 2: 133/200\n",
      "Loss C2: 0.9280979604948134\n",
      "local epoch for train_loader 4: 133/200\n",
      "Loss C4: 0.9770219802856446\n",
      "train_loss: 0.9546\n",
      "----------\n",
      "local epoch 134/200\n",
      "local epoch for train_loader 1: 134/200\n",
      "Loss C1: 0.9596947804093361\n",
      "local epoch for train_loader 2: 134/200\n",
      "Loss C2: 0.9349120259284973\n",
      "local epoch for train_loader 4: 134/200\n",
      "Loss C4: 0.9682002782821655\n",
      "train_loss: 0.9543\n",
      "current epoch: 134 current mean dice: 0.0698 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 135/200\n",
      "local epoch for train_loader 1: 135/200\n",
      "Loss C1: 0.9597608223557472\n",
      "local epoch for train_loader 2: 135/200\n",
      "Loss C2: 0.9295708253270104\n",
      "local epoch for train_loader 4: 135/200\n",
      "Loss C4: 0.9775539875030518\n",
      "train_loss: 0.9556\n",
      "----------\n",
      "local epoch 136/200\n",
      "local epoch for train_loader 1: 136/200\n",
      "Loss C1: 0.9596624597907066\n",
      "local epoch for train_loader 2: 136/200\n",
      "Loss C2: 0.929740465822674\n",
      "local epoch for train_loader 4: 136/200\n",
      "Loss C4: 0.9692094802856446\n",
      "train_loss: 0.9529\n",
      "current epoch: 136 current mean dice: 0.4305 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 137/200\n",
      "local epoch for train_loader 1: 137/200\n",
      "Loss C1: 0.9591417536139488\n",
      "local epoch for train_loader 2: 137/200\n",
      "Loss C2: 0.92888172183718\n",
      "local epoch for train_loader 4: 137/200\n",
      "Loss C4: 0.9688906192779541\n",
      "train_loss: 0.9523\n",
      "----------\n",
      "local epoch 138/200\n",
      "local epoch for train_loader 1: 138/200\n",
      "Loss C1: 0.9598045870661736\n",
      "local epoch for train_loader 2: 138/200\n",
      "Loss C2: 0.928443261555263\n",
      "local epoch for train_loader 4: 138/200\n",
      "Loss C4: 0.9687315225601196\n",
      "train_loss: 0.9523\n",
      "current epoch: 138 current mean dice: 0.4458 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 139/200\n",
      "local epoch for train_loader 1: 139/200\n",
      "Loss C1: 0.958908699452877\n",
      "local epoch for train_loader 2: 139/200\n",
      "Loss C2: 0.9284218123980931\n",
      "local epoch for train_loader 4: 139/200\n",
      "Loss C4: 0.9707231521606445\n",
      "train_loss: 0.9527\n",
      "----------\n",
      "local epoch 140/200\n",
      "local epoch for train_loader 1: 140/200\n",
      "Loss C1: 0.9598690494894981\n",
      "local epoch for train_loader 2: 140/200\n",
      "Loss C2: 0.9326150190262568\n",
      "local epoch for train_loader 4: 140/200\n",
      "Loss C4: 0.9681554436683655\n",
      "train_loss: 0.9535\n",
      "current epoch: 140 current mean dice: 0.4663 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 141/200\n",
      "local epoch for train_loader 1: 141/200\n",
      "Loss C1: 0.9591272845864296\n",
      "local epoch for train_loader 2: 141/200\n",
      "Loss C2: 0.929075646968115\n",
      "local epoch for train_loader 4: 141/200\n",
      "Loss C4: 0.9733710885047913\n",
      "train_loss: 0.9539\n",
      "----------\n",
      "local epoch 142/200\n",
      "local epoch for train_loader 1: 142/200\n",
      "Loss C1: 0.9595365971326828\n",
      "local epoch for train_loader 2: 142/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss C2: 0.9317728082338969\n",
      "local epoch for train_loader 4: 142/200\n",
      "Loss C4: 0.9691061019897461\n",
      "train_loss: 0.9535\n",
      "current epoch: 142 current mean dice: 0.4454 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 143/200\n",
      "local epoch for train_loader 1: 143/200\n",
      "Loss C1: 0.9589028209447861\n",
      "local epoch for train_loader 2: 143/200\n",
      "Loss C2: 0.92911240032741\n",
      "local epoch for train_loader 4: 143/200\n",
      "Loss C4: 0.9698412656784058\n",
      "train_loss: 0.9526\n",
      "----------\n",
      "local epoch 144/200\n",
      "local epoch for train_loader 1: 144/200\n",
      "Loss C1: 0.9601568207144737\n",
      "local epoch for train_loader 2: 144/200\n",
      "Loss C2: 0.9294579795428685\n",
      "local epoch for train_loader 4: 144/200\n",
      "Loss C4: 0.9682793855667114\n",
      "train_loss: 0.9526\n",
      "current epoch: 144 current mean dice: 0.4485 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 145/200\n",
      "local epoch for train_loader 1: 145/200\n",
      "Loss C1: 0.958989255130291\n",
      "local epoch for train_loader 2: 145/200\n",
      "Loss C2: 0.9302833278973898\n",
      "local epoch for train_loader 4: 145/200\n",
      "Loss C4: 0.9703237295150757\n",
      "train_loss: 0.9532\n",
      "----------\n",
      "local epoch 146/200\n",
      "local epoch for train_loader 1: 146/200\n",
      "Loss C1: 0.9600176140666008\n",
      "local epoch for train_loader 2: 146/200\n",
      "Loss C2: 0.9289625712803432\n",
      "local epoch for train_loader 4: 146/200\n",
      "Loss C4: 0.9684893846511841\n",
      "train_loss: 0.9525\n",
      "current epoch: 146 current mean dice: 0.4416 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 147/200\n",
      "local epoch for train_loader 1: 147/200\n",
      "Loss C1: 0.9590372368693352\n",
      "local epoch for train_loader 2: 147/200\n",
      "Loss C2: 0.9277160196077257\n",
      "local epoch for train_loader 4: 147/200\n",
      "Loss C4: 0.9705631136894226\n",
      "train_loss: 0.9524\n",
      "----------\n",
      "local epoch 148/200\n",
      "local epoch for train_loader 1: 148/200\n",
      "Loss C1: 0.9587982296943665\n",
      "local epoch for train_loader 2: 148/200\n",
      "Loss C2: 0.9278566894077119\n",
      "local epoch for train_loader 4: 148/200\n",
      "Loss C4: 0.9688640356063842\n",
      "train_loss: 0.9518\n",
      "current epoch: 148 current mean dice: 0.4662 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 149/200\n",
      "local epoch for train_loader 1: 149/200\n",
      "Loss C1: 0.9590494260191917\n",
      "local epoch for train_loader 2: 149/200\n",
      "Loss C2: 0.9280832495008197\n",
      "local epoch for train_loader 4: 149/200\n",
      "Loss C4: 0.9734039545059204\n",
      "train_loss: 0.9535\n",
      "----------\n",
      "local epoch 150/200\n",
      "local epoch for train_loader 1: 150/200\n",
      "Loss C1: 0.9601740762591362\n",
      "local epoch for train_loader 2: 150/200\n",
      "Loss C2: 0.9286974242755345\n",
      "local epoch for train_loader 4: 150/200\n",
      "Loss C4: 0.9684165358543396\n",
      "train_loss: 0.9524\n",
      "current epoch: 150 current mean dice: 0.4545 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 151/200\n",
      "local epoch for train_loader 1: 151/200\n",
      "Loss C1: 0.9592888876795769\n",
      "local epoch for train_loader 2: 151/200\n",
      "Loss C2: 0.929674642426627\n",
      "local epoch for train_loader 4: 151/200\n",
      "Loss C4: 0.9712293863296508\n",
      "train_loss: 0.9534\n",
      "----------\n",
      "local epoch 152/200\n",
      "local epoch for train_loader 1: 152/200\n",
      "Loss C1: 0.9590918943285942\n",
      "local epoch for train_loader 2: 152/200\n",
      "Loss C2: 0.9311320497876122\n",
      "local epoch for train_loader 4: 152/200\n",
      "Loss C4: 0.9685646653175354\n",
      "train_loss: 0.9529\n",
      "current epoch: 152 current mean dice: 0.4368 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 153/200\n",
      "local epoch for train_loader 1: 153/200\n",
      "Loss C1: 0.9596920609474182\n",
      "local epoch for train_loader 2: 153/200\n",
      "Loss C2: 0.9277687725566682\n",
      "local epoch for train_loader 4: 153/200\n",
      "Loss C4: 0.9693654775619507\n",
      "train_loss: 0.9523\n",
      "----------\n",
      "local epoch 154/200\n",
      "local epoch for train_loader 1: 154/200\n",
      "Loss C1: 0.9602979496121407\n",
      "local epoch for train_loader 2: 154/200\n",
      "Loss C2: 0.9313470948310125\n",
      "local epoch for train_loader 4: 154/200\n",
      "Loss C4: 0.9682767987251282\n",
      "train_loss: 0.9533\n",
      "current epoch: 154 current mean dice: 0.4506 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 155/200\n",
      "local epoch for train_loader 1: 155/200\n",
      "Loss C1: 0.9591212347149849\n",
      "local epoch for train_loader 2: 155/200\n",
      "Loss C2: 0.9279154397192455\n",
      "local epoch for train_loader 4: 155/200\n",
      "Loss C4: 0.9721586227416992\n",
      "train_loss: 0.9531\n",
      "----------\n",
      "local epoch 156/200\n",
      "local epoch for train_loader 1: 156/200\n",
      "Loss C1: 0.9602965041995049\n",
      "local epoch for train_loader 2: 156/200\n",
      "Loss C2: 0.9349156078838167\n",
      "local epoch for train_loader 4: 156/200\n",
      "Loss C4: 0.9683616995811463\n",
      "train_loss: 0.9545\n",
      "current epoch: 156 current mean dice: 0.2232 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 157/200\n",
      "local epoch for train_loader 1: 157/200\n",
      "Loss C1: 0.9598704352974892\n",
      "local epoch for train_loader 2: 157/200\n",
      "Loss C2: 0.9315434041477385\n",
      "local epoch for train_loader 4: 157/200\n",
      "Loss C4: 0.9773704051971436\n",
      "train_loss: 0.9563\n",
      "----------\n",
      "local epoch 158/200\n",
      "local epoch for train_loader 1: 158/200\n",
      "Loss C1: 0.9593256488442421\n",
      "local epoch for train_loader 2: 158/200\n",
      "Loss C2: 0.9283319172405061\n",
      "local epoch for train_loader 4: 158/200\n",
      "Loss C4: 0.9729890942573547\n",
      "train_loss: 0.9535\n",
      "current epoch: 158 current mean dice: 0.4638 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 159/200\n",
      "local epoch for train_loader 1: 159/200\n",
      "Loss C1: 0.9603025689721107\n",
      "local epoch for train_loader 2: 159/200\n",
      "Loss C2: 0.9298086762428284\n",
      "local epoch for train_loader 4: 159/200\n",
      "Loss C4: 0.9683239221572876\n",
      "train_loss: 0.9528\n",
      "----------\n",
      "local epoch 160/200\n",
      "local epoch for train_loader 1: 160/200\n",
      "Loss C1: 0.9589869976043701\n",
      "local epoch for train_loader 2: 160/200\n",
      "Loss C2: 0.92852402868725\n",
      "local epoch for train_loader 4: 160/200\n",
      "Loss C4: 0.9715716600418091\n",
      "train_loss: 0.9530\n",
      "current epoch: 160 current mean dice: 0.4548 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 161/200\n",
      "local epoch for train_loader 1: 161/200\n",
      "Loss C1: 0.9596195742487907\n",
      "local epoch for train_loader 2: 161/200\n",
      "Loss C2: 0.9324041604995728\n",
      "local epoch for train_loader 4: 161/200\n",
      "Loss C4: 0.969069755077362\n",
      "train_loss: 0.9537\n",
      "----------\n",
      "local epoch 162/200\n",
      "local epoch for train_loader 1: 162/200\n",
      "Loss C1: 0.9590671882033348\n",
      "local epoch for train_loader 2: 162/200\n",
      "Loss C2: 0.9276604964619591\n",
      "local epoch for train_loader 4: 162/200\n",
      "Loss C4: 0.970133101940155\n",
      "train_loss: 0.9523\n",
      "current epoch: 162 current mean dice: 0.4675 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 163/200\n",
      "local epoch for train_loader 1: 163/200\n",
      "Loss C1: 0.96071457862854\n",
      "local epoch for train_loader 2: 163/200\n",
      "Loss C2: 0.9284618553661165\n",
      "local epoch for train_loader 4: 163/200\n",
      "Loss C4: 0.9685716986656189\n",
      "train_loss: 0.9526\n",
      "----------\n",
      "local epoch 164/200\n",
      "local epoch for train_loader 1: 164/200\n",
      "Loss C1: 0.959271676838398\n",
      "local epoch for train_loader 2: 164/200\n",
      "Loss C2: 0.9284847066515968\n",
      "local epoch for train_loader 4: 164/200\n",
      "Loss C4: 0.9752037167549134\n",
      "train_loss: 0.9543\n",
      "current epoch: 164 current mean dice: 0.4493 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 165/200\n",
      "local epoch for train_loader 1: 165/200\n",
      "Loss C1: 0.9598929136991501\n",
      "local epoch for train_loader 2: 165/200\n",
      "Loss C2: 0.9299853926613217\n",
      "local epoch for train_loader 4: 165/200\n",
      "Loss C4: 0.9685333490371704\n",
      "train_loss: 0.9528\n",
      "----------\n",
      "local epoch 166/200\n",
      "local epoch for train_loader 1: 166/200\n",
      "Loss C1: 0.9594013094902039\n",
      "local epoch for train_loader 2: 166/200\n",
      "Loss C2: 0.9278447883469718\n",
      "local epoch for train_loader 4: 166/200\n",
      "Loss C4: 0.971272349357605\n",
      "train_loss: 0.9528\n",
      "current epoch: 166 current mean dice: 0.4614 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 167/200\n",
      "local epoch for train_loader 1: 167/200\n",
      "Loss C1: 0.9611137360334396\n",
      "local epoch for train_loader 2: 167/200\n",
      "Loss C2: 0.9279991700535729\n",
      "local epoch for train_loader 4: 167/200\n",
      "Loss C4: 0.9676109671592712\n",
      "train_loss: 0.9522\n",
      "----------\n",
      "local epoch 168/200\n",
      "local epoch for train_loader 1: 168/200\n",
      "Loss C1: 0.9592355489730835\n",
      "local epoch for train_loader 2: 168/200\n",
      "Loss C2: 0.9292848053432646\n",
      "local epoch for train_loader 4: 168/200\n",
      "Loss C4: 0.9756429553031921\n",
      "train_loss: 0.9547\n",
      "current epoch: 168 current mean dice: 0.4340 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 169/200\n",
      "local epoch for train_loader 1: 169/200\n",
      "Loss C1: 0.9606132730841637\n",
      "local epoch for train_loader 2: 169/200\n",
      "Loss C2: 0.9332839676312038\n",
      "local epoch for train_loader 4: 169/200\n",
      "Loss C4: 0.970735502243042\n",
      "train_loss: 0.9549\n",
      "----------\n",
      "local epoch 170/200\n",
      "local epoch for train_loader 1: 170/200\n",
      "Loss C1: 0.9597932174801826\n",
      "local epoch for train_loader 2: 170/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss C2: 0.9282427713984535\n",
      "local epoch for train_loader 4: 170/200\n",
      "Loss C4: 0.9694628715515137\n",
      "train_loss: 0.9525\n",
      "current epoch: 170 current mean dice: 0.4436 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 171/200\n",
      "local epoch for train_loader 1: 171/200\n",
      "Loss C1: 0.9589867889881134\n",
      "local epoch for train_loader 2: 171/200\n",
      "Loss C2: 0.9287444040888831\n",
      "local epoch for train_loader 4: 171/200\n",
      "Loss C4: 0.9699801445007324\n",
      "train_loss: 0.9526\n",
      "----------\n",
      "local epoch 172/200\n",
      "local epoch for train_loader 1: 172/200\n",
      "Loss C1: 0.9626290649175644\n",
      "local epoch for train_loader 2: 172/200\n",
      "Loss C2: 0.9294707122303191\n",
      "local epoch for train_loader 4: 172/200\n",
      "Loss C4: 0.9683277368545532\n",
      "train_loss: 0.9535\n",
      "current epoch: 172 current mean dice: 0.4635 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 173/200\n",
      "local epoch for train_loader 1: 173/200\n",
      "Loss C1: 0.9593634009361267\n",
      "local epoch for train_loader 2: 173/200\n",
      "Loss C2: 0.9286154395058042\n",
      "local epoch for train_loader 4: 173/200\n",
      "Loss C4: 0.9740661144256592\n",
      "train_loss: 0.9540\n",
      "----------\n",
      "local epoch 174/200\n",
      "local epoch for train_loader 1: 174/200\n",
      "Loss C1: 0.9599782973527908\n",
      "local epoch for train_loader 2: 174/200\n",
      "Loss C2: 0.9297295184362502\n",
      "local epoch for train_loader 4: 174/200\n",
      "Loss C4: 0.9684820532798767\n",
      "train_loss: 0.9527\n",
      "current epoch: 174 current mean dice: 0.4397 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 175/200\n",
      "local epoch for train_loader 1: 175/200\n",
      "Loss C1: 0.9591927602887154\n",
      "local epoch for train_loader 2: 175/200\n",
      "Loss C2: 0.9284108621733529\n",
      "local epoch for train_loader 4: 175/200\n",
      "Loss C4: 0.9697780251502991\n",
      "train_loss: 0.9525\n",
      "----------\n",
      "local epoch 176/200\n",
      "local epoch for train_loader 1: 176/200\n",
      "Loss C1: 0.9607408940792084\n",
      "local epoch for train_loader 2: 176/200\n",
      "Loss C2: 0.928764473824274\n",
      "local epoch for train_loader 4: 176/200\n",
      "Loss C4: 0.9678928136825562\n",
      "train_loss: 0.9525\n",
      "current epoch: 176 current mean dice: 0.4561 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 177/200\n",
      "local epoch for train_loader 1: 177/200\n",
      "Loss C1: 0.9592689275741577\n",
      "local epoch for train_loader 2: 177/200\n",
      "Loss C2: 0.9281562595140367\n",
      "local epoch for train_loader 4: 177/200\n",
      "Loss C4: 0.9746614694595337\n",
      "train_loss: 0.9540\n",
      "----------\n",
      "local epoch 178/200\n",
      "local epoch for train_loader 1: 178/200\n",
      "Loss C1: 0.9604322612285614\n",
      "local epoch for train_loader 2: 178/200\n",
      "Loss C2: 0.9324147758029756\n",
      "local epoch for train_loader 4: 178/200\n",
      "Loss C4: 0.9703509569168091\n",
      "train_loss: 0.9544\n",
      "current epoch: 178 current mean dice: 0.4477 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 179/200\n",
      "local epoch for train_loader 1: 179/200\n",
      "Loss C1: 0.9592156857252121\n",
      "local epoch for train_loader 2: 179/200\n",
      "Loss C2: 0.9289299050966898\n",
      "local epoch for train_loader 4: 179/200\n",
      "Loss C4: 0.9714720368385314\n",
      "train_loss: 0.9532\n",
      "----------\n",
      "local epoch 180/200\n",
      "local epoch for train_loader 1: 180/200\n",
      "Loss C1: 0.9599046632647514\n",
      "local epoch for train_loader 2: 180/200\n",
      "Loss C2: 0.9283613080070132\n",
      "local epoch for train_loader 4: 180/200\n",
      "Loss C4: 0.9684711217880249\n",
      "train_loss: 0.9522\n",
      "current epoch: 180 current mean dice: 0.4513 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 181/200\n",
      "local epoch for train_loader 1: 181/200\n",
      "Loss C1: 0.9586626142263412\n",
      "local epoch for train_loader 2: 181/200\n",
      "Loss C2: 0.9282578769184294\n",
      "local epoch for train_loader 4: 181/200\n",
      "Loss C4: 0.9719468235969544\n",
      "train_loss: 0.9530\n",
      "----------\n",
      "local epoch 182/200\n",
      "local epoch for train_loader 1: 182/200\n",
      "Loss C1: 0.9598046913743019\n",
      "local epoch for train_loader 2: 182/200\n",
      "Loss C2: 0.9296270807584127\n",
      "local epoch for train_loader 4: 182/200\n",
      "Loss C4: 0.9675503373146057\n",
      "train_loss: 0.9523\n",
      "current epoch: 182 current mean dice: 0.4586 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 183/200\n",
      "local epoch for train_loader 1: 183/200\n",
      "Loss C1: 0.9598191007971764\n",
      "local epoch for train_loader 2: 183/200\n",
      "Loss C2: 0.927682550180526\n",
      "local epoch for train_loader 4: 183/200\n",
      "Loss C4: 0.9720599174499511\n",
      "train_loss: 0.9532\n",
      "----------\n",
      "local epoch 184/200\n",
      "local epoch for train_loader 1: 184/200\n",
      "Loss C1: 0.9596482440829277\n",
      "local epoch for train_loader 2: 184/200\n",
      "Loss C2: 0.9281183651515416\n",
      "local epoch for train_loader 4: 184/200\n",
      "Loss C4: 0.9680962800979614\n",
      "train_loss: 0.9520\n",
      "current epoch: 184 current mean dice: 0.4574 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 185/200\n",
      "local epoch for train_loader 1: 185/200\n",
      "Loss C1: 0.960142619907856\n",
      "local epoch for train_loader 2: 185/200\n",
      "Loss C2: 0.9284737223670596\n",
      "local epoch for train_loader 4: 185/200\n",
      "Loss C4: 0.9695684313774109\n",
      "train_loss: 0.9527\n",
      "----------\n",
      "local epoch 186/200\n",
      "local epoch for train_loader 1: 186/200\n",
      "Loss C1: 0.9591861516237259\n",
      "local epoch for train_loader 2: 186/200\n",
      "Loss C2: 0.9284414507093883\n",
      "local epoch for train_loader 4: 186/200\n",
      "Loss C4: 0.9720829963684082\n",
      "train_loss: 0.9532\n",
      "current epoch: 186 current mean dice: 0.4550 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 187/200\n",
      "local epoch for train_loader 1: 187/200\n",
      "Loss C1: 0.959627628326416\n",
      "local epoch for train_loader 2: 187/200\n",
      "Loss C2: 0.9317899289585295\n",
      "local epoch for train_loader 4: 187/200\n",
      "Loss C4: 0.9684495210647583\n",
      "train_loss: 0.9533\n",
      "----------\n",
      "local epoch 188/200\n",
      "local epoch for train_loader 1: 188/200\n",
      "Loss C1: 0.9588905423879623\n",
      "local epoch for train_loader 2: 188/200\n",
      "Loss C2: 0.9284920153163728\n",
      "local epoch for train_loader 4: 188/200\n",
      "Loss C4: 0.9694988369941712\n",
      "train_loss: 0.9523\n",
      "current epoch: 188 current mean dice: 0.4433 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 189/200\n",
      "local epoch for train_loader 1: 189/200\n",
      "Loss C1: 0.9607012644410133\n",
      "local epoch for train_loader 2: 189/200\n",
      "Loss C2: 0.9292894459906078\n",
      "local epoch for train_loader 4: 189/200\n",
      "Loss C4: 0.9678529977798462\n",
      "train_loss: 0.9526\n",
      "----------\n",
      "local epoch 190/200\n",
      "local epoch for train_loader 1: 190/200\n",
      "Loss C1: 0.9591087102890015\n",
      "local epoch for train_loader 2: 190/200\n",
      "Loss C2: 0.9283235640752883\n",
      "local epoch for train_loader 4: 190/200\n",
      "Loss C4: 0.9740258097648621\n",
      "train_loss: 0.9538\n",
      "current epoch: 190 current mean dice: 0.4660 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 191/200\n",
      "local epoch for train_loader 1: 191/200\n",
      "Loss C1: 0.9605252221226692\n",
      "local epoch for train_loader 2: 191/200\n",
      "Loss C2: 0.9346471286955333\n",
      "local epoch for train_loader 4: 191/200\n",
      "Loss C4: 0.9705974578857421\n",
      "train_loss: 0.9553\n",
      "----------\n",
      "local epoch 192/200\n",
      "local epoch for train_loader 1: 192/200\n",
      "Loss C1: 0.9591400772333145\n",
      "local epoch for train_loader 2: 192/200\n",
      "Loss C2: 0.9293543668020339\n",
      "local epoch for train_loader 4: 192/200\n",
      "Loss C4: 0.969996988773346\n",
      "train_loss: 0.9528\n",
      "current epoch: 192 current mean dice: 0.4525 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 193/200\n",
      "local epoch for train_loader 1: 193/200\n",
      "Loss C1: 0.959815189242363\n",
      "local epoch for train_loader 2: 193/200\n",
      "Loss C2: 0.9343434997967311\n",
      "local epoch for train_loader 4: 193/200\n",
      "Loss C4: 0.9690593242645263\n",
      "train_loss: 0.9544\n",
      "----------\n",
      "local epoch 194/200\n",
      "local epoch for train_loader 1: 194/200\n",
      "Loss C1: 0.9600380957126617\n",
      "local epoch for train_loader 2: 194/200\n",
      "Loss C2: 0.9296588131359645\n",
      "local epoch for train_loader 4: 194/200\n",
      "Loss C4: 0.9713791608810425\n",
      "train_loss: 0.9537\n",
      "current epoch: 194 current mean dice: 0.4438 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 195/200\n",
      "local epoch for train_loader 1: 195/200\n",
      "Loss C1: 0.9593273177742958\n",
      "local epoch for train_loader 2: 195/200\n",
      "Loss C2: 0.9298605464753651\n",
      "local epoch for train_loader 4: 195/200\n",
      "Loss C4: 0.9702280759811401\n",
      "train_loss: 0.9531\n",
      "----------\n",
      "local epoch 196/200\n",
      "local epoch for train_loader 1: 196/200\n",
      "Loss C1: 0.9590896666049957\n",
      "local epoch for train_loader 2: 196/200\n",
      "Loss C2: 0.9295510138784137\n",
      "local epoch for train_loader 4: 196/200\n",
      "Loss C4: 0.969919753074646\n",
      "train_loss: 0.9529\n",
      "current epoch: 196 current mean dice: 0.4582 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 197/200\n",
      "local epoch for train_loader 1: 197/200\n",
      "Loss C1: 0.9598506391048431\n",
      "local epoch for train_loader 2: 197/200\n",
      "Loss C2: 0.9303704528581529\n",
      "local epoch for train_loader 4: 197/200\n",
      "Loss C4: 0.9688564300537109\n",
      "train_loss: 0.9530\n",
      "----------\n",
      "local epoch 198/200\n",
      "local epoch for train_loader 1: 198/200\n",
      "Loss C1: 0.95926932990551\n",
      "local epoch for train_loader 2: 198/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss C2: 0.928619608992622\n",
      "local epoch for train_loader 4: 198/200\n",
      "Loss C4: 0.9697206258773804\n",
      "train_loss: 0.9525\n",
      "current epoch: 198 current mean dice: 0.4612 best mean dice: 0.5088 at epoch 24\n",
      "----------\n",
      "local epoch 199/200\n",
      "local epoch for train_loader 1: 199/200\n",
      "Loss C1: 0.9601841494441032\n",
      "local epoch for train_loader 2: 199/200\n",
      "Loss C2: 0.934004423164186\n",
      "local epoch for train_loader 4: 199/200\n",
      "Loss C4: 0.9683767795562744\n",
      "train_loss: 0.9542\n",
      "----------\n",
      "local epoch 200/200\n",
      "local epoch for train_loader 1: 200/200\n",
      "Loss C1: 0.9591148346662521\n",
      "local epoch for train_loader 2: 200/200\n",
      "Loss C2: 0.9291271283513024\n",
      "local epoch for train_loader 4: 200/200\n",
      "Loss C4: 0.9723428726196289\n",
      "train_loss: 0.9535\n",
      "current epoch: 200 current mean dice: 0.4562 best mean dice: 0.5088 at epoch 24\n"
     ]
    }
   ],
   "source": [
    "global_model.train()\n",
    "epoch_loss = 0\n",
    "modelc1, modelc2, modelc4 = copy.deepcopy(global_model), copy.deepcopy(global_model), copy.deepcopy(global_model)\n",
    "\n",
    "#optimizerc1 = get_optimizer(optimizer_name='adam', cur_lr=learning_rate,  model=modelc1, cur_momentum=0)\n",
    "#optimizerc2 = get_optimizer(optimizer_name='adam', cur_lr=learning_rate,  model=modelc2, cur_momentum=0)\n",
    "#optimizerc4 = get_optimizer(optimizer_name='adam', cur_lr=learning_rate,  model=modelc4, cur_momentum=0)\n",
    "\n",
    "train_loss, train_dice = [], []\n",
    "#modelc1, modelc2, modelc4 = copy.deepcopy(global_model), copy.deepcopy(global_model), copy.deepcopy(global_model)\n",
    "for epoch in range(num_epochs):\n",
    "    #Local update loop\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"local epoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    local_weights, local_losses = [], []\n",
    "    global_model.train()\n",
    "    \n",
    "    global_weights = global_model.state_dict()\n",
    "    modelc1, modelc2, modelc4 = copy.deepcopy(global_model), copy.deepcopy(global_model), copy.deepcopy(global_model)\n",
    "    optimizerc1 = torch.optim.Adam(modelc1.parameters(), learning_rate)\n",
    "    optimizerc2 = torch.optim.Adam(modelc2.parameters(), learning_rate)\n",
    "    optimizerc4 = torch.optim.Adam(modelc4.parameters(), learning_rate)\n",
    "    \n",
    "    modelc1.train()\n",
    "    modelc2.train()\n",
    "    modelc4.train()\n",
    "\n",
    "    batch_loss_c1, epoch_loss_c1 = [], []\n",
    "    print(f\"local epoch for train_loader 1: {epoch + 1}/{num_epochs}\")\n",
    "    for batch_data in c1_train_loader:\n",
    "        #inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "        #Swaping axes to have a batch of Batch_size, Channels, width and height\n",
    "        #inputs, labels = torch.swapaxes(batch_data[0][0], 1, -1).to(device), torch.swapaxes(batch_data[1][0], 1, -1).to(device)\n",
    "        inputs, labels = batch_data[0][:,:,:,:,0].to(device), batch_data[1][:,:,:,:,0].to(device)\n",
    "        modelc1.zero_grad()        \n",
    "        #print(inputs.shape)\n",
    "        outputs = modelc1(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizerc1.step()\n",
    "        batch_loss_c1.append(loss.item())\n",
    "    local_losses.append(copy.deepcopy(sum(batch_loss_c1) / len(batch_loss_c1)))\n",
    "    print(\"Loss C1: \" + str(local_losses[-1]))\n",
    "    \n",
    "    batch_loss_c2,epoch_loss_c2 = [], []\n",
    "    print(f\"local epoch for train_loader 2: {epoch + 1}/{num_epochs}\")\n",
    "    for batch_data in c2_train_loader:\n",
    "        #inputs, labels = torch.swapaxes(batch_data[0][0], 1, -1).to(device), torch.swapaxes(batch_data[1][0], 1, -1).to(device)\n",
    "        inputs, labels = batch_data[0][:,:,:,:,0].to(device), batch_data[1][:,:,:,:,0].to(device)\n",
    "        modelc2.zero_grad()\n",
    "        outputs = modelc2(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizerc2.step()\n",
    "        batch_loss_c2.append(loss.item())\n",
    "    local_losses.append(copy.deepcopy(sum(batch_loss_c2) / len(batch_loss_c2)))\n",
    "    print(\"Loss C2: \" + str(local_losses[-1]))\n",
    "    \n",
    "    \n",
    "    #C3 is the Siemens data loader for which we have only one data point\n",
    "    batch_loss_c4,epoch_loss_c4 = [], []\n",
    "    print(f\"local epoch for train_loader 4: {epoch + 1}/{num_epochs}\")\n",
    "    for batch_data in c4_train_loader:\n",
    "        #inputs, labels = torch.swapaxes(batch_data[0][0], 1, -1).to(device), torch.swapaxes(batch_data[1][0], 1, -1).to(device)\n",
    "        inputs, labels = batch_data[0][:,:,:,:,0].to(device), batch_data[1][:,:,:,:,0].to(device)\n",
    "        modelc4.zero_grad()\n",
    "        outputs = modelc4(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizerc4.step()\n",
    "        batch_loss_c4.append(loss.item())\n",
    "    local_losses.append(copy.deepcopy(sum(batch_loss_c4) / len(batch_loss_c4)))\n",
    "    print(\"Loss C4: \" + str(local_losses[-1]))\n",
    "    \n",
    "    loss_avg = sum(local_losses) / len(local_losses)\n",
    "    train_loss.append(loss_avg)\n",
    "    \n",
    "\n",
    "    print(f\"train_loss: {train_loss[-1]:.4f}\")\n",
    "    writer.add_scalar(\"train_loss\", loss_avg, epoch)        \n",
    "    \n",
    "    #Agregating the weights with the FedAvg aproach    \n",
    "    #global_weights = average_weights([copy.deepcopy(modelc2.state_dict())])\n",
    "    global_weights = average_weights_with_numsamplesweight([copy.deepcopy(modelc1.state_dict()),copy.deepcopy(modelc2.state_dict()),copy.deepcopy(modelc4.state_dict())],weight_classes)\n",
    "    # Update global weights with the averaged model weights.\n",
    "    global_model.load_state_dict(global_weights)\n",
    "    \n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        global_model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_images = None\n",
    "            val_labels = None\n",
    "            val_outputs = None\n",
    "            for val_data in all_valid_loader:\n",
    "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "                roi_size = (128, 128)\n",
    "                sw_batch_size = 1\n",
    "                val_outputs = global_model(val_images[:,:,:,:,0])\n",
    "                val_outputs = val_outputs>0.5 #This assumes one slice in the last dim\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels[:,:,:,:,0])\n",
    "            # aggregate the final mean dice result\n",
    "            metric = dice_metric.aggregate().item()\n",
    "            # reset the status for next validation round\n",
    "            dice_metric.reset()\n",
    "            metric_values.append(metric)\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(global_model.state_dict(), modality+\"_federated_AVG_best_metric_model_segmentation2d_array.pth\")\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                \"current epoch: {} current mean dice: {:.4f} best mean dice: {:.4f} at epoch {}\".format(\n",
    "                    epoch + 1, metric, best_metric, best_metric_epoch\n",
    "                )\n",
    "            )\n",
    "            writer.add_scalar(\"val_mean_dice\", metric, epoch + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e24bd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/otalora/miccai22\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c22668b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tmax'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecad5b2",
   "metadata": {},
   "source": [
    "## Testing the best validation model in an unseen test volume (slice-wise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d0c94c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep= 40\n",
    "cur_checkpoint_path = '/home/otarola/miccai22/metric_model_segmentation2d_array_ep_'+str(ep)+'.pth'\n",
    "\n",
    "checkpoint = torch.load('/home/otarola/miccai22/'+modality+'_federated_AVG_best_metric_model_segmentation2d_array.pth')\n",
    "\n",
    "global_model.load_state_dict(checkpoint)\n",
    "outputs = global_model(inputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dae7b700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tmax\n"
     ]
    }
   ],
   "source": [
    "print(modality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7763734a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2996795/3027378860.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels   = torch.tensor(cur_label).to(device)\n",
      "/tmp/ipykernel_2996795/3027378860.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  cur_ct_slice = torch.tensor(cur_image[:,:,:,:,ct_slice]).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG TEST DICE SCORE FOR LEARNING RATE 0.000132: 0.40831694652636846 - STD: 0.2955684548567093\n"
     ]
    }
   ],
   "source": [
    "count_volume = 0\n",
    "dice_metric.reset()\n",
    "metric_values_test = []\n",
    "for test_data in all_test_loader:\n",
    "    count_volume = count_volume+1\n",
    "    cur_image, cur_label = test_data\n",
    "    cur_outputs = []\n",
    "    cur_labels  = []\n",
    "    labels   = torch.tensor(cur_label).to(device)\n",
    "    for ct_slice in range(cur_image.shape[-1]):\n",
    "        cur_ct_slice = torch.tensor(cur_image[:,:,:,:,ct_slice]).to(device)        \n",
    "        label    = labels[:,:,:,:,ct_slice]\n",
    "        outputs = global_model(cur_ct_slice)\n",
    "\n",
    "        cur_outputs.append(outputs.cpu().detach().numpy()>0.5)\n",
    "        cur_labels.append(label.cpu().detach().numpy()>0.5)\n",
    "        #print(torch.tensor(cur_outputs[-1]).shape)\n",
    "        #print(torch.tensor(cur_labels[-1]).shape)\n",
    "        dice_metric(y_pred=torch.tensor(cur_outputs[-1]), y=torch.tensor(cur_labels[-1]))\n",
    "\n",
    "    # aggregate the final mean dice result\n",
    "    metric = dice_metric.aggregate().item()\n",
    "    dice_metric.reset()\n",
    "    metric_values_test.append(metric)\n",
    "print(\"AVG TEST DICE SCORE FOR LEARNING RATE \"+str(learning_rate) + \": \" + str(np.mean(metric_values_test)) + \" - STD: \" + str(np.std(metric_values_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c70f525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f4dc3621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tmax'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86eea6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 224, 224])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(label.cpu().detach().numpy()>0.5).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "874679db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.20762594044208527,\n",
       " 0.3941236138343811,\n",
       " 0.07199297845363617,\n",
       " 0.04296388477087021,\n",
       " 0.7524344325065613,\n",
       " 0.7241988182067871,\n",
       " 0.2197580635547638,\n",
       " 0.721306324005127,\n",
       " 0.7161716222763062,\n",
       " 0.7396162152290344,\n",
       " 0.4236111044883728,\n",
       " 0.06390823423862457,\n",
       " 0.0,\n",
       " 0.8018816709518433,\n",
       " 0.2451612949371338]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_values_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03d25efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 2) (256, 256, 2)\n"
     ]
    }
   ],
   "source": [
    "path_test_case = '/str/data/ASAP/miccai22_data/isles/federated/center1/test/case_21/SMIR.Brain.XX.O.CT_CBF.345691/SMIR.Brain.XX.O.CT_CBF.345691.nii'\n",
    "path_test_label= '/str/data/ASAP/miccai22_data/isles/federated/center1/test/case_21/SMIR.Brain.XX.O.OT.345694/SMIR.Brain.XX.O.OT.345694.nii'\n",
    "\n",
    "test_vol = nib.load(path_test_case)\n",
    "test_lbl = nib.load(path_test_label)\n",
    "\n",
    "test_vol_pxls = test_vol.get_fdata()\n",
    "test_vol_pxls = np.array(test_vol_pxls, dtype = np.float32)\n",
    "test_lbl_pxls = test_lbl.get_fdata()\n",
    "test_lbl_pxls = np.array(test_lbl_pxls)\n",
    "test_vol_pxls[test_vol_pxls>1200] = 0\n",
    "\n",
    "print(test_vol_pxls.shape, test_lbl_pxls.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "47903c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe478ae47c0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_vol_pxls[:,:,1],cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab1d958a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_test = global_model(torch.tensor(test_vol_pxls[np.newaxis, np.newaxis, :,:,1]/1200).to(device))\n",
    "out_test = out_test.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c0ae3ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.array(out_test[0,0,:,:]>0.5, dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7fcdbf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_lbl = test_lbl_pxls[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "20387792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_metric(torch.tensor(pred[np.newaxis,np.newaxis,:,:]),torch.tensor(pred[np.newaxis,np.newaxis,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ecc6d741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 256, 256)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3a2aba01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe478928820>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(out_test[0,0,:,:]>0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "628e9452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe478d9bca0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_lbl_pxls[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a4380e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.20762594044208527,\n",
       " 0.3941236138343811,\n",
       " 0.07199297845363617,\n",
       " 0.04296388477087021,\n",
       " 0.7524344325065613,\n",
       " 0.7241988182067871,\n",
       " 0.2197580635547638,\n",
       " 0.721306324005127,\n",
       " 0.7161716222763062,\n",
       " 0.7396162152290344,\n",
       " 0.4236111044883728,\n",
       " 0.06390823423862457,\n",
       " 0.0,\n",
       " 0.8018816709518433,\n",
       " 0.2451612949371338]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_values_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "66560d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = np.array(outputs.cpu().detach().numpy()>0.9, dtype='uint8')[0,0,:,:]\n",
    "pp[pp<=0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f73e3812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fe478e3bc40>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pp,cmap='jet')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f1f46fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[0,0,:,:].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "efef822f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fe47889a310>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(label[0,0,:,:].cpu().detach().numpy(),cmap='jet')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e6696639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.colorbar(mappable=None, cax=None, ax=None, **kw)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.colorbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ed86a805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 224, 224])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9acb9b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2451612949371338"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "972a39ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c4_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "64dcda0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c3_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c71def59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c1_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "398bd702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c1_valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "871055af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c1_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ae9dedca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c2_train_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
